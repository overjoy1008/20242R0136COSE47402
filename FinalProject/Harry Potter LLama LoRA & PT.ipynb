{"cells":[{"cell_type":"markdown","source":["# 1. Downloading Llama & Preparing LoRA"],"metadata":{"id":"fROHRlcGdfNs"}},{"cell_type":"markdown","source":["First we check the GPU version available in the environment and install specific dependencies that are compatible with the detected GPU to prevent version conflicts."],"metadata":{"id":"IqM-T1RTzY6C"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1733829066447,"user_tz":-540,"elapsed":26813,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}}},"outputs":[],"source":["%%capture\n","import torch\n","major_version, minor_version = torch.cuda.get_device_capability()\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","if major_version >= 8:\n","    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n","else:\n","    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n","pass"]},{"cell_type":"markdown","source":["Next we need to prepare to load a range of quantized language models, including a new 15 trillion token LLama-3 model, optimized for memory efficiency with 4-bit quantization.\n"],"metadata":{"id":"r2v_X2fA0Df5"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CEiokeMJ0c74","executionInfo":{"status":"ok","timestamp":1733829068305,"user_tz":-540,"elapsed":1859,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"bc0d7c73-4542-49db-a175-24b5ca8838a4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmUBVEnvCDJv","executionInfo":{"status":"ok","timestamp":1733829131132,"user_tz":-540,"elapsed":62829,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"fead8a9a-7740-4f12-b22f-b27a827197c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! Llama 3 is up to 8k\n","dtype = None\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","fourbit_models = [\n","    \"unsloth/mistral-7b-bnb-4bit\",\n","    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","    \"unsloth/llama-2-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-it-bnb-4bit\",\n","    \"unsloth/gemma-2b-bnb-4bit\",\n","    \"unsloth/gemma-2b-it-bnb-4bit\",\n","    \"unsloth/llama-3-8b-bnb-4bit\",\n","]\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\", # Llama-3 70b also works (just change the model name)\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6bZsfBuZDeCL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733829138419,"user_tz":-540,"elapsed":7290,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"33bef39f-a00f-46f1-9d5a-52ed5afcda38"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.12.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0,\n","    bias = \"none\",\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 3407,\n","    use_rslora = False,\n","    loftq_config = None,\n",")"]},{"cell_type":"markdown","source":["### Understanding Model"],"metadata":{"id":"ScpDNEtyGl0K"}},{"cell_type":"code","source":["# def print_model_structure(model, indent=0):\n","#     \"\"\"\n","#     ëª¨ë¸ì˜ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ê³„ì¸µì ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n","\n","#     Args:\n","#         model: PyTorch ëª¨ë¸\n","#         indent: ë“¤ì—¬ì“°ê¸° ë ˆë²¨\n","#     \"\"\"\n","#     tab = '  ' * indent\n","\n","#     for name, module in model.named_children():\n","#         print(f\"{tab}{name}: ({module.__class__.__name__})\")\n","\n","#         if \"Attention\" in module.__class__.__name__:\n","#             print(f\"{tab}  â†’ Attention Layer Found!\")\n","#             if hasattr(module, 'num_heads'):\n","#                 print(f\"{tab}    - Number of heads: {module.num_heads}\")\n","#             if hasattr(module, 'head_dim'):\n","#                 print(f\"{tab}    - Head dimension: {module.head_dim}\")\n","\n","#         elif \"Transformer\" in module.__class__.__name__:\n","#             print(f\"{tab}  â†’ Transformer Block Found!\")\n","\n","#         if len(list(module.children())) > 0:\n","#             print_model_structure(module, indent + 1)\n","\n","# def analyze_lora_layers(model):\n","#     \"\"\"\n","#     LoRA ë ˆì´ì–´ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜\n","#     \"\"\"\n","#     print(\"\\n=== LoRA Layer Analysis ===\")\n","#     for name, module in model.named_modules():\n","#         if hasattr(module, 'lora_A'):\n","#             print(f\"\\nLayer: {name}\")\n","\n","#             # LoRA A í–‰ë ¬ ì •ë³´\n","#             if isinstance(module.lora_A, dict):\n","#                 for adapter_name, lora_A in module.lora_A.items():\n","#                     print(f\"Adapter: {adapter_name}\")\n","#                     if hasattr(lora_A, 'weight'):\n","#                         shape = lora_A.weight.shape\n","#                         print(f\"  Shape (A): {shape}\")\n","#             else:\n","#                 if hasattr(module.lora_A, 'weight'):\n","#                     shape = module.lora_A.weight.shape\n","#                     print(f\"  Shape (A): {shape}\")\n","\n","#             # ê¸°ë³¸ ë ˆì´ì–´ ì •ë³´\n","#             if hasattr(module, 'in_features'):\n","#                 print(f\"  Input features: {module.in_features}\")\n","#             if hasattr(module, 'out_features'):\n","#                 print(f\"  Output features: {module.out_features}\")\n","\n","# # ê¸°ë³¸ ëª¨ë¸ ì •ë³´ ì¶œë ¥\n","# print(\"=== Model Information ===\")\n","# print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n","# print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n","\n","# # ëª¨ë¸ êµ¬ì¡° ì¶œë ¥\n","# print(\"\\n=== Model Structure ===\")\n","# print_model_structure(model)\n","\n","# # LoRA ë ˆì´ì–´ ë¶„ì„\n","# analyze_lora_layers(model)"],"metadata":{"id":"yM2A5uovEjOu","executionInfo":{"status":"ok","timestamp":1733829138419,"user_tz":-540,"elapsed":2,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Adding Attention Layer"],"metadata":{"id":"EVIfLoMMGi5h"}},{"cell_type":"code","source":["# import torch\n","# from torch import nn\n","# import math\n","\n","# class CustomAttention(nn.Module):\n","#     def __init__(self, config):\n","#         super().__init__()\n","#         self.hidden_size = config.hidden_size\n","#         self.num_heads = config.num_attention_heads\n","#         self.head_dim = config.hidden_size // config.num_attention_heads\n","#         self.scaling = self.head_dim ** -0.5\n","\n","#         # ì£¼ìš” í”„ë¡œì ì…˜ ë ˆì´ì–´ë“¤\n","#         self.q_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","#         self.k_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","#         self.v_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","#         self.o_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","\n","#         self.rotary_emb = model.base_model.model.model.layers[0].self_attn.rotary_emb\n","\n","#     def forward(self, hidden_states, attention_mask=None, position_ids=None):\n","#         batch_size, seq_length, _ = hidden_states.shape\n","\n","#         # í”„ë¡œì ì…˜ ìˆ˜í–‰\n","#         query_states = self.q_proj(hidden_states)\n","#         key_states = self.k_proj(hidden_states)\n","#         value_states = self.v_proj(hidden_states)\n","\n","#         # í—¤ë“œ ì°¨ì›ìœ¼ë¡œ ì¬êµ¬ì„±\n","#         query_states = query_states.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n","#         key_states = key_states.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n","#         value_states = value_states.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","#         # RoPE (Rotary Position Embedding) ì ìš©\n","#         query_states, key_states = self.rotary_emb(query_states, key_states, position_ids)\n","\n","#         # Attention ê³„ì‚°\n","#         attention_scores = torch.matmul(query_states, key_states.transpose(2, 3)) * self.scaling\n","\n","#         if attention_mask is not None:\n","#             attention_scores = attention_scores + attention_mask\n","\n","#         attention_probs = torch.softmax(attention_scores, dim=-1)\n","\n","#         # Valueì™€ ê²°í•©í•˜ì—¬ ìµœì¢… ì¶œë ¥ ê³„ì‚°\n","#         hidden_states = torch.matmul(attention_probs, value_states)\n","#         hidden_states = hidden_states.transpose(1, 2).contiguous()\n","#         hidden_states = hidden_states.view(batch_size, seq_length, self.hidden_size)\n","\n","#         # ìµœì¢… í”„ë¡œì ì…˜\n","#         hidden_states = self.o_proj(hidden_states)\n","\n","#         return hidden_states\n","\n","# def add_attention_layer(model):\n","#     \"\"\"\n","#     ëª¨ë¸ì˜ ì•ë¶€ë¶„ì— ìƒˆë¡œìš´ attention layerë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n","#     \"\"\"\n","#     config = model.base_model.model.model.config\n","#     new_attention = CustomAttention(config)\n","\n","#     # ëª¨ë¸ì˜ ê¸°ì¡´ ë ˆì´ì–´ë“¤ì„ ì„ì‹œ ì €ì¥\n","#     original_layers = model.base_model.model.model.layers\n","\n","#     # ìƒˆë¡œìš´ ModuleList ìƒì„±\n","#     new_layers = nn.ModuleList([new_attention])\n","#     new_layers.extend(original_layers)\n","\n","#     # ëª¨ë¸ì˜ layersë¥¼ ìƒˆë¡œìš´ ModuleListë¡œ êµì²´\n","#     model.base_model.model.model.layers = new_layers\n","\n","#     return model\n","\n","# # ì‚¬ìš© ì˜ˆì‹œ:\n","# # model = add_attention_layer(model)"],"metadata":{"id":"6LrH1q3sGh_9","executionInfo":{"status":"ok","timestamp":1733829138420,"user_tz":-540,"elapsed":3,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# 2. Dataset Preprocessing"],"metadata":{"id":"ujY0eRdvE_RA"}},{"cell_type":"code","source":["# Google Drive ë§ˆìš´íŠ¸\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wWFxD1X865v","executionInfo":{"status":"ok","timestamp":1733753314764,"user_tz":-540,"elapsed":30812,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"176e7cff-e87a-4c3e-f96e-889bd330b04f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import random\n","import nltk\n","from datasets import Dataset, DatasetDict\n","from nltk.corpus import wordnet\n","\n","EOS_TOKEN = tokenizer.eos_token # do not forget this part!\n","\n","# Download required NLTK data\n","nltk.download('wordnet')\n","\n","def clean_text(text):\n","    \"\"\"Clean vertically split text if present\"\"\"\n","    if isinstance(text, list):\n","        text = '\\n'.join(text)\n","    if '\\n' in text and all(len(line.strip()) == 1 for line in text.split('\\n') if line.strip()):\n","        return ''.join(c for c in text if not c.isspace())\n","    return text\n","\n","def get_synonyms(word):\n","    \"\"\"Get list of synonyms for a word using WordNet\"\"\"\n","    synonyms = []\n","    for syn in wordnet.synsets(word):\n","        for lemma in syn.lemmas():\n","            if lemma.name() != word:\n","                synonyms.append(lemma.name())\n","    return list(set(synonyms))\n","\n","def augment_scene(scene):\n","    \"\"\"Augment scene text by replacing words with synonyms\"\"\"\n","    words = scene.split()\n","    augmented = []\n","    for word in words:\n","        if random.random() < 0.1:  # 10% probability of synonym replacement\n","            synonyms = get_synonyms(word)\n","            if synonyms:\n","                augmented.append(random.choice(synonyms))\n","            else:\n","                augmented.append(word)\n","        else:\n","            augmented.append(word)\n","    return \" \".join(augmented)\n","\n","def create_context(session_data, p_scene=0.8, p_attr=0.7, p_relations=0.6):\n","    \"\"\"Create context with probabilistic inclusion of different components\"\"\"\n","    context = \"\"\n","\n","    if random.random() < p_scene:\n","        context += f\"Scene:\\n{clean_text(session_data['scene'])}\\n\\n\"\n","\n","    if random.random() < p_attr:\n","        context += \"Character Information:\\n\"\n","        for speaker in session_data[\"speakers\"]:\n","            if speaker in session_data[\"attributes\"]:\n","                attrs = session_data[\"attributes\"][speaker]\n","                selected_attrs = random.sample(list(attrs.items()),\n","                                            k=random.randint(2, len(attrs)))\n","                context += f\"{speaker}:\\n\"\n","                for key, value in selected_attrs:\n","                    if value and value != \"None\":\n","                        context += f\"- {key}: {value}\\n\"\n","\n","    if random.random() < p_relations:\n","        relations = session_data.get(\"relations with Harry\", {})\n","        if relations:\n","            context += \"\\nRelations:\\n\"\n","            for person, rel in relations.items():\n","                selected_rels = random.sample(list(rel.items()),\n","                                           k=random.randint(1, len(rel)))\n","                for key, value in selected_rels:\n","                    if isinstance(value, (int, float)) and value != 0:\n","                        context += f\"{person} - {key}: {value}\\n\"\n","\n","    return context\n","\n","def create_dialogue_variations(dialogues, max_history=3):\n","    \"\"\"Create variations of dialogue history\"\"\"\n","    examples = []\n","    for i in range(len(dialogues) - 1):\n","        history_length = random.randint(1, min(i+1, max_history))\n","        selected_history = dialogues[max(0, i-history_length+1):i+1]\n","\n","        example = {\n","            \"previous_dialogue\": \"\\n\".join(selected_history),\n","            \"next_dialogue\": dialogues[i + 1]\n","        }\n","        examples.append(example)\n","    return examples\n","\n","def create_augmented_examples(session_data):\n","    \"\"\"Create augmented examples from session data\"\"\"\n","    examples = []\n","    base_dialogues = session_data[\"dialogue\"]\n","\n","    for _ in range(3):  # Create 3 variations per session\n","        context = create_context(session_data)\n","        augmented_scene = augment_scene(clean_text(session_data[\"scene\"]))\n","        dialogue_variations = create_dialogue_variations(base_dialogues)\n","\n","        for variation in dialogue_variations:\n","            example = {\n","                \"instruction\": f\"Given the following context and previous dialogue, \"\n","                             f\"generate the next line of dialogue:\",\n","                \"input\": context + \"\\nScene:\\n\" + augmented_scene +\n","                        \"\\n\\nPrevious Dialogue:\\n\" + variation[\"previous_dialogue\"],\n","                \"output\": variation[\"next_dialogue\"]\n","            }\n","            examples.append(example)\n","\n","    return examples\n","\n","def convert_to_alpaca(json_data):\n","    \"\"\"Convert dataset to Alpaca format with augmentation\"\"\"\n","    alpaca_data = []\n","\n","    if isinstance(json_data, dict):\n","        for session_key, session_data in json_data.items():\n","            session_examples = create_augmented_examples(session_data)\n","            alpaca_data.extend(session_examples)\n","    elif isinstance(json_data, list):\n","        for session_data in json_data:\n","            session_examples = create_augmented_examples(session_data)\n","            alpaca_data.extend(session_examples)\n","\n","    return alpaca_data\n","\n","def formatting_prompts_func(examples):\n","    \"\"\"Format examples in Alpaca prompt style\"\"\"\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","    instructions = examples[\"instruction\"]\n","    inputs = examples[\"input\"]\n","    outputs = examples[\"output\"]\n","    texts = []\n","\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","\n","    return {\"text\": texts}\n","\n","# Main execution\n","def process_dataset(train_path, test_path, output_train_path, output_test_path, formatted_dataset_path):\n","    # Process training data\n","    print(f\"Processing training data from: {train_path}\")\n","    with open(train_path, 'r', encoding='utf-8') as f:\n","        train_data = json.load(f)\n","    train_formatted = convert_to_alpaca(train_data)\n","\n","    # Process test data\n","    print(f\"Processing test data from: {test_path}\")\n","    with open(test_path, 'r', encoding='utf-8') as f:\n","        test_data = json.load(f)\n","    test_formatted = convert_to_alpaca(test_data)\n","\n","    # Save intermediate results\n","    print(f\"Saving training data to: {output_train_path}\")\n","    with open(output_train_path, 'w', encoding='utf-8') as f:\n","        json.dump(train_formatted, f, ensure_ascii=False, indent=2)\n","\n","    print(f\"Saving test data to: {output_test_path}\")\n","    with open(output_test_path, 'w', encoding='utf-8') as f:\n","        json.dump(test_formatted, f, ensure_ascii=False, indent=2)\n","\n","    # Create and save formatted dataset\n","    dataset = DatasetDict({\n","        'train': Dataset.from_list(train_formatted),\n","        'test': Dataset.from_list(test_formatted)\n","    })\n","\n","    formatted_dataset = dataset.map(\n","        formatting_prompts_func,\n","        batched=True,\n","        remove_columns=dataset['train'].column_names\n","    )\n","\n","    # Remove existing directory if it exists\n","    if os.path.exists(formatted_dataset_path):\n","        shutil.rmtree(formatted_dataset_path)\n","\n","    # Save formatted dataset\n","    formatted_dataset.save_to_disk(formatted_dataset_path)\n","\n","    print(f\"Augmented dataset conversion complete! Training entries: {len(train_formatted)}, Test entries: {len(test_formatted)}\")\n","\n","    return formatted_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTJZRBUSyK4T","executionInfo":{"status":"ok","timestamp":1733824438435,"user_tz":-540,"elapsed":1260,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"1aa53ab7-92fc-4d6e-ae08-dd156a0dde58"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["# File paths\n","train_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Dialogue Dataset/en_train_set.json'\n","test_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Dialogue Dataset/en_test_set.json'\n","output_train_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_train_set.json'\n","output_test_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_test_set.json'\n","formatted_dataset_path = '/content/drive/MyDrive/Colab Notebooks/ë”¥ëŸ¬ë‹ í”„ë¡œì íŠ¸/Dataset Station/Harry Potter Alpaca/hpa_formatted_dataset'\n","\n","# Process the dataset\n","formatted_dataset = process_dataset(\n","    train_path,\n","    test_path,\n","    output_train_path,\n","    output_test_path,\n","    formatted_dataset_path\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["52f9b70227734735a77025b1547a4f7f","e18f78b0a6c04c8db654ad8abf40856c","13abce7bc961407b80aef01ca37e0fff","6afd34f975714df989c95557bb172114","ea30410ff5b94e36aa7f1ae04c2041cb","b8e19f6a2b594e67890184c887173466","fd8bbe23de63456086beba03a3eb7015","cba5291efb80400f8528a5a049bb7a31","6ad660d0f04d4c90a435e222d5a93436","4246cf13026447c0b60a5c33dacf1b1a","96d4081338c04ec19db1142e9b8557b1","c420788c75cb4df0b73057c1f99fc2f7","32cce8257910411381ae107f1b272f87","c7f97e1a812c419d814d63ce35342af3","991589b50c8c4cb8b3228397fe25fc42","4f49199d63f7407ca0a9f00fedb6ca69","7c09c77a34ae4daba634d6f0922c42e3","9881d8fac75446fbbadb75103be04060","eb0db9321a3043e98581240e0b446418","643e63457df14b85a3f96185eb68f849","8e5d1fac31c1477cac1c32a694e7efdf","900a48c9a1fc4dcfa5aa980185b6e4d5","a4e87718aa47491eb9f69a420836f207","004f69c8123f445898206cfb4d15ded8","0c9cda1d48dc4561b6671b3408a3c375","4c3c24727a11472582b3119597c24341","926e06cf281e40549fb1db6ab51a80e0","e4f6744cca874f36be142f33c570e79f","87427d5afa494ad58ddb676da98aadd1","9b1d303c7b8e40299675942ca6e8ad6e","b1b441a11f4c43e89a61e4ee94784664","be3ac3e413f441ae8f446eba8b453934","570a8e8476554129bf9f2b4545f4b648","65ed847eec544f8dbb809936aa6cbd69","6f96ff44f96a44bcb75b11cafb9d268d","c27891e91cb949608bd0e1eef0f1efc8","767002e4ac14423a96a07459745f730c","00b36f1496b74c0a8ff0ce1709256745","7f3fd149169248f7a087ec9b18a34ad3","1f5f8eebe3b94eb9aa8f6b9578291686","849df78437854f358bc43511beb4ec89","7d0ff024983d456781895bccb2debbc7","d827420671ac4e14af3fb8d7d106c50b","7627743dd5bb4ecb84856bdb54482592"]},"id":"N4sMYQflyS3I","executionInfo":{"status":"ok","timestamp":1733824500680,"user_tz":-540,"elapsed":58175,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"6ecddaee-e3ff-4180-9f4c-60411b00f5e7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing training data from: /content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Dialogue Dataset/en_train_set.json\n","Processing test data from: /content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Dialogue Dataset/en_test_set.json\n","Saving training data to: /content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_train_set.json\n","Saving test data to: /content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_test_set.json\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/44166 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52f9b70227734735a77025b1547a4f7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2601 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c420788c75cb4df0b73057c1f99fc2f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/2 shards):   0%|          | 0/44166 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e87718aa47491eb9f69a420836f207"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/2601 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65ed847eec544f8dbb809936aa6cbd69"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Augmented dataset conversion complete! Training entries: 44166, Test entries: 2601\n"]}]},{"cell_type":"code","source":["print(formatted_dataset[\"train\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mD8icmtuzY6s","executionInfo":{"status":"ok","timestamp":1733824505861,"user_tz":-540,"elapsed":297,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"c3668558-bcb6-4378-88ae-7c0ee685c43f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","â€œUp! Get up! Now!â€\n","Harry woke with a start. His aunt rapped on the door again.\n","â€œUp!â€ she screeched. Harry heard her walking toward the kitchen and then the sound of the frying pan being put on the stove. He rolled onto his back and tried to remember the dream he had been having. It had been a good one. There had been a flying motorcycle in it. He had a funny feeling heâ€™d had the same dream before.\n","His aunt was back outside the door.\n","â€œAre you up yet?â€ she demanded.\n","â€œNearly,â€ said Harry.\n","â€œWell, get a move on, I want you to look after the bacon. And donâ€™t you dare let it burn, I want everything perfect on Duddyâ€™s birthday.â€\n","Harry groaned.\n","â€œWhat did you say?â€ his aunt snapped through the door.\n","â€œNothing, nothing . . .â€\n","\n","Character Information:\n","Petunia:\n","- character: Message, gossip\n","- looks: Slender, blond hair, long neck\n","- age: Adult\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","- name: Harry\n","- gender: male\n","- age: age 11\n","- title: The boy who lived\n","\n","Relations:\n","Petunia - family: 1.0\n","\n","Scene:\n","â€œUp! Get up! Now!â€ Harry woke with a start. His aunt rapped on the threshold again. â€œUp!â€ she screeched. Harry heard her walk toward the kitchen and then the phone of the frying pan being put on the stove. He rolled onto his back and tried to remember the dream he had been having. It had been a good one. There had been a flying motorcycle in it. He had a funny feeling heâ€™d had the same dream before. His aunt was back outside the door. â€œAre you up yet?â€ she demanded. â€œNearly,â€ said Harry. â€œWell, get a move on, I want you to look after the bacon. And donâ€™t you dare let it burn, I want everything perfect on Duddyâ€™s birthday.â€ Harry groaned. â€œWhat did you say?â€ his aunt snapped through the door. â€œNothing, nothing . . .â€\n","\n","Previous Dialogue:\n","Petunia: Up! Get up! Now! Up! Up! Are you up yet?\n","\n","### Response:\n","Harry: Nearly,<|end_of_text|>\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"-03B9tJm8RWF"}},{"cell_type":"markdown","source":["# 3. Fine-Tuning the Model"],"metadata":{"id":"EsMAQHLEG99c"}},{"cell_type":"code","source":["import json\n","\n","output_train_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_train_set.json'\n","output_test_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_test_set.json'\n","formatted_dataset_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_formatted_dataset'\n","\n","with open(output_train_path, 'r', encoding='utf-8') as f:\n","    train_data = json.load(f)\n","\n","with open(output_test_path, 'r', encoding='utf-8') as f:\n","    test_data = json.load(f)\n","\n","# ë‚˜ì¤‘ì— ë°ì´í„°ì…‹ì„ ë‹¤ì‹œ ë¡œë“œí•  ë•ŒëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n","from datasets import load_from_disk\n","formatted_dataset = load_from_disk(formatted_dataset_path)"],"metadata":{"id":"v3wvyYHl610r","executionInfo":{"status":"ok","timestamp":1733829261088,"user_tz":-540,"elapsed":13090,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# from trl import SFTTrainer\n","# from transformers import TrainingArguments\n","# from datasets import Dataset\n","\n","# # Training Arguments ì„¤ì •\n","# training_args = TrainingArguments(\n","#     per_device_train_batch_size=2,\n","#     per_device_eval_batch_size=2,  # í‰ê°€ë¥¼ ìœ„í•œ batch size ì¶”ê°€\n","#     gradient_accumulation_steps=4,\n","#     warmup_steps=10,\n","#     max_steps=100, # increase this to make the model learn \"better\"\n","#     learning_rate=2e-4,\n","#     fp16=not torch.cuda.is_bf16_supported(),\n","#     bf16=torch.cuda.is_bf16_supported(),\n","#     logging_steps=1,\n","#     optim=\"adamw_8bit\",\n","#     weight_decay=0.01,\n","#     lr_scheduler_type=\"linear\",\n","#     seed=3407,\n","#     output_dir=\"outputs\",\n","#     # í‰ê°€ ê´€ë ¨ ì„¤ì • ì¶”ê°€\n","#     evaluation_strategy=\"steps\",    # \"steps\" ë˜ëŠ” \"epoch\"\n","#     eval_steps=20,                 # 20 ìŠ¤í…ë§ˆë‹¤ í‰ê°€\n","#     save_strategy=\"steps\",\n","#     save_steps=20,                 # 20 ìŠ¤í…ë§ˆë‹¤ ëª¨ë¸ ì €ì¥\n","#     save_total_limit=3,           # ìµœëŒ€ 3ê°œì˜ ì²´í¬í¬ì¸íŠ¸ë§Œ ì €ì¥\n","#     load_best_model_at_end=True,  # í•™ìŠµ ì™„ë£Œ í›„ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ë¡œë“œ\n","#     metric_for_best_model=\"eval_loss\",  # ì–´ë–¤ ë©”íŠ¸ë¦­ìœ¼ë¡œ best modelì„ ê²°ì •í• ì§€\n","# )\n","\n","# # train ë°ì´í„°ì…‹ë§Œ ê°€ì ¸ì™€ì„œ ë¶„í• \n","# train_eval_dataset = formatted_dataset['train']\n","\n","# # train_test_splitìœ¼ë¡œ ë¶„í•  (ì˜ˆ: 80% train, 20% evaluation)\n","# split_dataset = train_eval_dataset.train_test_split(\n","#     test_size=0.2,  # 20%ë¥¼ evaluation setìœ¼ë¡œ ì‚¬ìš©\n","#     shuffle=True,   # ë°ì´í„° ì„ê¸°\n","#     seed=3407      # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •\n","# )\n","\n","# # Trainer ì„¤ì •\n","# trainer = SFTTrainer(\n","#     model=model,\n","#     tokenizer=tokenizer,\n","#     train_dataset=split_dataset['train'],      # ë¶„í• ëœ train set\n","#     eval_dataset=split_dataset['test'],        # ë¶„í• ëœ evaluation set\n","#     dataset_text_field=\"text\",\n","#     max_seq_length=max_seq_length,\n","#     dataset_num_proc=2,\n","#     packing=False,\n","#     args=training_args,\n","# )\n","\n","\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from datasets import Dataset\n","\n","# ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ ë” ì‘ì€ í‰ê°€ ì„¸íŠ¸ë¥¼ ë§Œë“¦\n","train_eval_dataset = formatted_dataset['train']\n","split_dataset = train_eval_dataset.train_test_split(\n","    test_size=0.2,\n","    shuffle=True,\n","    seed=3407\n",")\n","\n","# í‰ê°€ ë°ì´í„°ì…‹ì˜ í¬ê¸°ë¥¼ ì œí•œ\n","max_eval_samples = 500  # í‰ê°€ì— ì‚¬ìš©í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜\n","eval_dataset = split_dataset['test'].select(range(min(len(split_dataset['test']), max_eval_samples)))\n","\n","# Training Arguments ì„¤ì •\n","training_args = TrainingArguments(\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=4,  # í‰ê°€ ë°°ì¹˜ í¬ê¸°ë¥¼ ë” í¬ê²Œ ì„¤ì •\n","    gradient_accumulation_steps=4,\n","    warmup_steps=10,\n","    max_steps=100,\n","    learning_rate=2e-4,\n","    fp16=not torch.cuda.is_bf16_supported(),\n","    bf16=torch.cuda.is_bf16_supported(),\n","    logging_steps=1,\n","    optim=\"adamw_8bit\",\n","    weight_decay=0.01,\n","    lr_scheduler_type=\"linear\",\n","    seed=3407,\n","    output_dir=\"outputs\",\n","    # í‰ê°€ ê´€ë ¨ ì„¤ì • ìˆ˜ì •\n","    evaluation_strategy=\"steps\",\n","    eval_steps=50,  # í‰ê°€ ë¹ˆë„ë¥¼ ì¤„ì„ (20 -> 50)\n","    save_strategy=\"steps\",\n","    save_steps=50,  # ì €ì¥ ë¹ˆë„ë„ í•¨ê»˜ ì¡°ì •\n","    save_total_limit=3,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n",")\n","\n","# Trainer ì„¤ì •\n","trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=split_dataset['train'],\n","    eval_dataset=eval_dataset,  # í¬ê¸°ê°€ ì œí•œëœ í‰ê°€ ë°ì´í„°ì…‹ ì‚¬ìš©\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    dataset_num_proc=2,\n","    packing=False,\n","    args=training_args,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161,"referenced_widgets":["c6a97c45088c4a058ecf4d3eaf9f09f9","2072faa03a0b4e729f8d7cc1957d0e5b","eed68d78d3eb4c9eb01e0b9d27dd962d","d875c797d8244582bbbc300da7f9de28","0a4addfb1c7a4bc2a11703600d30da49","589182e5255b412f9deb87c7b49c8a8a","57dd050c574a48f09e9dccf912136f9e","cb9af07731e24ea288a365a03f703802","f7ebb0bee0b147b494a29e1acf792845","7d7ee6c126ad4dd5b0a8a814960170e9","670338d4087a44bcbe6430720e070236"]},"id":"vE7hGJT233zo","executionInfo":{"status":"ok","timestamp":1733829268032,"user_tz":-540,"elapsed":6946,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"f023893b-60c5-47fd-8969-ff488cc3661a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6a97c45088c4a058ecf4d3eaf9f09f9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2ejIt2xSNKKp","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1733826447130,"user_tz":-540,"elapsed":303,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"a4cb2260-846a-4be0-c45b-6e1017234ad0"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","5.605 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yqxqAZ7KJ4oL"},"outputs":[],"source":["# # We're now kicking off the actual training of our model, which will spit out some statistics showing us how well it learns\n","# trainer_stats = trainer.train()"]},{"cell_type":"code","source":["# í•™ìŠµ ì‹œì‘\n","trainer_stats = trainer.train()\n","\n","# í•™ìŠµ ì™„ë£Œ í›„ í‰ê°€\n","eval_results = trainer.evaluate()\n","print(f\"Evaluation results: {eval_results}\")\n","\n","# ëª¨ë¸ ì €ì¥\n","trainer.save_model(\"final_model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"ggfK-XeYQtlk","outputId":"98dc12a4-79ab-466b-e4d0-31c33dfae304","executionInfo":{"status":"ok","timestamp":1733837457915,"user_tz":-540,"elapsed":8181471,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 35,332 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 100\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moverjoy1008\u001b[0m (\u001b[33moverjoy1008-korea-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241210_111606-db2muveo</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/overjoy1008-korea-university/huggingface/runs/db2muveo' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/overjoy1008-korea-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/overjoy1008-korea-university/huggingface' target=\"_blank\">https://wandb.ai/overjoy1008-korea-university/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/overjoy1008-korea-university/huggingface/runs/db2muveo' target=\"_blank\">https://wandb.ai/overjoy1008-korea-university/huggingface/runs/db2muveo</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [100/100 1:58:25, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.456200</td>\n","      <td>1.366200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.239500</td>\n","      <td>1.282975</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [125/125 16:45]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation results: {'eval_loss': 1.2829750776290894, 'eval_runtime': 1013.767, 'eval_samples_per_second': 0.493, 'eval_steps_per_second': 0.123, 'epoch': 0.022642363862787274}\n"]}]},{"cell_type":"code","source":["# model.save_pretrained(\"lora_model\") # Local saving\n","model.push_to_hub(\"Overjoy1008/harry_potter_llama3_lora_100\", token = \"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\") # Online saving"],"metadata":{"id":"tYeObsv4O9IF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#4. Prompt Tuning"],"metadata":{"id":"19q-EXk6FCbA"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, PreTrainedModel, TrainingArguments\n","from trl import SFTTrainer\n","import torch\n","import torch.nn as nn\n","from dataclasses import dataclass\n","from typing import Optional, Tuple\n","from transformers.trainer_utils import get_last_checkpoint\n","import os\n","\n","# train ë°ì´í„°ì…‹ë§Œ ê°€ì ¸ì™€ì„œ ë¶„í• \n","train_eval_dataset = formatted_dataset['train']\n","\n","# train_test_splitìœ¼ë¡œ ë¶„í•  (ì˜ˆ: 80% train, 20% evaluation)\n","split_dataset = train_eval_dataset.train_test_split(\n","    test_size=0.2,  # 20%ë¥¼ evaluation setìœ¼ë¡œ ì‚¬ìš©\n","    shuffle=True,   # ë°ì´í„° ì„ê¸°\n","    seed=3407      # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",")\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","@dataclass\n","class PromptTuningConfig:\n","    num_virtual_tokens: int = 20\n","    initialization_method: str = \"random\"\n","    prompt_tuning_init_text: Optional[str] = None\n","\n","class PromptEmbedding(nn.Module):\n","    def __init__(self, config: PromptTuningConfig, model: PreTrainedModel, tokenizer: AutoTokenizer):\n","        super().__init__()\n","        self.config = config\n","        self.embedding_dim = model.config.hidden_size\n","        self.device = next(model.parameters()).device\n","\n","        # Get the base LlamaModel\n","        llama_model = model\n","        while not hasattr(llama_model, 'embed_tokens'):\n","            if hasattr(llama_model, 'base_model'):\n","                llama_model = llama_model.base_model\n","            else:\n","                raise AttributeError(\"Could not find embed_tokens in model\")\n","\n","        self.llama_model = llama_model\n","\n","        if config.initialization_method == \"random\":\n","            self.prompt_embeddings = nn.Parameter(\n","                torch.randn(config.num_virtual_tokens, self.embedding_dim).to(self.device)\n","            )\n","        elif config.initialization_method == \"vocabulary\":\n","            init_text = config.prompt_tuning_init_text\n","            if init_text is None:\n","                init_text = \"This is a story about Harry Potter:\"\n","\n","            tokens = tokenizer(init_text, return_tensors=\"pt\").input_ids.to(self.device)\n","            token_embeddings = self.llama_model.embed_tokens(tokens)\n","\n","            if token_embeddings.size(1) > config.num_virtual_tokens:\n","                self.prompt_embeddings = nn.Parameter(\n","                    token_embeddings[0, :config.num_virtual_tokens, :]\n","                )\n","            else:\n","                padding = torch.randn(\n","                    config.num_virtual_tokens - token_embeddings.size(1),\n","                    self.embedding_dim,\n","                    device=self.device\n","                )\n","                self.prompt_embeddings = nn.Parameter(\n","                    torch.cat([token_embeddings[0], padding], dim=0)\n","                )\n","\n","    def forward(self, batch_size: int):\n","        return self.prompt_embeddings.repeat(batch_size, 1, 1)\n","\n","class PromptTunedModel(nn.Module):\n","    def __init__(self, base_model: PreTrainedModel, prompt_embedding: PromptEmbedding):\n","        super().__init__()\n","        self.base_model = base_model\n","        self.prompt_embedding = prompt_embedding\n","        self.config = base_model.config\n","\n","        # Freeze base model parameters\n","        for param in self.base_model.parameters():\n","            param.requires_grad = False\n","\n","        self.device = next(base_model.parameters()).device\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None, inputs_embeds=None, **kwargs):\n","        # Handle input embeddings\n","        if input_ids is not None and inputs_embeds is None:\n","            input_ids = input_ids.to(self.device)\n","            batch_size = input_ids.size(0)\n","            prompt_embeds = self.prompt_embedding(batch_size)\n","            inputs_embeds = self.prompt_embedding.llama_model.embed_tokens(input_ids)\n","            combined_embeds = torch.cat([prompt_embeds, inputs_embeds], dim=1)\n","        elif inputs_embeds is not None:\n","            combined_embeds = inputs_embeds\n","            batch_size = inputs_embeds.size(0)\n","        else:\n","            raise ValueError(\"Either input_ids or inputs_embeds should be provided\")\n","\n","        # Handle attention mask\n","        if attention_mask is not None:\n","            attention_mask = attention_mask.to(self.device)\n","            prompt_attention_mask = torch.ones(\n","                batch_size,\n","                self.prompt_embedding.config.num_virtual_tokens,\n","                device=self.device\n","            )\n","            combined_attention_mask = torch.cat(\n","                [prompt_attention_mask, attention_mask], dim=1\n","            )\n","        else:\n","            combined_attention_mask = None\n","\n","        # Handle labels by adding padding for prompt tokens\n","        if labels is not None:\n","            labels = labels.to(self.device)\n","            # Create padding labels for the prompt tokens (using -100 to ignore in loss calculation)\n","            prompt_labels = torch.full(\n","                (batch_size, self.prompt_embedding.config.num_virtual_tokens),\n","                -100,\n","                device=self.device,\n","                dtype=labels.dtype\n","            )\n","            # Concatenate the padding labels with the actual labels\n","            labels = torch.cat([prompt_labels, labels], dim=1)\n","\n","        # Forward all arguments to the base model\n","        model_kwargs = {\n","            'inputs_embeds': combined_embeds,\n","            'attention_mask': combined_attention_mask,\n","            'labels': labels,\n","            **kwargs  # Pass through any additional kwargs\n","        }\n","\n","        # Remove None values\n","        model_kwargs = {k: v for k, v in model_kwargs.items() if v is not None}\n","\n","        outputs = self.base_model(**model_kwargs)\n","\n","        return outputs\n","\n","    def get_input_embeddings(self):\n","        \"\"\"Return the base model's input embeddings layer\"\"\"\n","        return self.prompt_embedding.llama_model.embed_tokens\n","\n","    def set_input_embeddings(self, value):\n","        \"\"\"Set the base model's input embeddings layer\"\"\"\n","        self.prompt_embedding.llama_model.embed_tokens = value\n","\n","    def get_output_embeddings(self):\n","        \"\"\"Return the base model's output embeddings layer\"\"\"\n","        return self.base_model.get_output_embeddings()\n","\n","    def prepare_inputs_for_generation(self, *args, **kwargs):\n","        \"\"\"Prepare inputs for generation\"\"\"\n","        return self.base_model.prepare_inputs_for_generation(*args, **kwargs)\n","\n","# ëª¨ë¸ ì„¤ì •\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","prompt_config = PromptTuningConfig(\n","    num_virtual_tokens=20,\n","    initialization_method=\"vocabulary\",\n","    prompt_tuning_init_text=\"This is a story about Harry Potter:\"\n",")\n","\n","prompt_embedding = PromptEmbedding(prompt_config, model, tokenizer)\n","prompt_tuned_model = PromptTunedModel(model, prompt_embedding)\n","prompt_tuned_model = prompt_tuned_model.to(device)\n","\n","# Training Arguments ì„¤ì •\n","training_args = TrainingArguments(\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    warmup_steps=10,\n","    max_steps=100,\n","    learning_rate=1e-3,\n","    fp16=not torch.cuda.is_bf16_supported(),\n","    bf16=torch.cuda.is_bf16_supported(),\n","    logging_steps=1,\n","    optim=\"adamw_8bit\",\n","    weight_decay=0.00,\n","    lr_scheduler_type=\"linear\",\n","    seed=3407,\n","    output_dir=\"prompt_tuning_outputs\",\n","    evaluation_strategy=\"steps\",\n","    eval_steps=50,\n","    save_strategy=\"steps\",\n","    save_steps=50,\n","    save_total_limit=3,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n",")\n","\n","# Trainer ì„¤ì •\n","trainer = SFTTrainer(\n","    model=prompt_tuned_model,\n","    tokenizer=tokenizer,\n","    train_dataset=split_dataset['train'],\n","    eval_dataset=split_dataset['test'],\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    dataset_num_proc=2,\n","    packing=False,\n","    args=training_args,\n",")\n","\n","# í•™ìŠµ ì‹œì‘\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"BgtOkI3YUFbJ","outputId":"7a14d9d0-8509-4232-cc4f-b91e4f09baa8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n","==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 35,332 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 100\n"," \"-____-\"     Number of trainable parameters = 81,920\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='51' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 51/100 41:13 < 41:13, 0.02 it/s, Epoch 0.01/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='178' max='2209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 178/2209 23:46 < 4:32:49, 0.12 it/s]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["# ëª¨ë¸ êµ¬ì¡° ë” ìì„¸íˆ í™•ì¸\n","print(\"\\nDetailed model inspection:\")\n","model_to_check = model.base_model.base_model\n","print(f\"Type: {type(model_to_check)}\")\n","print(f\"Available attributes: {dir(model_to_check)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WWYZsh4OWPIx","executionInfo":{"status":"ok","timestamp":1733830442667,"user_tz":-540,"elapsed":486,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"dd0197fd-d2f7-42be-ffa4-f5a61c90fb92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Detailed model inspection:\n","Type: <class 'transformers.models.llama.modeling_llama.LlamaModel'>\n","Available attributes: ['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_assisted_decoding', '_auto_class', '_autoset_attn_implementation', '_backward_compatibility_gradient_checkpointing', '_backward_hooks', '_backward_pre_hooks', '_beam_search', '_buffers', '_call_impl', '_check_and_enable_flash_attn_2', '_check_and_enable_sdpa', '_compiled_call_impl', '_constrained_beam_search', '_contrastive_search', '_convert_head_mask_to_5d', '_copy_lm_head_original_to_resized', '_create_repo', '_dispatch_accelerate_model', '_dola_decoding', '_expand_inputs_for_generation', '_extract_past_from_model_output', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_from_config', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_cache', '_get_candidate_generator', '_get_files_timestamps', '_get_initial_cache_position', '_get_logits_processor', '_get_name', '_get_no_split_modules', '_get_resized_embeddings', '_get_resized_lm_head', '_get_stopping_criteria', '_gradient_checkpointing_func', '_group_beam_search', '_has_unfinished_sequences', '_hf_hook', '_hf_peft_config_loaded', '_hook_rss_memory_post_forward', '_hook_rss_memory_pre_forward', '_init_added_embeddings_weights_with_mean', '_init_added_lm_head_bias_with_mean', '_init_added_lm_head_weights_with_mean', '_init_weights', '_initialize_weights', '_is_full_backward_hook', '_is_hf_initialized', '_is_quantized_training_enabled', '_is_stateful', '_keep_in_fp32_modules', '_keep_in_fp32_modules', '_keys_to_ignore_on_load_missing', '_keys_to_ignore_on_load_unexpected', '_keys_to_ignore_on_save', '_load_from_state_dict', '_load_pretrained_model', '_load_pretrained_model_low_mem', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_initialize_input_ids_for_generation', '_maybe_warn_non_full_backward_hook', '_merge_criteria_processor_list', '_modules', '_named_members', '_no_split_modules', '_non_persistent_buffers_set', '_offloaded_gradient_checkpointing', '_old_forward', '_parameters', '_prepare_4d_causal_attention_mask_with_cache_position', '_prepare_attention_mask_for_generation', '_prepare_cache_for_generation', '_prepare_decoder_input_ids_for_generation', '_prepare_encoder_decoder_kwargs_for_generation', '_prepare_generated_length', '_prepare_generation_config', '_prepare_model_inputs', '_prepare_special_tokens', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_reorder_cache', '_replicate_for_data_parallel', '_resize_token_embeddings', '_sample', '_save_to_state_dict', '_saved_temp_tokenizer', '_set_default_torch_dtype', '_set_gradient_checkpointing', '_skip_keys_device_placement', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_supports_cache_class', '_supports_default_dynamic_cache', '_supports_flash_attn_2', '_supports_num_logits_to_keep', '_supports_quantized_cache', '_supports_sdpa', '_supports_static_cache', '_temporary_reorder_cache', '_tie_encoder_decoder_weights', '_tie_or_clone_weights', '_tied_weights_keys', '_update_causal_mask', '_update_model_kwargs_for_generation', '_upload_modified_files', '_validate_assistant', '_validate_generated_length', '_validate_model_class', '_validate_model_kwargs', '_version', '_wrapped_call_impl', 'active_adapter', 'active_adapters', 'add_adapter', 'add_memory_hooks', 'add_model_tags', 'add_module', 'apply', 'base_model', 'base_model_prefix', 'bfloat16', 'buffers', 'call_super_init', 'can_generate', 'children', 'compile', 'compute_transition_scores', 'config', 'config_class', 'cpu', 'create_extended_attention_mask_for_decoder', 'cuda', 'dequantize', 'device', 'disable_adapters', 'disable_input_require_grads', 'double', 'dtype', 'dummy_inputs', 'dump_patches', 'embed_tokens', 'enable_adapters', 'enable_input_require_grads', 'estimate_tokens', 'eval', 'extra_repr', 'float', 'floating_point_ops', 'forward', 'forward', 'framework', 'from_pretrained', 'generate', 'generation_config', 'get_adapter_state_dict', 'get_buffer', 'get_extended_attention_mask', 'get_extra_state', 'get_head_mask', 'get_input_embeddings', 'get_memory_footprint', 'get_output_embeddings', 'get_parameter', 'get_position_embeddings', 'get_submodule', 'gradient_checkpointing', 'gradient_checkpointing_disable', 'gradient_checkpointing_enable', 'half', 'heal_tokens', 'init_weights', 'invert_attention_mask', 'ipu', 'is_gradient_checkpointing', 'is_parallelizable', 'layers', 'load_adapter', 'load_state_dict', 'loss_function', 'main_input_name', 'max_seq_length', 'model_tags', 'model_tags', 'modules', 'mtia', 'name_or_path', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'norm', 'num_parameters', 'original_push_to_hub', 'padding_idx', 'parameters', 'post_init', 'prepare_inputs_for_generation', 'prune_heads', 'push_to_hub', 'push_to_hub', 'register_backward_hook', 'register_buffer', 'register_for_auto_class', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_memory_hooks_state', 'resize_position_embeddings', 'resize_token_embeddings', 'retrieve_modules_from_names', 'reverse_bettertransformer', 'rotary_emb', 'save_pretrained', 'set_adapter', 'set_extra_state', 'set_input_embeddings', 'set_submodule', 'share_memory', 'state_dict', 'supports_gradient_checkpointing', 'tie_weights', 'to', 'to_bettertransformer', 'to_empty', 'train', 'training', 'type', 'vocab_size', 'warn_if_padding_and_no_attention_mask', 'warnings_issued', 'xpu', 'zero_grad']\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCqnaKmlO1U9","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733759566493,"user_tz":-540,"elapsed":1044,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"49bca5ac-4a37-437f-8570-84b9de2e17e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["4770.1562 seconds used for training.\n","79.5 minutes used for training.\n","Peak reserved memory = 8.439 GB.\n","Peak reserved memory for training = 2.834 GB.\n","Peak reserved memory % of max memory = 57.221 %.\n","Peak reserved memory for training % of max memory = 19.216 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","source":["# 4. Using, Saving, Loading the LoRA Model"],"metadata":{"id":"kHDqv5fAHOLH"}},{"cell_type":"code","source":["if True:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model)"],"metadata":{"id":"4RTOq1w3vUrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Su6oHXy0vUtJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ì €ì¥í•  ê²½ë¡œ ì„¤ì •\n","save_directory = \"/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Harry Potter LoRA 100\"\n","\n","# ëª¨ë¸ ì €ì¥\n","model.save_pretrained(save_directory)\n","\n","# í† í¬ë‚˜ì´ì € ì €ì¥\n","tokenizer.save_pretrained(save_directory)\n","\n","# í•™ìŠµ ìƒíƒœ(config) ì €ì¥ - ì„ íƒì‚¬í•­\n","trainer.save_state()\n","\n","import os\n","print(\"ì €ì¥ëœ íŒŒì¼ë“¤:\")\n","for file in os.listdir(save_directory):\n","    print(f\"- {file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMBpyx8_KH-w","executionInfo":{"status":"ok","timestamp":1733837547883,"user_tz":-540,"elapsed":2306,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"c2a44553-eaa0-40f6-b4cf-4f70458cf877"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["ì €ì¥ëœ íŒŒì¼ë“¤:\n","- README.md\n","- adapter_model.safetensors\n","- adapter_config.json\n","- tokenizer_config.json\n","- special_tokens_map.json\n","- tokenizer.json\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# ì €ì¥ëœ ê²½ë¡œ\n","save_directory = \"/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Harry Potter LoRA\"\n","\n","# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n","model = AutoModelForCausalLM.from_pretrained(save_directory)\n","tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","\n","# GPUë¡œ ëª¨ë¸ ì´ë™ (if available)\n","model = model.to(\"cuda\")"],"metadata":{"id":"p6IaLVpQKeT1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!"],"metadata":{"id":"ekOmTR1hSNcr"}},{"cell_type":"markdown","source":[" You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"],"metadata":{"id":"CrSvZObor0lY"}},{"cell_type":"code","source":["test_cases = [\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Harry and Snape:\",\n","    \"input\": \"Scene:\\nThe dungeon was darker than usual, filled with weird-colored smoke from everyone's cauldrons. Snape's lip curled when he saw Harry's watery potion.\\n\\\"Potter, what is this supposed to be?\\\"\\n\\nCharacter Information:\\nSnape:\\n- name: Severus Snape\\n- title: Potions Master\\n- character: Sarcastic, strict, bitter\\n- affiliation: Hogwarts Professor\\n\\nHarry:\\n- name: Harry Potter\\n- age: 11\\n- affiliation: Gryffindor student\\n\\nPrevious Dialogue:\\nSnape: Potter, what is this supposed to be?\",\n","    \"expected_output\": \"Harry: The Draught of Living Death, sir.\"\n","  },\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Hermione and Ron:\",\n","    \"input\": \"Scene:\\nThe library was quiet except for the rustling of pages. Hermione was surrounded by a tower of books about House-elves' rights, while Ron looked on with disbelief.\\n\\\"Honestly, Hermione, they like working!\\\"\\n\\nCharacter Information:\\nHermione:\\n- name: Hermione Granger\\n- character: Passionate about justice, intelligent\\n- affiliation: S.P.E.W. founder\\n\\nRon:\\n- name: Ron Weasley\\n- character: Practical, sometimes insensitive\\n\\nPrevious Dialogue:\\nRon: Honestly, Hermione, they like working!\",\n","    \"expected_output\": \"Hermione: That's because they've been conditioned to accept their oppression, Ron!\"\n","  },\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Voldemort and Dumbledore:\",\n","    \"input\": \"Scene:\\nThe Ministry's Atrium was silent. Broken glass littered the floor from the magical battle. Voldemort and Dumbledore faced each other, wands raised.\\n\\\"You do not seek to kill me, Dumbledore?\\\"\\n\\nCharacter Information:\\nVoldemort:\\n- name: Lord Voldemort\\n- character: Ruthless, powerful, fears death\\n- affiliation: Dark Lord\\n\\nDumbledore:\\n- name: Albus Dumbledore\\n- character: Wise, powerful, compassionate\\n- affiliation: Hogwarts Headmaster\\n\\nPrevious Dialogue:\\nVoldemort: You do not seek to kill me, Dumbledore?\",\n","    \"expected_output\": \"Dumbledore: We both know there are other ways of destroying a man, Tom.\"\n","  },\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Sirius and Harry:\",\n","    \"input\": \"Scene:\\nThe cave near Hogsmeade was cold and dark. Buckbeak lay in the corner, while Sirius tore apart a chicken leg. Harry sat across from his godfather, worried about the Triwizard Tournament.\\n\\\"I don't know if I can do this, Sirius.\\\"\\n\\nCharacter Information:\\nSirius:\\n- name: Sirius Black\\n- character: Brave, protective, reckless\\n- relation: Harry's godfather\\n\\nHarry:\\n- name: Harry Potter\\n- age: 14\\n- character: Worried but determined\\n\\nPrevious Dialogue:\\nHarry: I don't know if I can do this, Sirius.\",\n","    \"expected_output\": \"Sirius: You're your father's son, Harry. James would've laughed in the face of danger too.\"\n","  },\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Luna and Neville:\",\n","    \"input\": \"Scene:\\nThe Room of Requirement was filled with students practicing defensive spells. Luna watched as Neville finally mastered a particularly difficult Shield Charm.\\n\\\"I've never seen anyone improve so quickly, Neville.\\\"\\n\\nCharacter Information:\\nLuna:\\n- name: Luna Lovegood\\n- character: Dreamy, honest, perceptive\\n- affiliation: Dumbledore's Army\\n\\nNeville:\\n- name: Neville Longbottom\\n- character: Growing confidence, determined\\n- affiliation: Dumbledore's Army\\n\\nPrevious Dialogue:\\nLuna: I've never seen anyone improve so quickly, Neville.\",\n","    \"expected_output\": \"Neville: Thanks Luna. I suppose we all have to step up now that Harry's teaching us.\"\n","  }\n","]"],"metadata":{"id":"U59tUacQMqAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_cases[1]['instruction']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"dbEnLDAGNDFg","executionInfo":{"status":"ok","timestamp":1733760948451,"user_tz":-540,"elapsed":462,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"ea18275c-cc25-4ab3-a1d8-ea2d189e5d32"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Hermione and Ron:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["output_train_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_train_set.json'\n","output_test_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_test_set.json'\n","formatted_dataset_path = '/content/drive/MyDrive/Colab Notebooks/á„ƒá…µá†¸á„…á…¥á„‚á…µá†¼ á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/Dataset Station/Harry Potter Alpaca/hpa_formatted_dataset'\n","\n","with open(output_train_path, 'r', encoding='utf-8') as f:\n","    train_data = json.load(f)\n","\n","with open(output_test_path, 'r', encoding='utf-8') as f:\n","    test_data = json.load(f)\n","\n","# ë‚˜ì¤‘ì— ë°ì´í„°ì…‹ì„ ë‹¤ì‹œ ë¡œë“œí•  ë•ŒëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n","from datasets import load_from_disk\n","formatted_dataset = load_from_disk(formatted_dataset_path)"],"metadata":{"id":"LfF4EqDWRWjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(formatted_dataset['train']['text'][0])"],"metadata":{"id":"6hGWKy5NV40d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_json[3][\"instruction\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGV3REQRaZAL","executionInfo":{"status":"ok","timestamp":1733762122181,"user_tz":-540,"elapsed":1267,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"9df3cd9d-252b-4c91-be75-493299f69ee1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Petunia and Vernon and Harry:\n"]}]},{"cell_type":"code","source":["print(train_json[3][\"input\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFT0axc4Rpeu","executionInfo":{"status":"ok","timestamp":1733762136983,"user_tz":-540,"elapsed":479,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"25d04ea7-508a-467a-8994-e305bb75e8e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scene:\n","â€œBad news, Vernon,â€ she said. â€œMrs. Figgâ€™s broken her leg. She canâ€™t take him.â€ She jerked her head in Harryâ€™s direction.\n","Dudleyâ€™s mouth fell open in horror, but Harryâ€™s heart gave a leap. Every year on Dudleyâ€™s birthday, his parents took him and a friend out for the day, to adventure parks, hamburger restaurants, or the movies. Every year, Harry was left behind with Mrs. Figg, a mad old lady who lived two streets away. Harry hated it there. The whole house smelled of cabbage and Mrs. Figg made him look at photographs of all the cats sheâ€™d ever owned.\n","â€œNow what?â€ said Aunt Petunia, looking furiously at Harry as though heâ€™d planned this. Harry knew he ought to feel sorry that Mrs. Figg had broken her leg, but it wasnâ€™t easy when he reminded himself it would be a whole year before he had to look at Tibbles, Snowy, Mr. Paws, and Tufty again.\n","â€œWe could phone Marge,â€ Uncle Vernon suggested.\n","â€œDonâ€™t be silly, Vernon, she hates the boy.â€\n","The Dursleys often spoke about Harry like this, as though he wasnâ€™t there â€” or rather, as though he was something very nasty that couldnâ€™t understand them, like a slug.\n","â€œWhat about whatâ€™s-her-name, your friend â€” Yvonne?â€\n","â€œOn vacation in Majorca,â€ snapped Aunt Petunia.\n","â€œYou could just leave me here,â€ Harry put in hopefully (heâ€™d be able to watch what he wanted on television for a change and maybe even have a go on Dudleyâ€™s computer).\n","Aunt Petunia looked as though sheâ€™d just swallowed a lemon.\n","â€œAnd come back and find the house in ruins?â€ she snarled.\n","â€œI wonâ€™t blow up the house,â€ said Harry, but they werenâ€™t listening.\n","â€œI suppose we could take him to the zoo,â€ said Aunt Petunia slowly, â€œ. . . and leave him in the car. . . .â€\n","â€œThat carâ€™s new, heâ€™s not sitting in it alone. . . .â€\n","Dudley began to cry loudly. In fact, he wasnâ€™t really crying â€” it had been years since heâ€™d really cried â€” but he knew that if he screwed up his face and wailed, his mother would give him anything he wanted.\n","â€œDinky Duddydums, donâ€™t cry, Mummy wonâ€™t let him spoil your special day!â€ she cried, flinging her arms around him.\n","â€œI . . . donâ€™t . . . want . . . him . . . t-t-to come!â€ Dudley yelled between huge, pretend sobs. â€œHe always sp-spoils everything!â€ He shot Harry a nasty grin through the gap in his motherâ€™s arms.\n","Just then, the doorbell rang â€”â€œOh, good Lord, theyâ€™re here!â€ said Aunt Petunia frantically â€” and a moment later, Dudleyâ€™s best friend, Piers Polkiss, walked in with his mother. Piers was a scrawny boy with a face like a rat. He was usually the one who held peopleâ€™s arms behind their backs while Dudley hit them. Dudley stopped pretending to cry at once.\n","Half an hour later, Harry, who couldnâ€™t believe his luck, was sitting in the back of the Dursleysâ€™ car with Piers and Dudley, on the way to the zoo for the first time in his life. His aunt and uncle hadnâ€™t been able to think of anything else to do with him, but before theyâ€™d left, Uncle Vernon had taken Harry aside.\n","â€œIâ€™m warning you,â€ he had said, putting his large purple face right up close to Harryâ€™s, â€œIâ€™m warning you now, boy â€” any funny business, anything at all â€” and youâ€™ll be in that cupboard from now until Christmas.â€\n","\n","Character Information:\n","Petunia:\n","- name: Petunia\n","- gender: Female\n","- age: Adult\n","- looks: Slender, blond hair, long neck\n","- character: Message, gossip\n","- lineage: Maculogy\n","Relations with Harry:\n","- family: 1.0\n","- Harry's affection to him: -4.0\n","- Harry's familiarity with him: 8.0\n","- His affection to Harry: -4.0\n","- His familiarity with Harry: 6.0\n","\n","Vernon:\n","- name: Vernon Dursley\n","- gender: male\n","- age: Adult\n","- looks: Very fat, tall and burly, accumulating beard\n","- character: mean\n","- belongings: car\n","- affiliation: Grandine Company\n","- lineage: Maculogy\n","- title: Company supervisor\n","Relations with Harry:\n","- family: 1.0\n","- Harry's affection to him: -4.0\n","- Harry's familiarity with him: 8.0\n","- His affection to Harry: -4.0\n","- His familiarity with Harry: 6.0\n","\n","Harry:\n","- name: Harry\n","- nickname: The boy who lived\n","- gender: male\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- title: The boy who lived\n","\n","\n","Previous Dialogue:\n","Petunia: Bad news, Vernon, Mrs. Figgâ€™s broken her leg. She canâ€™t take him. Now what? \n","\n"]}]},{"cell_type":"code","source":["print(train_json[3][\"output\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJPcHBWkSB80","executionInfo":{"status":"ok","timestamp":1733762244389,"user_tz":-540,"elapsed":926,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"e93c4d7e-2d9e-45ac-f5dd-87d461566144"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vernon: We could phone Marge,\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2r3ydL6GdEuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jt86m47idEw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from nltk.lm import MLE\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from scipy.spatial.distance import cosine\n","from sentence_transformers import SentenceTransformer\n","import nltk\n","\n","# Download required NLTK data\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","def calculate_bleu(reference, hypothesis):\n","    \"\"\"\n","    Calculate BLEU score between reference and hypothesis\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: BLEU score\n","    \"\"\"\n","    # Tokenize the sentences\n","    ref_tokens = nltk.word_tokenize(reference.lower())\n","    hyp_tokens = nltk.word_tokenize(hypothesis.lower())\n","\n","    # Calculate BLEU score with smoothing\n","    smoothing = SmoothingFunction().method1\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoothing)\n","\n","def calculate_meteor(reference, hypothesis):\n","    \"\"\"\n","    Calculate METEOR score between reference and hypothesis\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: METEOR score\n","    \"\"\"\n","    return meteor_score([reference.split()], hypothesis.split())\n","\n","def calculate_perplexity(text, model_name='gpt2'):\n","    \"\"\"\n","    Calculate perplexity using GPT-2\n","\n","    Args:\n","        text (str): Input text to calculate perplexity for\n","        model_name (str): Name of the pretrained model to use\n","\n","    Returns:\n","        float: Perplexity score\n","    \"\"\"\n","    # Load model and tokenizer\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    model.eval()\n","\n","    # Encode text\n","    encodings = tokenizer(text, return_tensors='pt')\n","\n","    # Calculate perplexity\n","    max_length = model.config.n_positions\n","    stride = 512\n","    seq_len = encodings.input_ids.size(1)\n","\n","    nlls = []\n","    prev_end_loc = 0\n","    for begin_loc in range(0, seq_len, stride):\n","        end_loc = min(begin_loc + max_length, seq_len)\n","        trg_len = end_loc - prev_end_loc\n","        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n","        target_ids = input_ids.clone()\n","        target_ids[:, :-trg_len] = -100\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, labels=target_ids)\n","            neg_log_likelihood = outputs.loss\n","\n","        nlls.append(neg_log_likelihood)\n","        prev_end_loc = end_loc\n","        if end_loc == seq_len:\n","            break\n","\n","    ppl = torch.exp(torch.stack(nlls).mean())\n","    return ppl.item()\n","\n","def calculate_simile(reference, hypothesis):\n","    \"\"\"\n","    Calculate SIMILE (Semantic Similarity) score using sentence transformers\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: SIMILE score (cosine similarity between sentence embeddings)\n","    \"\"\"\n","    # Load sentence transformer model\n","    model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","    # Get embeddings\n","    ref_embedding = model.encode([reference])[0]\n","    hyp_embedding = model.encode([hypothesis])[0]\n","\n","    # Calculate cosine similarity\n","    similarity = 1 - cosine(ref_embedding, hyp_embedding)\n","    return similarity\n","\n","def evaluate_responses(references, hypotheses):\n","    \"\"\"\n","    Calculate all metrics for a list of reference and hypothesis texts\n","\n","    Args:\n","        references (list): List of reference texts\n","        hypotheses (list): List of hypothesis texts\n","\n","    Returns:\n","        dict: Dictionary containing average scores for all metrics\n","    \"\"\"\n","    scores = {\n","        'bleu': [],\n","        'meteor': [],\n","        'perplexity': [],\n","        'simile': []\n","    }\n","\n","    for ref, hyp in zip(references, hypotheses):\n","        scores['bleu'].append(calculate_bleu(ref, hyp))\n","        scores['meteor'].append(calculate_meteor(ref, hyp))\n","        scores['perplexity'].append(calculate_perplexity(hyp))\n","        scores['simile'].append(calculate_simile(ref, hyp))\n","\n","    # Calculate averages\n","    return {metric: np.mean(values) for metric, values in scores.items()}\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Sample data\n","    references = [\n","        \"The quick brown fox jumps over the lazy dog.\",\n","        \"Machine learning is a subset of artificial intelligence.\"\n","    ]\n","    hypotheses = [\n","        \"The fast brown fox leaps over the sleeping dog.\",\n","        \"Machine learning is a branch of artificial intelligence.\"\n","    ]\n","\n","    # Install required packages if not already installed\n","    !pip install -q transformers torch sentence-transformers nltk\n","\n","    # Calculate scores\n","    scores = evaluate_responses(references, hypotheses)\n","\n","    # Print results\n","    print(\"\\nEvaluation Metrics:\")\n","    print(f\"BLEU Score: {scores['bleu']:.4f}\")\n","    print(f\"METEOR Score: {scores['meteor']:.4f}\")\n","    print(f\"Perplexity: {scores['perplexity']:.4f}\")\n","    print(f\"SIMILE Score: {scores['simile']:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":814},"id":"p2eJK8grdEy_","executionInfo":{"status":"error","timestamp":1733815609110,"user_tz":-540,"elapsed":6529,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"a9d8d30f-d949-4b39-dad0-ac5ecc64be5b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"error","ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-fdf86f275d68>\u001b[0m in \u001b[0;36m<cell line: 144>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# Calculate scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_responses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-fdf86f275d68>\u001b[0m in \u001b[0;36mevaluate_responses\u001b[0;34m(references, hypotheses)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bleu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meteor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_meteor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perplexity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-fdf86f275d68>\u001b[0m in \u001b[0;36mcalculate_bleu\u001b[0;34m(reference, hypothesis)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Tokenize the sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mref_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mhyp_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     return [\n\u001b[1;32m    144\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_punkt_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPunktTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mPunktSentenceTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mload_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mlang_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt_tab/{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_punkt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"]}]},{"cell_type":"code","source":["# Install required packages\n","!pip install -q transformers torch sentence-transformers nltk\n","\n","import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from nltk.lm import MLE\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from scipy.spatial.distance import cosine\n","from sentence_transformers import SentenceTransformer\n","import nltk\n","\n","# Download ALL required NLTK data at the start\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger')\n","\n","def calculate_bleu(reference, hypothesis):\n","    \"\"\"\n","    Calculate BLEU score between reference and hypothesis\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: BLEU score\n","    \"\"\"\n","    # Tokenize the sentences\n","    ref_tokens = nltk.word_tokenize(reference.lower())\n","    hyp_tokens = nltk.word_tokenize(hypothesis.lower())\n","\n","    # Calculate BLEU score with smoothing\n","    smoothing = SmoothingFunction().method1\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoothing)\n","\n","def calculate_meteor(reference, hypothesis):\n","    \"\"\"\n","    Calculate METEOR score between reference and hypothesis\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: METEOR score\n","    \"\"\"\n","    return meteor_score([reference.split()], hypothesis.split())\n","\n","def calculate_perplexity(text, model_name='gpt2'):\n","    \"\"\"\n","    Calculate perplexity using GPT-2\n","\n","    Args:\n","        text (str): Input text to calculate perplexity for\n","        model_name (str): Name of the pretrained model to use\n","\n","    Returns:\n","        float: Perplexity score\n","    \"\"\"\n","    # Load model and tokenizer\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    model.eval()\n","\n","    # Encode text\n","    encodings = tokenizer(text, return_tensors='pt')\n","\n","    # Calculate perplexity\n","    max_length = model.config.n_positions\n","    stride = 512\n","    seq_len = encodings.input_ids.size(1)\n","\n","    nlls = []\n","    prev_end_loc = 0\n","    for begin_loc in range(0, seq_len, stride):\n","        end_loc = min(begin_loc + max_length, seq_len)\n","        trg_len = end_loc - prev_end_loc\n","        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n","        target_ids = input_ids.clone()\n","        target_ids[:, :-trg_len] = -100\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, labels=target_ids)\n","            neg_log_likelihood = outputs.loss\n","\n","        nlls.append(neg_log_likelihood)\n","        prev_end_loc = end_loc\n","        if end_loc == seq_len:\n","            break\n","\n","    ppl = torch.exp(torch.stack(nlls).mean())\n","    return ppl.item()\n","\n","def calculate_simile(reference, hypothesis):\n","    \"\"\"\n","    Calculate SIMILE (Semantic Similarity) score using sentence transformers\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: SIMILE score (cosine similarity between sentence embeddings)\n","    \"\"\"\n","    # Load sentence transformer model\n","    model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","    # Get embeddings\n","    ref_embedding = model.encode([reference])[0]\n","    hyp_embedding = model.encode([hypothesis])[0]\n","\n","    # Calculate cosine similarity\n","    similarity = 1 - cosine(ref_embedding, hyp_embedding)\n","    return similarity\n","\n","def evaluate_responses(references, hypotheses):\n","    \"\"\"\n","    Calculate all metrics for a list of reference and hypothesis texts\n","\n","    Args:\n","        references (list): List of reference texts\n","        hypotheses (list): List of hypothesis texts\n","\n","    Returns:\n","        dict: Dictionary containing average scores for all metrics\n","    \"\"\"\n","    scores = {\n","        'bleu': [],\n","        'meteor': [],\n","        'perplexity': [],\n","        'simile': []\n","    }\n","\n","    for ref, hyp in zip(references, hypotheses):\n","        scores['bleu'].append(calculate_bleu(ref, hyp))\n","        scores['meteor'].append(calculate_meteor(ref, hyp))\n","        scores['perplexity'].append(calculate_perplexity(hyp))\n","        scores['simile'].append(calculate_simile(ref, hyp))\n","\n","    # Calculate averages\n","    return {metric: np.mean(values) for metric, values in scores.items()}\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Sample data\n","    references = [\n","        \"The quick brown fox jumps over the lazy dog.\",\n","        \"Machine learning is a subset of artificial intelligence.\"\n","    ]\n","    hypotheses = [\n","        \"The fast brown fox leaps over the sleeping dog.\",\n","        \"Machine learning is a branch of artificial intelligence.\"\n","    ]\n","\n","    # Calculate scores\n","    scores = evaluate_responses(references, hypotheses)\n","\n","    # Print results\n","    print(\"\\nEvaluation Metrics:\")\n","    print(f\"BLEU Score: {scores['bleu']:.4f}\")\n","    print(f\"METEOR Score: {scores['meteor']:.4f}\")\n","    print(f\"Perplexity: {scores['perplexity']:.4f}\")\n","    print(f\"SIMILE Score: {scores['simile']:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":887,"referenced_widgets":["06b0b5c6bd4c4606b96c56586a5a969f","54f71e95d414421c8955d0ed6a72a0be","7804471a616b4b3c82b25fb571cfdbbe","11fe91b689df446db617cd60bc289862","54f9c7b5ff8f47c994275e5e02bfcd9f","b209a5ce1a4641fdbf9ea503acb0f108","737e7fe57c8545bea4c2d7af1099e48e","f3c9246062f147e48ba5f793cb8c1dac","dc6097ac48c54ea3a2da7c8532176b9d","248de5138a8243e288d8c5ed9b6b3a37","7430be762ab44b9e9ad7476f9b408ead","d1a9193130964a32a15544dab5310d2a","9813b985e97c411fa554f362ee3c42b8","da34e5ba9d4c4342875ab07be2257804","ecc146ea7c744add8845eb093bac824b","3cdc75bbc37b4ec2bed70355d60a9078","4c949bedfe5f4350b1731e4333d0871e","ee457dcaa92b4f73a60408ac12cb3ccd","8e9f6090106b4a7aacdc6bce521c9f83","bf9a90bb39d447a4abba2cec4ab6ed94","0101882a7c024f659558a1fb19244462","b280b36a94734adbb1648fbd0d4e4d53","1b5268fcc60d4b4f8ed5287516558f90","350ad988dcc24b29985684cd87a01128","3f925f435c644a2fbe2f10cb7095c199","4b33ae6dbe3947878789154d3b7f69db","60912685336a4324b19dcf106e8a30ad","786baba186ff40eb9f4923d306493d5f","9d144ebfe96045eca3eb0a9cfa0914a8","6803e762288c427cb0d6a7074473ec22","c41796fbc16e4c77852bd772e275b1bf","4676d0e3769f404cb0cbde38a42c37ca","6c9b78b2748e4aaeb14ff90f37c03038","d16094dc3f81455bb8cf2fc8e6730ca0","dd9fb35cf2d2476c89defd096273a5f1","177b85f83eec47beb41e72683e887366","8555042c75a047efa47a9ff6a634a6f3","f8d22dc858494872b01c34bb49563ec2","0f5850588abf498bb45c64c39c75f932","15a6cb3a0d534efe973c5e98b6afd3e1","bc1c489409eb493d8c5b89068d7ba9ed","c4e4cc5e14304c0a9e656a1ef69410bb","37afa932f1884e77b1ed6e9fbc4a025c","47d59a08e75f45c780c241eab5f77417","5eb7172adae9467f85a9faf4cc414247","38bdd48028a14a3192b0e2d2be54642f","eafceacb104e4622b54faaa5a3f00f1f","d9e3fce8db43428097b6592621f02d5f","b699a4911ba649c2a8015a63fe342c2a","289408ddb467436f808ec2d62160f843","16ed514587a84338a6eb39b96179c57d","605dfc90d21f470484634e125d40de6f","3eaa26d43e9e431b9f1481fac2b71b86","1fdfc46b60f94d578afdc8408b5b1f38","7b82c4f0073b43b7a20a811e390cc6b5","5b822ce0dc4942a5b10a38729fc9d940","376bccb84a654dd0b63d6f7539763ee1","1156178e280248fd9e33abead2a23e9e","572ba88a54bd452c9e19d06f523e592e","9c21507260914e98b308eee228c82b5c","a9ca2cdc28d1470498186ee6e0ced4f3","debb00b747c94b9f91471ab97bbb7420","1aa2d7f795c542d083eb4ef83cc898ac","f0d4403d5bec491aafa25bd51a22daac","2cb597f252a34c83afdde505e9ffdbf9","93d89ce3fc8143a680f632ebb4adf540","aeb8280f9ce7428b88fd77b49ff948fb","7e945787c68d4d49948695f490220248","8ef7b9d616c343b3b7dcf7883ff945e2","65917152dc604aeda0edc1c47c367484","f16b291a5d2f4bd4b9635b5aa99b3145","97a267e4f5cf4238bfcdff19b785987e","5ae0273b0a834c1c979c9d1b594efd31","befc06fe73644b4c85635f04ff3ab2d9","f2d9f492d8ad48ee8f6abc4b7b0ee977","5f40ae75ce1f4a309e37cb8e61f6a7e8","70929129f1f94438a7ba340a6d403d15","91ea0a96d7be4e6882a47bf65e451a56","eed2aa114b494969abbac1cde7fb47fb","5c03fe142ff842979513e5d4918793fb","863264cfb9704716b0650feb18925d7a","0db011e15d94455b92c21c7762fda4c4","26e96f4d96834a44856c9c1bc4c31898","f433cad65814441881566a9c18bbae59","e3277da32e874d779948d2aa27c87e56","a3905c9747d84172967ea1a0d94c7406","866795b0cc554da8acaa63d9ebbd214f","fcc7d69a1f35451c8967f3e0a71da2ed","fcb9e204ae644a6f80fe924e16cdb0fd","6b00b87e8db4459eb0758d0419fe07ee","84cfed1b59ed4d918ff594947be27adb","b31acc9e55ba41929c7dab203fb79978","939b5ada21bb4b858128a1d4caa9117f","31f4ebde0fe049c68adc14e8a5b5b83d","2859ae351c884351aecac5bfea7a6268","8788398ad42648eebc21afab6eb43494","158bb8aebead4eacbbdcc7d854450ec3","53613814bcc840629b85df1b81433a49","94cf679831484e61a61548e878920c64","d0bf3aa31dfe4e84bb8fe6f778e04ebd","f0d53a637764468abcd42a4b7436a2eb","69711a6bed4243dcaef1172005affa93","94d40cb5e4ee46719f47453a8a49435a","d720daf786e84ef780f9c54346af1be2","e4bc59acfefe4d5587f65a161445ae45","96d1b98bf3f346c3bd401f39d4944bd4","18cae444d1e14a34ae33174d301f1b91","f829babaa56e4b6bb670b2fb394be5a6","cf0f4c95fc974cef9093c2de6c807dfc","8973dc3d59504d5fa1f1967ce575bc7c","437af67932df433589d66affbc3da5fa","67df030304d94110a92a9036ad9c3ae7","ef3322b1830f4ec8bc06cde267434a7f","84a5197dd9ec4e5c8936551eb21a17c2","f5183736ca124e3ea327c4e1dc8c1e81","b3d438d7703b4e1fb11100534b478b85","ce1e4e7661144057b56e3e871d9ef6b4","8944addec5294f62abad29ed983f9d2e","58d30bff243544caa8d37b39e086e8d9","e6edefa1eec1411abcf84f2a00b56328","f4fb331d752d4add96ba184f9eb1f148","a983e6264b2c47e5961d6026e03454f4","43d96cf8e7c0441dbff06c89f1fab67a","dbee6b6638fc4108b68476e1ab928f40","3782966617394ae2a8c1a2d326e8e023","d542f761d50a48408031f0b3196586fb","84394c3dee9545d783e3f25cc1cfe658","6fbcd51dbffb40d1a6bc6b7fc7321b54","a12ce4c1a46b4c90aee55957aa9379b2","55d206ad7de340059ce19e973cb64647","dc9cec09589240c1a7cca71d22e1dc1c","75499456c89d4ef6ac2358d280b519b4","68e35762c9254b93b5af79b87a1b915d","d542a0a6324f4f2fbd1fa3a4329dc09c","e8ed5fbe7b4248e99924eca3aa782cd6","e35d12fc7b9a4e4689a1ad4091450b5f","a589061c45844ba1b25fd697cfa4df04","8e5c130e104a4719b8a03779d79d8471","63a129ea4f474caeadfd9c613a22158e","c2eae8b240934a5d82d9a0224427b25d","50ff39c332b74150ae0f94089d7a2ef3","834cf3587ed442b08003c2d4fda0d89f","77d96a7599d34559840ae84f7c541b75","23356d2e2a514506a56f12c6c3f75a98","a7047118b19b4276869d3fec71ab4822","35bf59643b70494a82c7abe20b7872ad","27a3eee23cb349c083c90227b333acd2","e8982b572c75466e8e78a366a2ebe474","64752a50060e4768928ae1b553a77d4d","f8d9c508a5444eb984372f2dd0f596ba","92964bfb29d24e15a054b724df7ffbf9","712f227f1028439893886da36d2fb6f2","9f758b677ce644579e0d04434ea01ad2","e0c07743b6134cc8adafa2287339e4ee","b6698b2f0a0748c593f8266a03e8e3a1","a28bc8b706d544f581d4793fe1f44297","6dbbea6f0c0348c88cbd7739774cc324","6c2f09e456ef4b2b8d2e17012e5093b2","95ee80498f87425aa3e4c7b5e9bf36de","8564cf1b429e49b99c8f52dba6a7f038","2f50793d2b264caf9e8b8478f9123d3f","5b37c73ac2d34886b126481a4b2bb553","952bac09ae824f02b127d04bcba8510d","a99e3fd505014877948e52c120b973cc","863e14ba8d2c4f0f9b2eefa009fa76f1","0f1c42eff3724a0aa7e2c8d9cca3d8f7","4b86acb21bb84f5d9baef7f96f9fc706","f72de091cb58404995d81cbfeb7561db","b2c94b607c4643778f2f4cb3b4383ebe","5bfec39d57614082bdedb25650d903ca","80cf5fa1a7b3451785d401e10ff0d77c","c2fc3cf71cea4279ab40b555bfbab1f8","4b283a280e644b0185894d9c83e62fba","b4d7ac82f62147ff9be029a3f7b31f71","dd58f23b33ab48b5bc9691706850ecfc","ec1c80734f444e8fba351c0ef5c996d7","9c760e27bfa44c34a6b58470413ea430","c45defc9b220461f968e8ff084c39ad0","b9f9509d2a8141099d6e5e1d48385f23","2595f6c665a14f1e81faafab3ab71e94","313b03bd2238456794502432c280265c","4db00b6bbe6044e09b6f6d6517180bf0","f00fd8b4d5644ba3a69a662e0da9cb32","ebf5942b5dcf467faa172b1ddd315bf1","71a84d3ecb504943846915b33fa4fcdb","a4cd4a5c08ae402691a85ae10da59816","fcc2e03cf6bf4e56b87354936ff19f1a","300a8e3915344a14a5ee4cc4e9f9c8c9","36d2b63258d141919cfecfc38b2587db","6a28307dc08d4ab092661ab023f5beb6","42bb7fab57864aa9809fe9cfd928e708","83830143d44c48fba63c1d5301d71de9","1098e11bc01d481f836d6f681980f030","bddd129db7584bc584211544a9dd78db","9d7a8de016f149ecafc025222f75d467","7c7a5fe6812e4e78814416e26d8b3321","2ab59cd9b4f445618a0de8f32b8baf48","6ef524bde1f546b2824e400244e0016c"]},"id":"s-maaIkvejr3","executionInfo":{"status":"ok","timestamp":1733815891403,"user_tz":-540,"elapsed":41329,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"6aea2c06-9cc4-42c5-9bee-d4b1aa2deb10"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06b0b5c6bd4c4606b96c56586a5a969f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1a9193130964a32a15544dab5310d2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b5268fcc60d4b4f8ed5287516558f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d16094dc3f81455bb8cf2fc8e6730ca0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eb7172adae9467f85a9faf4cc414247"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b822ce0dc4942a5b10a38729fc9d940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeb8280f9ce7428b88fd77b49ff948fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91ea0a96d7be4e6882a47bf65e451a56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb9e204ae644a6f80fe924e16cdb0fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0bf3aa31dfe4e84bb8fe6f778e04ebd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"437af67932df433589d66affbc3da5fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a983e6264b2c47e5961d6026e03454f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e35762c9254b93b5af79b87a1b915d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23356d2e2a514506a56f12c6c3f75a98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6698b2f0a0748c593f8266a03e8e3a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f1c42eff3724a0aa7e2c8d9cca3d8f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c760e27bfa44c34a6b58470413ea430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"300a8e3915344a14a5ee4cc4e9f9c8c9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Metrics:\n","BLEU Score: 0.3386\n","METEOR Score: 0.8734\n","Perplexity: 166.2554\n","SIMILE Score: 0.8484\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a7aBU22AdE05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mchHIzcPdE4F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_n = 3"],"metadata":{"id":"avY1glKlSa8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","# ------------------------------------------------------------------------\n","\n","# ëª¨ë¸ì„ inference ëª¨ë“œë¡œ ì„¤ì •\n","FastLanguageModel.for_inference(model)\n","\n","# í…ŒìŠ¤íŠ¸í•  ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ ìƒì„±\n","test_instruction = train_json[test_n]['instruction']\n","test_input = train_json[test_n]['input']\n","\n","# ì…ë ¥ í…ìŠ¤íŠ¸ ìƒì„±\n","inputs = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            test_instruction,  # instruction\n","            test_input,       # input\n","            \"\",              # output - ìƒì„±ì„ ìœ„í•´ ë¹„ì›Œë‘ \n","        )\n","    ],\n","    return_tensors=\"pt\"\n",").to(\"cuda\")\n","\n","# í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ streamer ì„¤ì •\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","\n","# ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •\n","generation_params = {\n","    \"max_new_tokens\": 256,      # ë” ê¸´ ëŒ€í™”ë¥¼ ìœ„í•´ ì¦ê°€\n","    \"temperature\": 0.2,         # ì°½ì˜ì„± ì¡°ì ˆ (0.7)\n","    \"top_p\": 0.2,              # ë‹¤ì–‘ì„± ì¡°ì ˆ (0.9)\n","    \"do_sample\": True,         # ë‹¤ì–‘í•œ ì‘ë‹µ ìƒì„± ê°€ëŠ¥\n","    \"streamer\": text_streamer,\n","    \"pad_token_id\": tokenizer.pad_token_id,\n","    \"eos_token_id\": tokenizer.eos_token_id,\n","}\n","\n","# í…ìŠ¤íŠ¸ ìƒì„±\n","print(\"Generating dialogue...\")\n","outputs = model.generate(**inputs, **generation_params)\n","\n","# ìƒì„±ëœ í…ìŠ¤íŠ¸ ë””ì½”ë”© (streamerë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì„ ê²½ìš°)\n","# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","# print(generated_text)\n","\n","# ì—¬ëŸ¬ ë‹¤ë¥¸ ìƒí™©ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ í•¨ìˆ˜\n","def generate_dialogue(instruction, scene, characters):\n","    input_text = f\"Scene:\\n{scene}\\n\\nCharacter Information:\\n{characters}\"\n","\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, **generation_params)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(\"### Correct Dialogue:\")\n","print(train_json[test_n]['output'], \"<|end_of_text|>\")\n","\n","test_n += 1"],"metadata":{"id":"nSxmp-oXKyp_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a name=\"Save\"></a>\n","### Saving, loading finetuned models\n","To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n","\n","**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"],"metadata":{"id":"uMuVrWbjAzhc"}},{"cell_type":"markdown","source":["Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"],"metadata":{"id":"AEEcJ4qfC7Lp"}},{"cell_type":"code","source":["# if False:\n","#     from unsloth import FastLanguageModel\n","#     model, tokenizer = FastLanguageModel.from_pretrained(\n","#         model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","#         max_seq_length = max_seq_length,\n","#         dtype = dtype,\n","#         load_in_4bit = load_in_4bit,\n","#     )\n","#     FastLanguageModel.for_inference(model)\n","\n","# # alpaca_prompt = You MUST run cells from above!\n","\n","# inputs = tokenizer(\n","# [\n","#     alpaca_prompt.format(\n","#         \"What is a famous tall tower in Paris?\", # instruction\n","#         \"\", # input\n","#         \"\", # output - leave this blank for generation!\n","#     )\n","# ], return_tensors = \"pt\").to(\"cuda\")\n","\n","# outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","# tokenizer.batch_decode(outputs)"],"metadata":{"id":"MKX_XKs_BNZR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733454453005,"user_tz":-540,"elapsed":6257,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"32b5da67-cca3-4290-dbf8-ee52ca688af4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is a famous tall tower in Paris?\\n\\n### Input:\\n\\n\\n### Response:\\nThe Eiffel Tower is a famous tall tower located in Paris, France. It is 324 meters (1,063 feet) tall, making it the tallest structure in Paris. The Eiffel Tower was built in 1889 as the entrance arch for the 1889 World's Fair and was designed by\"]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[],"metadata":{"id":"mK5ptKBPbOcp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from typing import Dict, List, Optional\n","\n","class DialoguePromptGenerator:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.base_prompt_template = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Generate the next line of dialogue that matches the character's personality, relationships, and the scene context.\n","\n","### Input:\n","Scene Description:\n","{scene}\n","\n","Character Information:\n","{character_info}\n","\n","Previous Dialogue:\n","{dialogue_history}\n","\n","Speaking Character: {speaker}\n","\n","### Response:\n","\"\"\"\n","\n","    def format_character_info(self, attributes: Dict, relations: Optional[Dict] = None) -> str:\n","        \"\"\"Format character attributes and relationships into a structured string\"\"\"\n","        info_str = \"\"\n","\n","        # Format basic attributes\n","        for key, value in attributes.items():\n","            if value and value != \"None\":\n","                info_str += f\"- {key}: {value}\\n\"\n","\n","        # Add relationships if available\n","        if relations:\n","            info_str += \"\\nRelations with Harry:\\n\"\n","            for key, value in relations.items():\n","                if isinstance(value, (int, float)) and value != 0:\n","                    info_str += f\"- {key}: {value}\\n\"\n","\n","        return info_str\n","\n","    def format_dialogue_history(self, history: List[str]) -> str:\n","        \"\"\"Format dialogue history with clear speaker indicators\"\"\"\n","        return \"\\n\".join(history)\n","\n","    def generate_prompt(self,\n","                       scene: str,\n","                       character_attributes: Dict,\n","                       dialogue_history: List[str],\n","                       speaker: str,\n","                       relations: Optional[Dict] = None) -> str:\n","        \"\"\"Generate a complete prompt for dialogue generation\"\"\"\n","\n","        # Format character information\n","        character_info = self.format_character_info(character_attributes, relations)\n","\n","        # Format dialogue history\n","        formatted_history = self.format_dialogue_history(dialogue_history)\n","\n","        # Fill template\n","        prompt = self.base_prompt_template.format(\n","            scene=scene,\n","            character_info=character_info,\n","            dialogue_history=formatted_history,\n","            speaker=speaker\n","        )\n","\n","        return prompt\n","\n","    def tokenize_prompt(self, prompt: str) -> torch.Tensor:\n","        \"\"\"Tokenize the prompt for model input\"\"\"\n","        return self.tokenizer(\n","            prompt,\n","            truncation=True,\n","            max_length=512,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\"\n","        )\n","\n","    def generate_dialogue(self, model, prompt: str, max_length: int = 1000) -> str:\n","        \"\"\"Generate dialogue using the model\"\"\"\n","        inputs = self.tokenize_prompt(prompt)\n","\n","        outputs = model.generate(\n","            input_ids=inputs[\"input_ids\"],\n","            attention_mask=inputs[\"attention_mask\"],\n","            max_length=max_length,\n","            num_return_sequences=1,\n","            temperature=0.7,\n","            top_p=0.9,\n","            do_sample=True\n","        )\n","\n","        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"xxyH77uzST4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_generator = DialoguePromptGenerator(tokenizer)"],"metadata":{"id":"-bVdqUNWST7p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example data\n","scene = \"In the Great Hall during breakfast\"\n","character_attributes = {\n","    \"personality\": \"brave, loyal\",\n","    \"house\": \"Gryffindor\",\n","    \"year\": \"3rd year\"\n","}\n","relations = {\n","    \"friendship\": 0.9,\n","    \"trust\": 0.8\n","}\n","dialogue_history = [\n","    \"Harry: Did you see the notice about Hogsmeade?\",\n","    \"Ron: Yeah, can't wait to visit Honeydukes!\"\n","]\n","speaker = \"Hermione\"\n","\n","# Generate prompt\n","prompt = prompt_generator.generate_prompt(\n","    scene=scene,\n","    character_attributes=character_attributes,\n","    dialogue_history=dialogue_history,\n","    speaker=speaker,\n","    relations=relations\n",")\n","\n","FastLanguageModel.for_inference(model)\n","\n","# Generate dialogue\n","response = prompt_generator.generate_dialogue(model, prompt)"],"metadata":{"id":"l7v5Tpo6St2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLvGSeyzSt42","executionInfo":{"status":"ok","timestamp":1733798304893,"user_tz":-540,"elapsed":274,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"12dbfe61-f869-4ec3-8498-bd99c2b12881"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Generate the next line of dialogue that matches the character's personality, relationships, and the scene context.\n","\n","### Input:\n","Scene Description:\n","In the Great Hall during breakfast\n","\n","Character Information:\n","- personality: brave, loyal\n","- house: Gryffindor\n","- year: 3rd year\n","\n","Relations with Harry:\n","- friendship: 0.9\n","- trust: 0.8\n","\n","\n","Previous Dialogue:\n","Harry: Did you see the notice about Hogsmeade?\n","Ron: Yeah, can't wait to visit Honeydukes!\n","\n","Speaking Character: Hermione\n","\n","### Response:\n","Hermione: I can't wait to visit Honeydukes!\n"]}]},{"cell_type":"code","source":["# For more consistent responses\n","prompt_generator.generate_dialogue(model, prompt, temperature=0.5, top_p=0.95)\n","\n","# For more creative responses\n","prompt_generator.generate_dialogue(model, prompt, temperature=0.8, top_p=0.9)"],"metadata":{"id":"zr3U92VaSt65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["character_attributes.update({\n","    \"mood\": \"excited\",\n","    \"current_goals\": \"preparing for exams\",\n","    \"recent_events\": \"just learned a new spell\"\n","})"],"metadata":{"id":"II14HHO-St8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4Bgf1mVZc8u4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YgA55ORJc8ww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"r8rwXJL6SxWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/mlvlab/ProMetaR.git\n","%cd ProMetaR/\n","\n","!git clone https://github.com/KaiyangZhou/Dassl.pytorch.git\n","%cd Dassl.pytorch/\n","\n","# Install dependencies\n","!pip install -r requirements.txt\n","!cp -r dassl ../\n","# Install this library (no need to re-build if the source code is modified)\n","# !python setup.py develop\n","%cd ..\n","\n","!pip install -r requirements.txt\n","\n","%mkdir outputs\n","%mkdir data\n","\n","%cd data\n","%mkdir eurosat\n","!wget http://madm.dfki.de/files/sentinel/EuroSAT.zip -O EuroSAT.zip\n","\n","!unzip -o EuroSAT.zip -d eurosat/\n","%cd eurosat\n","!gdown 1Ip7yaCWFi0eaOFUGga0lUdVi_DDQth1o\n","\n","%cd ../../\n","\n","import os.path as osp\n","from collections import OrderedDict\n","import math\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.cuda.amp import GradScaler, autocast\n","from PIL import Image\n","import torchvision.transforms as transforms\n","import torch\n","from clip import clip\n","from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n","import time\n","from tqdm import tqdm\n","import datetime\n","import argparse\n","from dassl.utils import setup_logger, set_random_seed, collect_env_info\n","from dassl.config import get_cfg_default\n","from dassl.engine import build_trainer\n","from dassl.engine import TRAINER_REGISTRY, TrainerX\n","from dassl.metrics import compute_accuracy\n","from dassl.utils import load_pretrained_weights, load_checkpoint\n","from dassl.optim import build_optimizer, build_lr_scheduler\n","\n","# custom\n","import datasets.oxford_pets\n","import datasets.oxford_flowers\n","import datasets.fgvc_aircraft\n","import datasets.dtd\n","import datasets.eurosat\n","import datasets.stanford_cars\n","import datasets.food101\n","import datasets.sun397\n","import datasets.caltech101\n","import datasets.ucf101\n","import datasets.imagenet\n","import datasets.imagenet_sketch\n","import datasets.imagenetv2\n","import datasets.imagenet_a\n","import datasets.imagenet_r\n","\n","def print_args(args, cfg):\n","    print(\"***************\")\n","    print(\"** Arguments **\")\n","    print(\"***************\")\n","    optkeys = list(args.__dict__.keys())\n","    optkeys.sort()\n","    for key in optkeys:\n","        print(\"{}: {}\".format(key, args.__dict__[key]))\n","    print(\"************\")\n","    print(\"** Config **\")\n","    print(\"************\")\n","    print(cfg)\n","\n","def reset_cfg(cfg, args):\n","    if args.root:\n","        cfg.DATASET.ROOT = args.root\n","    if args.output_dir:\n","        cfg.OUTPUT_DIR = args.output_dir\n","    if args.seed:\n","        cfg.SEED = args.seed\n","    if args.trainer:\n","        cfg.TRAINER.NAME = args.trainer\n","    cfg.DATASET.NUM_SHOTS = 16\n","    cfg.DATASET.SUBSAMPLE_CLASSES = args.subsample_classes\n","    cfg.DATALOADER.TRAIN_X.BATCH_SIZE = args.train_batch_size\n","    cfg.OPTIM.MAX_EPOCH = args.epoch\n","\n","def extend_cfg(cfg):\n","    \"\"\"\n","    Add new config variables.\n","    \"\"\"\n","    from yacs.config import CfgNode as CN\n","    cfg.TRAINER.COOP = CN()\n","    cfg.TRAINER.COOP.N_CTX = 16  # number of context vectors\n","    cfg.TRAINER.COOP.CSC = False  # class-specific context\n","    cfg.TRAINER.COOP.CTX_INIT = \"\"  # initialization words\n","    cfg.TRAINER.COOP.PREC = \"fp16\"  # fp16, fp32, amp\n","    cfg.TRAINER.COOP.CLASS_TOKEN_POSITION = \"end\"  # 'middle' or 'end' or 'front'\n","    cfg.TRAINER.COCOOP = CN()\n","    cfg.TRAINER.COCOOP.N_CTX = 4  # number of context vectors\n","    cfg.TRAINER.COCOOP.CTX_INIT = \"a photo of a\"  # initialization words\n","    cfg.TRAINER.COCOOP.PREC = \"fp16\"  # fp16, fp32, amp\n","    cfg.TRAINER.PROMETAR = CN()\n","    cfg.TRAINER.PROMETAR.N_CTX_VISION = 4  # number of context vectors at the vision branch\n","    cfg.TRAINER.PROMETAR.N_CTX_TEXT = 4  # number of context vectors at the language branch\n","    cfg.TRAINER.PROMETAR.CTX_INIT = \"a photo of a\"  # initialization words\n","    cfg.TRAINER.PROMETAR.PREC = \"fp16\"  # fp16, fp32, amp\n","    cfg.TRAINER.PROMETAR.PROMPT_DEPTH_VISION = 9  # Max 12, minimum 0, for 0 it will be using shallow IVLP prompting (J=1)\n","    cfg.TRAINER.PROMETAR.PROMPT_DEPTH_TEXT = 9  # Max 12, minimum 0, for 0 it will be using shallow IVLP prompting (J=1)\n","    cfg.DATASET.SUBSAMPLE_CLASSES = \"all\"  # all, base or new\n","    cfg.TRAINER.PROMETAR.ADAPT_LR = 0.0005\n","    cfg.TRAINER.PROMETAR.LR_RATIO = 0.0005\n","    cfg.TRAINER.PROMETAR.FAST_ADAPTATION = False\n","    cfg.TRAINER.PROMETAR.MIXUP_ALPHA = 0.5\n","    cfg.TRAINER.PROMETAR.MIXUP_BETA = 0.5\n","    cfg.TRAINER.PROMETAR.DIM_RATE=8\n","    cfg.OPTIM_VNET = CN()\n","    cfg.OPTIM_VNET.NAME = \"adam\"\n","    cfg.OPTIM_VNET.LR = 0.0003\n","    cfg.OPTIM_VNET.WEIGHT_DECAY = 5e-4\n","    cfg.OPTIM_VNET.MOMENTUM = 0.9\n","    cfg.OPTIM_VNET.SGD_DAMPNING = 0\n","    cfg.OPTIM_VNET.SGD_NESTEROV = False\n","    cfg.OPTIM_VNET.RMSPROP_ALPHA = 0.99\n","    cfg.OPTIM_VNET.ADAM_BETA1 = 0.9\n","    cfg.OPTIM_VNET.ADAM_BETA2 = 0.999\n","    cfg.OPTIM_VNET.STAGED_LR = False\n","    cfg.OPTIM_VNET.NEW_LAYERS = ()\n","    cfg.OPTIM_VNET.BASE_LR_MULT = 0.1\n","    # Learning rate scheduler\n","    cfg.OPTIM_VNET.LR_SCHEDULER = \"single_step\"\n","    # -1 or 0 means the stepsize is equal to max_epoch\n","    cfg.OPTIM_VNET.STEPSIZE = (-1, )\n","    cfg.OPTIM_VNET.GAMMA = 0.1\n","    cfg.OPTIM_VNET.MAX_EPOCH = 10\n","    # Set WARMUP_EPOCH larger than 0 to activate warmup training\n","    cfg.OPTIM_VNET.WARMUP_EPOCH = -1\n","    # Either linear or constant\n","    cfg.OPTIM_VNET.WARMUP_TYPE = \"linear\"\n","    # Constant learning rate when type=constant\n","    cfg.OPTIM_VNET.WARMUP_CONS_LR = 1e-5\n","    # Minimum learning rate when type=linear\n","    cfg.OPTIM_VNET.WARMUP_MIN_LR = 1e-5\n","    # Recount epoch for the next scheduler (last_epoch=-1)\n","    # Otherwise last_epoch=warmup_epoch\n","    cfg.OPTIM_VNET.WARMUP_RECOUNT = True\n","\n","def setup_cfg(args):\n","    cfg = get_cfg_default()\n","    extend_cfg(cfg)\n","    # 1. From the dataset config file\n","    if args.dataset_config_file:\n","        cfg.merge_from_file(args.dataset_config_file)\n","    # 2. From the method config file\n","    if args.config_file:\n","        cfg.merge_from_file(args.config_file)\n","    # 3. From input arguments\n","    reset_cfg(cfg, args)\n","    cfg.freeze()\n","    return cfg\n","\n","_tokenizer = _Tokenizer()\n","\n","def load_clip_to_cpu(cfg): # Load CLIP\n","    backbone_name = cfg.MODEL.BACKBONE.NAME\n","    url = clip._MODELS[backbone_name]\n","    model_path = clip._download(url)\n","\n","    try:\n","        # loading JIT archive\n","        model = torch.jit.load(model_path, map_location=\"cpu\").eval()\n","        state_dict = None\n","\n","    except RuntimeError:\n","        state_dict = torch.load(model_path, map_location=\"cpu\")\n","\n","    if cfg.TRAINER.NAME == \"\":\n","      design_trainer = \"CoOp\"\n","    else:\n","      design_trainer = cfg.TRAINER.NAME\n","    design_details = {\"trainer\": design_trainer,\n","                      \"vision_depth\": 0,\n","                      \"language_depth\": 0, \"vision_ctx\": 0,\n","                      \"language_ctx\": 0}\n","    model = clip.build_model(state_dict or model.state_dict(), design_details)\n","\n","    return model\n","\n","from dassl.config import get_cfg_default\n","cfg = get_cfg_default()\n","cfg.MODEL.BACKBONE.NAME = \"ViT-B/16\" # Set the vision encoder backbone of CLIP to ViT.\n","clip_model = load_clip_to_cpu(cfg)\n","\n","\n","\n","class TextEncoder(nn.Module):\n","    def __init__(self, clip_model): # ì´ˆê¸°í™” í•˜ëŠ” í•¨ìˆ˜\n","        super().__init__()\n","        self.transformer = clip_model.transformer\n","        self.positional_embedding = clip_model.positional_embedding\n","        self.ln_final = clip_model.ln_final\n","        self.text_projection = clip_model.text_projection\n","        self.dtype = clip_model.dtype\n","\n","    def forward(self, prompts, tokenized_prompts): # ëª¨ë¸ í˜¸ì¶œ\n","        x = prompts + self.positional_embedding.type(self.dtype)\n","        x = x.permute(1, 0, 2)  # NLD -> LND\n","        x = self.transformer(x)\n","        x = x.permute(1, 0, 2)  # LND -> NLD\n","        x = self.ln_final(x).type(self.dtype)\n","\n","        # x.shape = [batch_size, n_ctx, transformer.width]\n","        # take features from the eot embedding (eot_token is the highest number in each sequence)\n","        x = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)] @ self.text_projection\n","\n","        return x\n","\n","\n","@TRAINER_REGISTRY.register(force=True)\n","class CoCoOp(TrainerX):\n","    def check_cfg(self, cfg):\n","        assert cfg.TRAINER.COCOOP.PREC in [\"fp16\", \"fp32\", \"amp\"]\n","\n","    def build_model(self):\n","        cfg = self.cfg\n","        classnames = self.dm.dataset.classnames\n","        print(f\"Loading CLIP (backbone: {cfg.MODEL.BACKBONE.NAME})\")\n","        clip_model = load_clip_to_cpu(cfg)\n","\n","        if cfg.TRAINER.COCOOP.PREC == \"fp32\" or cfg.TRAINER.COCOOP.PREC == \"amp\":\n","            # CLIP's default precision is fp16\n","            clip_model.float()\n","\n","        print(\"Building custom CLIP\")\n","        self.model = CoCoOpCustomCLIP(cfg, classnames, clip_model)\n","\n","        print(\"Turning off gradients in both the image and the text encoder\")\n","        name_to_update = \"prompt_learner\"\n","\n","        for name, param in self.model.named_parameters():\n","            if name_to_update not in name:\n","                param.requires_grad_(False)\n","\n","        # Double check\n","        enabled = set()\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad:\n","                enabled.add(name)\n","        print(f\"Parameters to be updated: {enabled}\")\n","\n","        if cfg.MODEL.INIT_WEIGHTS:\n","            load_pretrained_weights(self.model.prompt_learner, cfg.MODEL.INIT_WEIGHTS)\n","\n","        self.model.to(self.device)\n","        # NOTE: only give prompt_learner to the optimizer\n","        self.optim = build_optimizer(self.model.prompt_learner, cfg.OPTIM)\n","        self.sched = build_lr_scheduler(self.optim, cfg.OPTIM)\n","        self.register_model(\"prompt_learner\", self.model.prompt_learner, self.optim, self.sched)\n","\n","        self.scaler = GradScaler() if cfg.TRAINER.COCOOP.PREC == \"amp\" else None\n","\n","        # Note that multi-gpu training could be slow because CLIP's size is\n","        # big, which slows down the copy operation in DataParallel\n","        device_count = torch.cuda.device_count()\n","        if device_count > 1:\n","            print(f\"Multiple GPUs detected (n_gpus={device_count}), use all of them!\")\n","            self.model = nn.DataParallel(self.model)\n","\n","    def before_train(self):\n","        directory = self.cfg.OUTPUT_DIR\n","        if self.cfg.RESUME:\n","            directory = self.cfg.RESUME\n","        self.start_epoch = self.resume_model_if_exist(directory)\n","\n","        # Remember the starting time (for computing the elapsed time)\n","        self.time_start = time.time()\n","\n","\n","    def forward_backward(self, batch):\n","        image, label = self.parse_batch_train(batch)\n","\n","        model = self.model\n","        optim = self.optim\n","        scaler = self.scaler\n","\n","        prec = self.cfg.TRAINER.COCOOP.PREC\n","        loss = model(image, label) # Input image ëª¨ë¸ í†µê³¼\n","        optim.zero_grad()\n","        loss.backward() # Backward (ì—­ì „íŒŒ)\n","        optim.step() # ëª¨ë¸ parameter update\n","\n","        loss_summary = {\"loss\": loss.item()}\n","\n","        if (self.batch_idx + 1) == self.num_batches:\n","            self.update_lr()\n","\n","        return loss_summary\n","\n","    def parse_batch_train(self, batch):\n","        input = batch[\"img\"]\n","        label = batch[\"label\"]\n","        input = input.to(self.device)\n","        label = label.to(self.device)\n","        return input, label\n","\n","    def load_model(self, directory, epoch=None):\n","        if not directory:\n","            print(\"Note that load_model() is skipped as no pretrained model is given\")\n","            return\n","\n","        names = self.get_model_names()\n","\n","        # By default, the best model is loaded\n","        model_file = \"model-best.pth.tar\"\n","\n","        if epoch is not None:\n","            model_file = \"model.pth.tar-\" + str(epoch)\n","\n","        for name in names:\n","            model_path = osp.join(directory, name, model_file)\n","\n","            if not osp.exists(model_path):\n","                raise FileNotFoundError('Model not found at \"{}\"'.format(model_path))\n","\n","            checkpoint = load_checkpoint(model_path)\n","            state_dict = checkpoint[\"state_dict\"]\n","            epoch = checkpoint[\"epoch\"]\n","\n","            # Ignore fixed token vectors\n","            if \"token_prefix\" in state_dict:\n","                del state_dict[\"token_prefix\"]\n","\n","            if \"token_suffix\" in state_dict:\n","                del state_dict[\"token_suffix\"]\n","\n","            print(\"Loading weights to {} \" 'from \"{}\" (epoch = {})'.format(name, model_path, epoch))\n","            # set strict=False\n","            self._models[name].load_state_dict(state_dict, strict=False)\n","\n","    def after_train(self):\n","      print(\"Finish training\")\n","\n","      do_test = not self.cfg.TEST.NO_TEST\n","      if do_test:\n","          if self.cfg.TEST.FINAL_MODEL == \"best_val\":\n","              print(\"Deploy the model with the best val performance\")\n","              self.load_model(self.output_dir)\n","          else:\n","              print(\"Deploy the last-epoch model\")\n","          acc = self.test()\n","\n","      # Show elapsed time\n","      elapsed = round(time.time() - self.time_start)\n","      elapsed = str(datetime.timedelta(seconds=elapsed))\n","      print(f\"Elapsed: {elapsed}\")\n","\n","      # Close writer\n","      self.close_writer()\n","      return acc\n","\n","    def train(self):\n","        \"\"\"Generic training loops.\"\"\"\n","        self.before_train()\n","        for self.epoch in range(self.start_epoch, self.max_epoch):\n","            self.before_epoch()\n","            self.run_epoch()\n","            self.after_epoch()\n","        acc = self.after_train()\n","        return acc\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--root\", type=str, default=\"data/\", help=\"path to dataset\")\n","parser.add_argument(\"--output-dir\", type=str, default=\"outputs/cocoop3\", help=\"output directory\")\n","parser.add_argument(\n","    \"--seed\", type=int, default=1, help=\"only positive value enables a fixed seed\"\n",")\n","parser.add_argument(\n","    \"--config-file\", type=str, default=\"configs/trainers/ProMetaR/vit_b16_c2_ep10_batch4_4+4ctx.yaml\", help=\"path to config file\"\n",")\n","parser.add_argument(\n","    \"--dataset-config-file\",\n","    type=str,\n","    default=\"configs/datasets/eurosat.yaml\",\n","    help=\"path to config file for dataset setup\",\n",")\n","parser.add_argument(\"--trainer\", type=str, default=\"CoOp\", help=\"name of trainer\")\n","parser.add_argument(\"--eval-only\", action=\"store_true\", help=\"evaluation only\")\n","parser.add_argument(\n","    \"--model-dir\",\n","    type=str,\n","    default=\"\",\n","    help=\"load model from this directory for eval-only mode\",\n",")\n","parser.add_argument(\"--train-batch-size\", type=int, default=4)\n","parser.add_argument(\"--epoch\", type=int, default=10)\n","parser.add_argument(\"--subsample-classes\", type=str, default=\"base\")\n","parser.add_argument(\n","    \"--load-epoch\", type=int, default=0, help=\"load model weights at this epoch for evaluation\"\n",")\n","args = parser.parse_args([])\n","\n","def main(args):\n","    cfg = setup_cfg(args)\n","    if cfg.SEED >= 0:\n","        set_random_seed(cfg.SEED)\n","\n","    if torch.cuda.is_available() and cfg.USE_CUDA:\n","        torch.backends.cudnn.benchmark = True\n","\n","    trainer = build_trainer(cfg)\n","    if args.eval_only:\n","        trainer.load_model(args.model_dir, epoch=args.load_epoch)\n","        acc = trainer.test()\n","        return acc\n","\n","    acc = trainer.train()\n","    return acc"],"metadata":{"id":"Dj8mLRimgaha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9IRNAMNAgbG-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from trl import SFTTrainer\n","import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","\n","\n","class DialoguePromptLearner(nn.Module):\n","    def __init__(self, model, tokenizer, cfg):\n","        super().__init__()\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","        # Configuration for prompt learning\n","        self.n_ctx = cfg.get('n_ctx', 8)  # Number of context tokens to learn\n","        self.ctx_init = cfg.get('ctx_init', '')  # Optional initialization text\n","        self.ctx_dim = model.config.hidden_size\n","\n","        # Initialize context vectors\n","        if self.ctx_init:\n","            # Initialize with given words\n","            ctx_init = self.ctx_init.replace('_', ' ')\n","            n_ctx = len(ctx_init.split())\n","            prompt_tokens = tokenizer(ctx_init, return_tensors='pt')\n","            with torch.no_grad():\n","                embedding = model.get_input_embeddings()(prompt_tokens['input_ids'][0, :n_ctx])\n","            self.ctx = nn.Parameter(embedding)\n","        else:\n","            # Random initialization\n","            self.ctx = nn.Parameter(torch.randn(self.n_ctx, self.ctx_dim))\n","\n","        # Meta network for instance-specific prompts\n","        self.meta_net = nn.Sequential(OrderedDict([\n","            (\"linear1\", nn.Linear(self.ctx_dim, self.ctx_dim // 16)),\n","            (\"relu\", nn.ReLU(inplace=True)),\n","            (\"linear2\", nn.Linear(self.ctx_dim // 16, self.ctx_dim))\n","        ]))\n","\n","    def forward(self, inputs):\n","        batch_size = inputs['input_ids'].size(0)\n","\n","        # Get scene embeddings (using [CLS] token output)\n","        with torch.no_grad():\n","            scene_features = self.model.get_encoder()(\n","                input_ids=inputs['input_ids'],\n","                attention_mask=inputs['attention_mask']\n","            ).last_hidden_state[:, 0]  # Use [CLS] token\n","\n","        # Generate instance-specific bias\n","        bias = self.meta_net(scene_features)  # (batch, ctx_dim)\n","        bias = bias.unsqueeze(1)  # (batch, 1, ctx_dim)\n","\n","        # Apply bias to context tokens\n","        ctx = self.ctx.unsqueeze(0).expand(batch_size, -1, -1)  # (batch, n_ctx, ctx_dim)\n","        ctx_shifted = ctx + bias  # (batch, n_ctx, ctx_dim)\n","\n","        # Prepare prompted input\n","        prompted_embeddings = self.model.get_input_embeddings()(inputs['input_ids'])\n","\n","        # Insert learned context tokens after instruction/before input\n","        instruction_end = (inputs['input_ids'] == self.tokenizer.encode(\"### Input:\", add_special_tokens=False)[0]).nonzero()[:, 1]\n","        for i in range(batch_size):\n","            idx = instruction_end[i]\n","            prompted_embeddings[i] = torch.cat([\n","                prompted_embeddings[i, :idx],\n","                ctx_shifted[i],\n","                prompted_embeddings[i, idx:]\n","            ], dim=0)\n","\n","        return prompted_embeddings\n","\n","class CoCoOpSFTTrainer(SFTTrainer):\n","    def __init__(self, *args, prompt_tuning_config=None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.prompt_learner = DialoguePromptLearner(\n","            self.model,\n","            self.tokenizer,\n","            prompt_tuning_config or {}\n","        )\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        # Get prompted embeddings\n","        prompted_embeddings = self.prompt_learner(inputs)\n","\n","        # Replace the standard embeddings with prompted ones\n","        original_forward = self.model.forward\n","\n","        def prompted_forward(*args, **kwargs):\n","            kwargs['inputs_embeds'] = prompted_embeddings\n","            kwargs['input_ids'] = None\n","            return original_forward(*args, **kwargs)\n","\n","        self.model.forward = prompted_forward\n","\n","        # Compute loss using parent class\n","        loss = super().compute_loss(model, inputs, return_outputs)\n","\n","        # Restore original forward\n","        self.model.forward = original_forward\n","\n","        return loss"],"metadata":{"id":"Ak1nHEYlgFIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_dialogue_with_prompts(instruction, scene, characters):\n","    input_text = f\"Scene:\\n{scene}\\n\\nCharacter Information:\\n{characters}\"\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","    # Get prompted embeddings\n","    prompted_embeddings = trainer.prompt_learner(inputs)\n","\n","    # Generate with prompted embeddings\n","    outputs = model.generate(\n","        inputs_embeds=prompted_embeddings,\n","        **generation_params\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"_SJHkD1TgQtB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","from transformers import TextStreamer\n","\n","class DialoguePromptLearner(nn.Module):\n","    def __init__(self, model, tokenizer):\n","        super().__init__()\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","        # Configuration\n","        self.n_ctx = 8  # í•™ìŠµí•  ì»¨í…ìŠ¤íŠ¸ í† í° ìˆ˜\n","        self.ctx_dim = model.config.hidden_size\n","\n","        # ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ì´ˆê¸°í™” (ëœë¤)\n","        self.ctx = nn.Parameter(torch.randn(self.n_ctx, self.ctx_dim))\n","\n","        # ë©”íƒ€ ë„¤íŠ¸ì›Œí¬ ì •ì˜\n","        self.meta_net = nn.Sequential(OrderedDict([\n","            (\"linear1\", nn.Linear(self.ctx_dim, self.ctx_dim // 16)),\n","            (\"relu\", nn.ReLU(inplace=True)),\n","            (\"linear2\", nn.Linear(self.ctx_dim // 16, self.ctx_dim))\n","        ])).to(model.device)\n","\n","    def forward(self, inputs):\n","        batch_size = inputs['input_ids'].size(0)\n","\n","        # ì”¬ ì„ë² ë”© ì¶”ì¶œ ([CLS] í† í° ì¶œë ¥ ì‚¬ìš©)\n","        with torch.no_grad():\n","            outputs = self.model.get_encoder()(\n","                input_ids=inputs['input_ids'].to(self.model.device),\n","                attention_mask=inputs['attention_mask'].to(self.model.device)\n","            )\n","            scene_features = outputs.last_hidden_state[:, 0]\n","\n","        # ì¸ìŠ¤í„´ìŠ¤ë³„ ë°”ì´ì–´ìŠ¤ ìƒì„±\n","        bias = self.meta_net(scene_features)\n","        bias = bias.unsqueeze(1)\n","\n","        # ì»¨í…ìŠ¤íŠ¸ í† í°ì— ë°”ì´ì–´ìŠ¤ ì ìš©\n","        ctx = self.ctx.unsqueeze(0).expand(batch_size, -1, -1)\n","        ctx_shifted = ctx + bias\n","\n","        # í”„ë¡¬í”„íŠ¸ëœ ì…ë ¥ ì¤€ë¹„\n","        prompted_embeddings = self.model.get_input_embeddings()(inputs['input_ids'].to(self.model.device))\n","\n","        # instructionê³¼ input ì‚¬ì´ì— í•™ìŠµëœ ì»¨í…ìŠ¤íŠ¸ í† í° ì‚½ì…\n","        instruction_marker = \"### Input:\"\n","        marker_ids = self.tokenizer.encode(instruction_marker, add_special_tokens=False)[0]\n","        instruction_end = (inputs['input_ids'] == marker_ids).nonzero()[:, 1]\n","\n","        new_embeddings = []\n","        for i in range(batch_size):\n","            idx = instruction_end[i]\n","            new_emb = torch.cat([\n","                prompted_embeddings[i, :idx],\n","                ctx_shifted[i],\n","                prompted_embeddings[i, idx:]\n","            ], dim=0)\n","            new_embeddings.append(new_emb)\n","\n","        return torch.stack(new_embeddings)\n","\n","# CoCoOpì„ ì‚¬ìš©í•œ ì¸í¼ëŸ°ìŠ¤ í•¨ìˆ˜\n","def generate_dialogue_with_cocoop(model, tokenizer, instruction, input_text, prompt_learner):\n","    # ì…ë ¥ í…ìŠ¤íŠ¸ ì¤€ë¹„\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    )\n","\n","    # í”„ë¡¬í”„íŠ¸ëœ ì„ë² ë”© ìƒì„±\n","    prompted_embeddings = prompt_learner(inputs)\n","\n","    # í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ streamer ì„¤ì •\n","    text_streamer = TextStreamer(tokenizer)\n","\n","    # ìƒì„± íŒŒë¼ë¯¸í„°\n","    generation_params = {\n","        \"max_new_tokens\": 256,\n","        \"temperature\": 0.2,\n","        \"top_p\": 0.2,\n","        \"do_sample\": True,\n","        \"streamer\": text_streamer,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","    }\n","\n","    # í…ìŠ¤íŠ¸ ìƒì„±\n","    outputs = model.generate(\n","        inputs_embeds=prompted_embeddings,\n","        **generation_params\n","    )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# í”„ë¡¬í”„íŠ¸ ëŸ¬ë„ˆ ì´ˆê¸°í™” ë° ì¸í¼ëŸ°ìŠ¤ ì‹¤í–‰\n","prompt_learner = DialoguePromptLearner(model, tokenizer)\n","\n","# í…ŒìŠ¤íŠ¸ ì˜ˆì‹œë¡œ ì¸í¼ëŸ°ìŠ¤ ì‹¤í–‰\n","def test_cocoop_inference(test_n):\n","    print(\"Generating dialogue with CoCoOp...\")\n","\n","    test_instruction = train_json[test_n]['instruction']\n","    test_input = train_json[test_n]['input']\n","\n","    # CoCoOpì„ ì‚¬ìš©í•œ ëŒ€í™” ìƒì„±\n","    generated_text = generate_dialogue_with_cocoop(\n","        model,\n","        tokenizer,\n","        test_instruction,\n","        test_input,\n","        prompt_learner\n","    )\n","\n","    print(\"\\n=== Generated Response ===\")\n","    print(generated_text)\n","\n","    print(\"\\n=== Correct Response ===\")\n","    print(train_json[test_n]['output'], \"<|end_of_text|>\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"qbLARvoqhE7w","executionInfo":{"status":"error","timestamp":1733799853293,"user_tz":-540,"elapsed":392,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"217d4342-1b6e-4a26-9067-8342c9738a08"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'DialogueCoCoOpModel' object has no attribute 'config'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-f707b54299ee>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# í”„ë¡¬í”„íŠ¸ ëŸ¬ë„ˆ ì´ˆê¸°í™” ë° ì¸í¼ëŸ°ìŠ¤ ì‹¤í–‰\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mprompt_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDialoguePromptLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# í…ŒìŠ¤íŠ¸ ì˜ˆì‹œë¡œ ì¸í¼ëŸ°ìŠ¤ ì‹¤í–‰\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-47-f707b54299ee>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m  \u001b[0;31m# í•™ìŠµí•  ì»¨í…ìŠ¤íŠ¸ í† í° ìˆ˜\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ì´ˆê¸°í™” (ëœë¤)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'DialogueCoCoOpModel' object has no attribute 'config'"]}]},{"cell_type":"code","source":["# íŠ¹ì • í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‹¤í–‰\n","test_cocoop_inference(test_n=0)  # ë˜ëŠ” ë‹¤ë¥¸ ì¸ë±ìŠ¤"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"-KzWVF9zhjx9","executionInfo":{"status":"error","timestamp":1733799866673,"user_tz":-540,"elapsed":297,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"b1f9377d-4707-4062-b6d0-b462e3a7fd45"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'test_cocoop_inference' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-df30d73526b1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# íŠ¹ì • í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¡œ ì‹¤í–‰\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_cocoop_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ë˜ëŠ” ë‹¤ë¥¸ ì¸ë±ìŠ¤\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'test_cocoop_inference' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cFdn6MWKh2Uv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nyijEPT5il_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XylMv4RcimEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","from transformers import TextStreamer\n","\n","class DialoguePromptLearner(nn.Module):\n","    def __init__(self, model, tokenizer):\n","        super().__init__()\n","        self.base_model = model  # FastLanguageModel ì¸ìŠ¤í„´ìŠ¤\n","        self.tokenizer = tokenizer\n","\n","        # FastLanguageModelì˜ êµ¬ì¡°ì— ë§ì¶° ì„¤ì •\n","        self.n_ctx = 8  # í•™ìŠµí•  ì»¨í…ìŠ¤íŠ¸ í† í° ìˆ˜\n","        # model.config.hidden_sizeë¡œ ì§ì ‘ ì ‘ê·¼\n","        self.ctx_dim = model.config.hidden_size\n","        self.device = next(model.parameters()).device\n","\n","        # ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ì´ˆê¸°í™” (ëœë¤)\n","        self.ctx = nn.Parameter(torch.randn(self.n_ctx, self.ctx_dim, device=self.device))\n","\n","        # ë©”íƒ€ ë„¤íŠ¸ì›Œí¬ ì •ì˜\n","        self.meta_net = nn.Sequential(OrderedDict([\n","            (\"linear1\", nn.Linear(self.ctx_dim, self.ctx_dim // 16)),\n","            (\"relu\", nn.ReLU(inplace=True)),\n","            (\"linear2\", nn.Linear(self.ctx_dim // 16, self.ctx_dim))\n","        ])).to(self.device)\n","\n","    def forward(self, inputs):\n","        batch_size = inputs['input_ids'].size(0)\n","\n","        # ì”¬ ì„ë² ë”© ì¶”ì¶œ\n","        with torch.no_grad():\n","            input_ids = inputs['input_ids'].to(self.device)\n","            attention_mask = inputs['attention_mask'].to(self.device)\n","\n","            # FastLanguageModelì˜ ì„ë² ë”© ë ˆì´ì–´ ì§ì ‘ ì ‘ê·¼\n","            embeddings = self.base_model.embed_tokens(input_ids)\n","            scene_features = embeddings[:, 0]\n","\n","        # ì¸ìŠ¤í„´ìŠ¤ë³„ ë°”ì´ì–´ìŠ¤ ìƒì„±\n","        bias = self.meta_net(scene_features)\n","        bias = bias.unsqueeze(1)\n","\n","        # ì»¨í…ìŠ¤íŠ¸ í† í°ì— ë°”ì´ì–´ìŠ¤ ì ìš©\n","        ctx = self.ctx.unsqueeze(0).expand(batch_size, -1, -1)\n","        ctx_shifted = ctx + bias\n","\n","        # í”„ë¡¬í”„íŠ¸ëœ ì…ë ¥ ì¤€ë¹„\n","        prompted_embeddings = self.base_model.embed_tokens(input_ids)\n","\n","        # instructionê³¼ input ì‚¬ì´ì— í•™ìŠµëœ ì»¨í…ìŠ¤íŠ¸ í† í° ì‚½ì…\n","        instruction_marker = \"### Input:\"\n","        marker_ids = self.tokenizer.encode(instruction_marker, add_special_tokens=False)[0]\n","        instruction_end = (input_ids == marker_ids).nonzero()[:, 1]\n","\n","        new_embeddings = []\n","        for i in range(batch_size):\n","            idx = instruction_end[i]\n","            new_emb = torch.cat([\n","                prompted_embeddings[i, :idx],\n","                ctx_shifted[i],\n","                prompted_embeddings[i, idx:]\n","            ], dim=0)\n","            new_embeddings.append(new_emb)\n","\n","        return torch.stack(new_embeddings)\n","\n","def generate_dialogue_with_cocoop(model, tokenizer, instruction, input_text, prompt_learner):\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    )\n","\n","    # í”„ë¡¬í”„íŠ¸ëœ ì„ë² ë”© ìƒì„±\n","    prompted_embeddings = prompt_learner(inputs)\n","\n","    # í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ streamer ì„¤ì •\n","    text_streamer = TextStreamer(tokenizer)\n","\n","    # ìƒì„± íŒŒë¼ë¯¸í„°\n","    generation_params = {\n","        \"max_new_tokens\": 256,\n","        \"temperature\": 0.2,\n","        \"top_p\": 0.2,\n","        \"do_sample\": True,\n","        \"streamer\": text_streamer,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","    }\n","\n","    # FastLanguageModel generate í˜¸ì¶œ\n","    outputs = model.generate(\n","        inputs_embeds=prompted_embeddings,\n","        attention_mask=torch.ones_like(inputs['input_ids']),\n","        **generation_params\n","    )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n","def test_cocoop_inference(model, tokenizer, train_json, test_n=0):\n","    print(\"Initializing CoCoOp prompt learner...\")\n","    prompt_learner = DialoguePromptLearner(model, tokenizer)\n","\n","    print(\"\\nGenerating dialogue with CoCoOp...\")\n","    test_instruction = train_json[test_n]['instruction']\n","    test_input = train_json[test_n]['input']\n","\n","    generated_text = generate_dialogue_with_cocoop(\n","        model,\n","        tokenizer,\n","        test_instruction,\n","        test_input,\n","        prompt_learner\n","    )\n","\n","    print(\"\\n=== Generated Response ===\")\n","    print(generated_text)\n","\n","    print(\"\\n=== Correct Response ===\")\n","    print(train_json[test_n]['output'], \"<|end_of_text|>\")"],"metadata":{"id":"fj3wzdKAimL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FastLanguageModelì´ ì´ë¯¸ ì¤€ë¹„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •\n","test_cocoop_inference(model, tokenizer, train_data, test_n=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"OK7p-dlfiqqJ","executionInfo":{"status":"error","timestamp":1733800331502,"user_tz":-540,"elapsed":299,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"ed5cd856-971d-44d8-c7dc-e00a60baa195"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing CoCoOp prompt learner...\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'DialogueCoCoOpModel' object has no attribute 'config'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-3d1bab104f2e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# FastLanguageModelì´ ì´ë¯¸ ì¤€ë¹„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_cocoop_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-59-34bbaecbff3f>\u001b[0m in \u001b[0;36mtest_cocoop_inference\u001b[0;34m(model, tokenizer, train_json, test_n)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_cocoop_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing CoCoOp prompt learner...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mprompt_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDialoguePromptLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGenerating dialogue with CoCoOp...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-59-34bbaecbff3f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m  \u001b[0;31m# í•™ìŠµí•  ì»¨í…ìŠ¤íŠ¸ í† í° ìˆ˜\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# model.config.hidden_sizeë¡œ ì§ì ‘ ì ‘ê·¼\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'DialogueCoCoOpModel' object has no attribute 'config'"]}]},{"cell_type":"code","source":["print(\"Model type:\", type(model))\n","print(\"Available attributes:\", [attr for attr in dir(model) if not attr.startswith('_')])\n","\n","# ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° êµ¬ì¡°ë„ í™•ì¸\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name}, Shape: {param.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASbbiEaPjfFq","executionInfo":{"status":"ok","timestamp":1733800403349,"user_tz":-540,"elapsed":345,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"9e8e6490-cea7-47aa-9a34-57ba38b1c02d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model type: <class '__main__.DialogueCoCoOpModel'>\n","Available attributes: ['T_destination', 'add_module', 'apply', 'base_model', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'context_encoder', 'cpu', 'cuda', 'dialogue_encoder', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'load_state_dict', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'prompt_learner', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prefix_tokens, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.meta_lr, Shape: torch.Size([1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.embed_tokens.weight, Shape: torch.Size([128256, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.norm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.lm_head.weight, Shape: torch.Size([128256, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_attention.in_proj_weight, Shape: torch.Size([2304, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_attention.in_proj_bias, Shape: torch.Size([2304])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_attention.out_proj.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_attention.out_proj.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.1.weight, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.1.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.3.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.3.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.4.weight, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.4.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.1.weight, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.1.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.3.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.3.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.4.weight, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.4.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.0.weight, Shape: torch.Size([1536, 2304])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.0.bias, Shape: torch.Size([1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.1.weight, Shape: torch.Size([1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.1.bias, Shape: torch.Size([1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.3.weight, Shape: torch.Size([7680, 1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.3.bias, Shape: torch.Size([7680])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: dialogue_encoder.2.bias, Shape: torch.Size([768])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","from transformers import TextStreamer\n","\n","class DialoguePromptLearner(nn.Module):\n","    def __init__(self, model, tokenizer):\n","        super().__init__()\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","        # ì‹¤ì œ ëª¨ë¸ì˜ hidden size ê°€ì ¸ì˜¤ê¸°\n","        self.ctx_dim = 4096  # ëª¨ë¸ ì¶œë ¥ì—ì„œ í™•ì¸ëœ í¬ê¸°\n","        self.n_ctx = 8  # í•™ìŠµí•  ì»¨í…ìŠ¤íŠ¸ í† í° ìˆ˜\n","\n","        # device ê°€ì ¸ì˜¤ê¸°\n","        self.device = next(model.parameters()).device\n","\n","        # ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ì´ˆê¸°í™” (ëœë¤)\n","        self.ctx = nn.Parameter(torch.randn(self.n_ctx, self.ctx_dim, device=self.device))\n","\n","        # ë©”íƒ€ ë„¤íŠ¸ì›Œí¬ ì •ì˜\n","        self.meta_net = nn.Sequential(OrderedDict([\n","            (\"linear1\", nn.Linear(self.ctx_dim, self.ctx_dim // 16)),\n","            (\"relu\", nn.ReLU(inplace=True)),\n","            (\"linear2\", nn.Linear(self.ctx_dim // 16, self.ctx_dim))\n","        ])).to(self.device)\n","\n","    def forward(self, inputs):\n","        batch_size = inputs['input_ids'].size(0)\n","\n","        # ì…ë ¥ì„ ì¥ì¹˜ë¡œ ì´ë™\n","        input_ids = inputs['input_ids'].to(self.device)\n","        attention_mask = inputs['attention_mask'].to(self.device)\n","\n","        # ê¸°ë³¸ ëª¨ë¸ì—ì„œ ì„ë² ë”© ì¶”ì¶œ\n","        # base_model ê²½ë¡œ ë‹¨ìˆœí™” ë° device í™•ì¸\n","        base_model = self.model.base_model\n","        while hasattr(base_model, 'base_model'):\n","            base_model = base_model.base_model\n","        base_model = base_model.model\n","\n","        with torch.no_grad():\n","            # ëª¨ë¸ì˜ ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì„ë² ë”©\n","            embeddings = base_model.model.embed_tokens(input_ids)\n","            scene_features = embeddings[:, 0]  # [CLS] í† í° ì„ë² ë”© ì‚¬ìš©\n","\n","        # ì»¨í…ìŠ¤íŠ¸ ì¡°ì •ì„ ìœ„í•œ ë©”íƒ€ ë„¤íŠ¸ì›Œí¬\n","        bias = self.meta_net(scene_features)  # (batch, ctx_dim)\n","        bias = bias.unsqueeze(1)  # (batch, 1, ctx_dim)\n","\n","        # ì»¨í…ìŠ¤íŠ¸ í† í° í™•ì¥ ë° ë°”ì´ì–´ìŠ¤ ì ìš©\n","        ctx = self.ctx.unsqueeze(0).expand(batch_size, -1, -1)  # (batch, n_ctx, ctx_dim)\n","        ctx_shifted = ctx + bias  # (batch, n_ctx, ctx_dim)\n","\n","        # í”„ë¡¬í”„íŠ¸ëœ ì„ë² ë”© ì¤€ë¹„\n","        prompted_embeddings = base_model.model.embed_tokens(input_ids)\n","\n","        # instructionê³¼ input ì‚¬ì´ì— í•™ìŠµëœ ì»¨í…ìŠ¤íŠ¸ í† í° ì‚½ì…\n","        instruction_marker = \"### Input:\"\n","        marker_ids = torch.tensor(self.tokenizer.encode(instruction_marker, add_special_tokens=False)[0]).to(self.device)\n","        instruction_end = (input_ids == marker_ids).nonzero()[:, 1]\n","\n","        new_embeddings = []\n","        for i in range(batch_size):\n","            idx = instruction_end[i]\n","            new_emb = torch.cat([\n","                prompted_embeddings[i, :idx],\n","                ctx_shifted[i],\n","                prompted_embeddings[i, idx:]\n","            ], dim=0)\n","            new_embeddings.append(new_emb)\n","\n","        return torch.stack(new_embeddings)\n","\n","def generate_dialogue_with_cocoop(model, tokenizer, instruction, input_text, prompt_learner):\n","    # ì…ë ¥ í…ìŠ¤íŠ¸ ì¤€ë¹„\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","    # ì…ë ¥ì„ GPUë¡œ ì´ë™\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    ).to(prompt_learner.device)\n","\n","    # í”„ë¡¬í”„íŠ¸ëœ ì„ë² ë”© ìƒì„±\n","    prompted_embeddings = prompt_learner(inputs)\n","\n","    # í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ streamer ì„¤ì •\n","    text_streamer = TextStreamer(tokenizer)\n","\n","    # ìƒì„± íŒŒë¼ë¯¸í„°\n","    generation_params = {\n","        \"max_new_tokens\": 256,\n","        \"temperature\": 0.2,\n","        \"top_p\": 0.2,\n","        \"do_sample\": True,\n","        \"streamer\": text_streamer,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","    }\n","\n","    # FastLanguageModelì— ë§ì¶˜ ìƒì„± í”„ë¡œì„¸ìŠ¤\n","    outputs = model.generate(\n","        inputs_embeds=prompted_embeddings,\n","        attention_mask=torch.ones_like(inputs['input_ids']).to(prompt_learner.device),\n","        **generation_params\n","    )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜\n","def test_cocoop_inference(model, tokenizer, train_json, test_n=0):\n","    print(\"Initializing CoCoOp prompt learner...\")\n","    prompt_learner = DialoguePromptLearner(model, tokenizer)\n","\n","    print(\"\\nGenerating dialogue with CoCoOp...\")\n","    test_instruction = train_json[test_n]['instruction']\n","    test_input = train_json[test_n]['input']\n","\n","    generated_text = generate_dialogue_with_cocoop(\n","        model,\n","        tokenizer,\n","        test_instruction,\n","        test_input,\n","        prompt_learner\n","    )\n","\n","    print(\"\\n=== Generated Response ===\")\n","    print(generated_text)\n","\n","    print(\"\\n=== Correct Response ===\")\n","    print(train_json[test_n]['output'], \"<|end_of_text|>\")"],"metadata":{"id":"IJ2F5KvQjg2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_cocoop_inference(model, tokenizer, train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"KgDs7PiJj-eH","executionInfo":{"status":"error","timestamp":1733806390501,"user_tz":-540,"elapsed":5833571,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"c8db0e9a-c638-4ec8-c49c-21792f2cd647"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing CoCoOp prompt learner...\n","\n","Generating dialogue with CoCoOp...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-4e9da33f2a86>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_cocoop_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-68-7c7980acc2b5>\u001b[0m in \u001b[0;36mtest_cocoop_inference\u001b[0;34m(model, tokenizer, train_json, test_n)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     generated_text = generate_dialogue_with_cocoop(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-7c7980acc2b5>\u001b[0m in \u001b[0;36mgenerate_dialogue_with_cocoop\u001b[0;34m(model, tokenizer, instruction, input_text, prompt_learner)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# í”„ë¡¬í”„íŠ¸ëœ ì„ë² ë”© ìƒì„±\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mprompted_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ streamer ì„¤ì •\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-7c7980acc2b5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'base_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mbase_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m         \"\"\"\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### Eval"],"metadata":{"id":"gDvBFfDXo6sU"}},{"cell_type":"code","source":[],"metadata":{"id":"MY_j9zvio6Kl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import json\n","\n","# output_train_path = '/content/drive/MyDrive/Colab Notebooks/Harry Potter Alpaca/Harry Potter Alpaca/hpa_train_set.json'\n","# output_test_path = '/content/drive/MyDrive/Colab Notebooks/Harry Potter Alpaca/Harry Potter Alpaca/hpa_test_set.json'\n","# formatted_dataset_path = '/content/drive/MyDrive/Colab Notebooks/Harry Potter Alpaca/Harry Potter Alpaca/hpa_formatted_dataset'\n","\n","# with open(output_train_path, 'r', encoding='utf-8') as f:\n","#     train_data = json.load(f)\n","\n","# with open(output_test_path, 'r', encoding='utf-8') as f:\n","#     test_data = json.load(f)\n","\n","# # ë‚˜ì¤‘ì— ë°ì´í„°ì…‹ì„ ë‹¤ì‹œ ë¡œë“œí•  ë•ŒëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n","# from datasets import load_from_disk\n","# formatted_dataset = load_from_disk(formatted_dataset_path)"],"metadata":{"id":"6k26yUOMxci3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","# ëª¨ë¸ì„ inference ëª¨ë“œë¡œ ì„¤ì •\n","FastLanguageModel.for_inference(model)\n","\n","test_result = []\n","\n","# ------------------------------------------------------------------------\n","for test_n in range(200):\n","    # í…ŒìŠ¤íŠ¸í•  ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ ìƒì„±\n","    test_instruction = test_data[test_n]['instruction']\n","    test_input = test_data[test_n]['input']\n","\n","    # ì…ë ¥ í…ìŠ¤íŠ¸ ìƒì„±\n","    inputs = tokenizer(\n","        [\n","            alpaca_prompt.format(\n","                test_instruction,  # instruction\n","                test_input,       # input\n","                \"\",              # output - ìƒì„±ì„ ìœ„í•´ ë¹„ì›Œë‘ \n","            )\n","        ],\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","    # í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ streamer ì„¤ì •\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","\n","    # ìƒì„± íŒŒë¼ë¯¸í„° ì„¤ì •\n","    generation_params = {\n","        \"max_new_tokens\": 256,      # ë” ê¸´ ëŒ€í™”ë¥¼ ìœ„í•´ ì¦ê°€\n","        \"temperature\": 0.2,         # ì°½ì˜ì„± ì¡°ì ˆ (0.7)\n","        \"top_p\": 0.2,              # ë‹¤ì–‘ì„± ì¡°ì ˆ (0.9)\n","        \"do_sample\": True,         # ë‹¤ì–‘í•œ ì‘ë‹µ ìƒì„± ê°€ëŠ¥\n","        \"streamer\": text_streamer,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","    }\n","\n","    # í…ìŠ¤íŠ¸ ìƒì„±\n","    print(\"Data\", test_n)\n","    print(\"Generating dialogue...\")\n","    outputs = model.generate(**inputs, **generation_params)\n","\n","    print(\"### Correct Dialogue:\")\n","    print(test_data[test_n]['output'], \"<|end_of_text|>\")\n","\n","    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"### Response:\")[1].strip()\n","    ground_truth = test_data[test_n]['output'] + \"<|end_of_text|>\"\n","    test_result.append({\n","        \"prediction\": prediction,\n","        \"ground_truth\": ground_truth\n","    })"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733838944721,"user_tz":-540,"elapsed":241817,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"361b180e-bf3d-4ef9-a4d4-3516a2d1ce16","id":"nqZYXWLqxci7"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Data 100\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Knuts?\n","\n","### Response:\n","Hagrid: Galleons.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school. <|end_of_text|>\n","Data 101\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,\n","Harry: Knuts?\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Um â€” Hagrid? <|end_of_text|>\n","Data 102\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.\n","Harry: Um â€” Hagrid?\n","\n","### Response:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Mm? <|end_of_text|>\n","Data 103\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.\n","Harry: Um â€” Hagrid?\n","Hagrid: Mm?\n","\n","### Response:\n","Hagrid: What?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: I havenâ€™t got any money â€” and you heard Uncle Vernon last night . . . he wonâ€™t pay for me to go and learn magic. But if their house was destroyed â€” <|end_of_text|>\n","Data 104\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Um â€” Hagrid?\n","Hagrid: Mm?\n","Harry: I havenâ€™t got any money â€” and you heard Uncle Vernon last night... he wonâ€™t pay for me to go and learn magic. But if their house was destroyed â€”\n","\n","### Response:\n","Hagrid: Donâ€™t worry, Harry. Weâ€™ll get you sorted out.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither. <|end_of_text|>\n","Data 105\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: I havenâ€™t got any money â€” and you heard Uncle Vernon last night... he wonâ€™t pay for me to go and learn magic. But if their house was destroyed â€”\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither.\n","\n","### Response:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Wizards have banks? <|end_of_text|>\n","Data 106\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither.\n","Harry: Wizards have banks?\n","\n","### Response:\n","Hagrid: They do, they do.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Just the one. <|end_of_text|>\n","Data 107\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Wizards have banks?\n","Hagrid: Just the one.\n","\n","### Response:\n","Hagrid: Gringotts.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? <|end_of_text|>\n","Data 108\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins?\n","\n","### Response:\n","Hagrid: Goblins?<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He usually gets me ter do important stuff fer him. Fetchinâ€™ you â€” gettinâ€™ things from Gringotts â€” knows he can trust me, see. Got everythinâ€™? Come on, then.  <|end_of_text|>\n","Data 109\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: It was a dream, I dreamed a giant called Hagrid came to tell me I was going to a school for wizards. When I open my eyes Iâ€™ll be at home in my cupboard. And thereâ€™s Aunt Petunia knocking on the door, All right, Iâ€™m getting up. Donâ€™t do that.\n","\n","### Response:\n","Hagrid: Itâ€™s not a dream, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Pay him, <|end_of_text|>\n","Data 110\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Pay him,\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: What? What? <|end_of_text|>\n","Data 111\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Pay him,\n","Harry: What? What?\n","\n","### Response:\n","Hagrid: Pay him,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts, <|end_of_text|>\n","Data 112\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Knuts? <|end_of_text|>\n","Data 113\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,\n","Harry: Knuts?\n","\n","### Response:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school. <|end_of_text|>\n","Data 114\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Um â€” Hagrid? <|end_of_text|>\n","Data 115\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.\n","Harry: Um â€” Hagrid?\n","\n","### Response:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Mm? <|end_of_text|>\n","Data 116\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Mm?\n","\n","### Response:\n","Harry: What?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: I havenâ€™t got any money â€” and you heard Uncle Vernon last night . . . he wonâ€™t pay for me to go and learn magic. But if their house was destroyed â€” <|end_of_text|>\n","Data 117\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Um â€” Hagrid?\n","Hagrid: Mm?\n","Harry: I havenâ€™t got any money â€” and you heard Uncle Vernon last night... he wonâ€™t pay for me to go and learn magic. But if their house was destroyed â€”\n","\n","### Response:\n","Hagrid: Well, I dunno what Dumbledoreâ€™s got in mind, Harry, but Iâ€™m sure yehâ€™ll be all right.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither. <|end_of_text|>\n","Data 118\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither.\n","\n","### Response:\n","Harry: Iâ€™m not allowed to eat between meals.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Wizards have banks? <|end_of_text|>\n","Data 119\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Wizards have banks?\n","\n","### Response:\n","Hagrid: Gringotts, Harry. Gringotts is the wizard bank.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Just the one. <|end_of_text|>\n","Data 120\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither.\n","Harry: Wizards have banks?\n","Hagrid: Just the one.\n","\n","### Response:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? <|end_of_text|>\n","Data 121\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Wizards have banks?\n","Hagrid: Just the one.\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins?\n","\n","### Response:\n","Hagrid: Gringotts is the wizard bank, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He usually gets me ter do important stuff fer him. Fetchinâ€™ you â€” gettinâ€™ things from Gringotts â€” knows he can trust me, see. Got everythinâ€™? Come on, then.  <|end_of_text|>\n","Data 122\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: It was a dream, I dreamed a giant called Hagrid came to tell me I was going to a school for wizards. When I open my eyes Iâ€™ll be at home in my cupboard. And thereâ€™s Aunt Petunia knocking on the door, All right, Iâ€™m getting up. Donâ€™t do that.\n","\n","### Response:\n","Hagrid: Iâ€™m not a dream, Harry. Youâ€™re not in your cupboard. Youâ€™re at Hogwarts.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Pay him, <|end_of_text|>\n","Data 123\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Pay him,\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: What? What? <|end_of_text|>\n","Data 124\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: It was a dream, I dreamed a giant called Hagrid came to tell me I was going to a school for wizards. When I open my eyes Iâ€™ll be at home in my cupboard. And thereâ€™s Aunt Petunia knocking on the door, All right, Iâ€™m getting up. Donâ€™t do that.\n","Hagrid: Pay him,\n","Harry: What? What?\n","\n","### Response:\n","Hagrid: The owl.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts, <|end_of_text|>\n","Data 125\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Pay him,\n","Harry: What? What?\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,\n","\n","### Response:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Knuts? <|end_of_text|>\n","Data 126\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: What? What?\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,\n","Harry: Knuts?\n","\n","### Response:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school. <|end_of_text|>\n","Data 127\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts,\n","Harry: Knuts?\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.\n","\n","### Response:\n","Hagrid: He wants payinâ€™ fer deliverinâ€™ the paper. Look in the pockets. Give him five Knuts, Harry: Knuts? Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Um â€” Hagrid? <|end_of_text|>\n","Data 128\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Knuts?\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.\n","Harry: Um â€” Hagrid?\n","\n","### Response:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London anâ€™ buy all yer stuff fer school.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Mm? <|end_of_text|>\n","Data 129\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Um â€” Hagrid?\n","Hagrid: Mm?\n","\n","### Response:\n","Hagrid: Well, Iâ€™m sorry, Harry, but Iâ€™ve got important business with Dumbledore. Iâ€™ll be back for you at half past four.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: I havenâ€™t got any money â€” and you heard Uncle Vernon last night . . . he wonâ€™t pay for me to go and learn magic. But if their house was destroyed â€” <|end_of_text|>\n","Data 130\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Mm?\n","Harry: I havenâ€™t got any money â€” and you heard Uncle Vernon last night... he wonâ€™t pay for me to go and learn magic. But if their house was destroyed â€”\n","\n","### Response:\n","Hagrid: Well, I dunno, Harry. I dunno how Dumbledoreâ€™ll take it. Heâ€™s the headmaster, yeh see, so heâ€™s in charge of all the students, anâ€™ heâ€™s that strict â€”<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither. <|end_of_text|>\n","Data 131\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither.\n","\n","### Response:\n","Harry: Iâ€™m not allowed to eat after midnight.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Wizards have banks? <|end_of_text|>\n","Data 132\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didnâ€™ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizardsâ€™ bank. Have a sausage, theyâ€™re not bad cold â€” anâ€™ I wouldnâ€™ say no teh a bit oâ€™ yer birthday cake, neither.\n","Harry: Wizards have banks?\n","\n","### Response:\n","Hagrid: Theyâ€™ve got a lot oâ€™ things Muggles havenâ€™t, boy. Gringotts has got loads oâ€™ gold. Anâ€™ itâ€™s guarded by a load oâ€™ goblins.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Just the one. <|end_of_text|>\n","Data 133\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Just the one.\n","\n","### Response:\n","Harry: Yes, please.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? <|end_of_text|>\n","Data 134\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Wizards have banks?\n","Hagrid: Just the one.\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins?\n","\n","### Response:\n","Hagrid: Gringotts is the wizarding bank. It's run by goblins.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He usually gets me ter do important stuff fer him. Fetchinâ€™ you â€” gettinâ€™ things from Gringotts â€” knows he can trust me, see. Got everythinâ€™? Come on, then.  <|end_of_text|>\n","Data 135\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Got everythinâ€™? Come on, then.\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: How did you get here? <|end_of_text|>\n","Data 136\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","\n","### Response:\n","Hagrid: I flew.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Flew, <|end_of_text|>\n","Data 137\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","Hagrid: Flew,\n","\n","### Response:\n","Hagrid: Flew,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Flew? <|end_of_text|>\n","Data 138\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Flew,\n","Harry: Flew?\n","\n","### Response:\n","Hagrid: Flew,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yeah  <|end_of_text|>\n","Data 139\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Flew?\n","Hagrid: Yeah \n","\n","### Response:\n","Hagrid: Yeah, I flew.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts? <|end_of_text|>\n","Data 140\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","\n","### Response:\n","Hagrid: Because itâ€™s impossible, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Spells â€” enchantments, They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual, <|end_of_text|>\n","Data 141\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","Hagrid: Spells â€” enchantments, They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual,\n","\n","### Response:\n","Hagrid: They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Thereâ€™s a Ministry of Magic? <|end_of_text|>\n","Data 142\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Thereâ€™s a Ministry of Magic?\n","\n","### Response:\n","Hagrid: Yeah, itâ€™s in London.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: â€™Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askinâ€™ fer advice. <|end_of_text|>\n","Data 143\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: â€™Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askinâ€™ fer advice.\n","\n","### Response:\n","Harry: What?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: But what does a Ministry of Magic do? <|end_of_text|>\n","Data 144\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Thereâ€™s a Ministry of Magic?\n","Hagrid: â€™Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askinâ€™ fer advice.\n","Harry: But what does a Ministry of Magic do?\n","\n","### Response:\n","Hagrid: Keep the Muggles out, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country. <|end_of_text|>\n","Data 145\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: But what does a Ministry of Magic do?\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.\n","\n","### Response:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why? Why? Why? <|end_of_text|>\n","Data 146\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: But what does a Ministry of Magic do?\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.\n","Harry: Why? Why? Why?\n","\n","### Response:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Why? Blimey, Harry, everyoneâ€™d be wantinâ€™ magic solutions to their problems. Nah, weâ€™re best left alone. <|end_of_text|>\n","Data 147\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Got everythinâ€™? Come on, then.\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: How did you get here? <|end_of_text|>\n","Data 148\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Got everythinâ€™? Come on, then.\n","Harry: How did you get here?\n","\n","### Response:\n","Hagrid: Flew.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Flew, <|end_of_text|>\n","Data 149\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Flew,\n","\n","### Response:\n","Harry: What?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Flew? <|end_of_text|>\n","Data 150\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","Hagrid: Flew,\n","Harry: Flew?\n","\n","### Response:\n","Hagrid: Flew,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yeah  <|end_of_text|>\n","Data 151\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Flew?\n","Hagrid: Yeah \n","\n","### Response:\n","Hagrid: Yeah, I flew.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts? <|end_of_text|>\n","Data 152\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","\n","### Response:\n","Hagrid: Because itâ€™s impossible.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Spells â€” enchantments, They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual, <|end_of_text|>\n","Data 153\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Spells â€” enchantments, They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual,\n","\n","### Response:\n","Hagrid: They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Thereâ€™s a Ministry of Magic? <|end_of_text|>\n","Data 154\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Thereâ€™s a Ministry of Magic?\n","\n","### Response:\n","Hagrid: Yeah, itâ€™s in London.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: â€™Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askinâ€™ fer advice. <|end_of_text|>\n","Data 155\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: â€™Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askinâ€™ fer advice.\n","\n","### Response:\n","Harry: Whatâ€™s the Ministry of Magic?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: But what does a Ministry of Magic do? <|end_of_text|>\n","Data 156\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: â€™Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askinâ€™ fer advice.\n","Harry: But what does a Ministry of Magic do?\n","\n","### Response:\n","Hagrid: Well, they keep the Muggles out, donâ€™ they?<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country. <|end_of_text|>\n","Data 157\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.\n","\n","### Response:\n","Harry: What do they do with the Muggles who find out about us?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why? Why? Why? <|end_of_text|>\n","Data 158\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: But what does a Ministry of Magic do?\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.\n","Harry: Why? Why? Why?\n","\n","### Response:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Why? Blimey, Harry, everyoneâ€™d be wantinâ€™ magic solutions to their problems. Nah, weâ€™re best left alone. <|end_of_text|>\n","Data 159\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Got everythinâ€™? Come on, then.\n","\n","### Response:\n","Harry: Whatâ€™s that?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: How did you get here? <|end_of_text|>\n","Data 160\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","\n","### Response:\n","Hagrid: I flew.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Flew, <|end_of_text|>\n","Data 161\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","Hagrid: Flew,\n","\n","### Response:\n","Hagrid: Iâ€™m not supposed to tell you that, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Flew? <|end_of_text|>\n","Data 162\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Flew,\n","Harry: Flew?\n","\n","### Response:\n","Hagrid: Yeah, I did.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yeah  <|end_of_text|>\n","Data 163\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Flew,\n","Harry: Flew?\n","Hagrid: Yeah \n","\n","### Response:\n","Harry: You flew?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts? <|end_of_text|>\n","Data 164\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","\n","### Response:\n","Hagrid: Because itâ€™s impossible, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Spells â€” enchantments, They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual, <|end_of_text|>\n","Data 165\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","Hagrid: Spells â€” enchantments, They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual,\n","\n","### Response:\n","Hagrid: They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Thereâ€™s a Ministry of Magic? <|end_of_text|>\n","Data 166\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","Hagrid: Spells â€” enchantments, They say thereâ€™s dragons guardinâ€™ the high-security vaults. And then yeh gotta find yer way â€” Gringotts is hundreds of miles under London, see. Deep under the Underground. Yehâ€™d die of hunger tryinâ€™ ter get out, even if yeh did manage ter get yer hands on summat. Ministry oâ€™ Magic messinâ€™ things up as usual,\n","Harry: Thereâ€™s a Ministry of Magic?\n","\n","### Response:\n","Hagrid: Yeah, theyâ€™re the ones who keep the Muggles from findinâ€™ out about us.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: â€™Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askinâ€™ fer advice. <|end_of_text|>\n","Data 167\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: â€™Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askinâ€™ fer advice.\n","\n","### Response:\n","Harry: Whatâ€™s the Ministry of Magic?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: But what does a Ministry of Magic do? <|end_of_text|>\n","Data 168\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: But what does a Ministry of Magic do?\n","\n","### Response:\n","Hagrid: They keep the Muggles from finding out about us, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country. <|end_of_text|>\n","Data 169\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.\n","\n","### Response:\n","Harry: Whatâ€™s the Ministry of Magic?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why? Why? Why? <|end_of_text|>\n","Data 170\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.\n","Harry: Why? Why? Why?\n","\n","### Response:\n","Hagrid: Well, their main job is to keep it from the Muggles that thereâ€™s still witches anâ€™ wizards up anâ€™ down the country.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Why? Blimey, Harry, everyoneâ€™d be wantinâ€™ magic solutions to their problems. Nah, weâ€™re best left alone. <|end_of_text|>\n","Data 171\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","\n","Relations:\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also chaffer the Apothecary to buy potion ingredients, and Hagrid call to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","\n","### Response:\n","Hagrid: Don't be daft, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh, <|end_of_text|>\n","Data 172\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","\n","Relations:\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also chaffer the Apothecary to buy potion ingredients, and Hagrid call to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,\n","\n","### Response:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: You donâ€™t have to â€” <|end_of_text|>\n","Data 173\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","\n","Relations:\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also chaffer the Apothecary to buy potion ingredients, and Hagrid call to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,\n","Harry: You donâ€™t have to â€”\n","\n","### Response:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I know I donâ€™t have to. Tell yeh what, Iâ€™ll get yer animal. Not a toad, toads went outta fashion years ago, yehâ€™d be laughed at anâ€™ I donâ€™ like cats, they make me sneeze. <|end_of_text|>\n","Data 174\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Harry:\n","- age: age 11\n","- name: Harry\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- gender: male\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- lineage: wizard\n","- age: Adult\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to bargain Harry's school books. Harry was fascinated by the variety of books, including single on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as A birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","\n","### Response:\n","Hagrid: You can't use magic in the Muggle world, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh, <|end_of_text|>\n","Data 175\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Harry:\n","- age: age 11\n","- name: Harry\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- gender: male\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- lineage: wizard\n","- age: Adult\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to bargain Harry's school books. Harry was fascinated by the variety of books, including single on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as A birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,\n","\n","### Response:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™t work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: You donâ€™t have to â€” <|end_of_text|>\n","Data 176\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Harry:\n","- age: age 11\n","- name: Harry\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- gender: male\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- lineage: wizard\n","- age: Adult\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to bargain Harry's school books. Harry was fascinated by the variety of books, including single on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as A birthday present.\n","\n","Previous Dialogue:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,\n","Harry: You donâ€™t have to â€”\n","\n","### Response:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh canâ€™t work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I know I donâ€™t have to. Tell yeh what, Iâ€™ll get yer animal. Not a toad, toads went outta fashion years ago, yehâ€™d be laughed at anâ€™ I donâ€™ like cats, they make me sneeze. <|end_of_text|>\n","Data 177\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Character Information:\n","Harry:\n","- gender: male\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one along curses that he wanted to use on Dudley. Hagrid remind Harry that he couldn't use magic in the Muggle world. They also shoot_the_breeze the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","\n","### Response:\n","Hagrid: You canâ€™t use magic in the Muggle world, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh, <|end_of_text|>\n","Data 178\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Character Information:\n","Harry:\n","- gender: male\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one along curses that he wanted to use on Dudley. Hagrid remind Harry that he couldn't use magic in the Muggle world. They also shoot_the_breeze the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,\n","\n","### Response:\n","Hagrid: Iâ€™m not sayinâ€™ thatâ€™s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, Anâ€™ anyway, yeh couldnâ€™ work any of them curses yet, yehâ€™ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: You donâ€™t have to â€” <|end_of_text|>\n","Data 179\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Character Information:\n","Harry:\n","- gender: male\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one along curses that he wanted to use on Dudley. Hagrid remind Harry that he couldn't use magic in the Muggle world. They also shoot_the_breeze the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: You donâ€™t have to â€”\n","\n","### Response:\n","Hagrid: I know, I know, but I want ter.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I know I donâ€™t have to. Tell yeh what, Iâ€™ll get yer animal. Not a toad, toads went outta fashion years ago, yehâ€™d be laughed at anâ€™ I donâ€™ like cats, they make me sneeze. <|end_of_text|>\n","Data 180\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Donâ€™ mention it, Donâ€™ expect youâ€™ve had a lotta presents from them Dursleys. Just Ollivanders left now â€” only place fer wands, Ollivanders, and yeh gotta have the best wand.\n","\n","### Response:\n","Harry: I know.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Good afternoon, <|end_of_text|>\n","Data 181\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Good afternoon,\n","\n","### Response:\n","Hagrid: Good afternoon, sir.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Hello, <|end_of_text|>\n","Data 182\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Good afternoon,\n","Harry: Hello,\n","\n","### Response:\n","Ollivanders: Youâ€™re the boy who came in here a few years ago, arenâ€™t you?<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it â€” itâ€™s really the wand that chooses the wizard, of course Oh, Yew. <|end_of_text|>\n","Data 183\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Harry: Hello,\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it â€” itâ€™s really the wand that chooses the wizard, of course Oh, Yew.\n","\n","### Response:\n","Hagrid:<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: It was, sir, yes, <|end_of_text|>\n","Data 184\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it â€” itâ€™s really the wand that chooses the wizard, of course Oh, Yew.\n","Hagrid: It was, sir, yes,\n","\n","### Response:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it â€” itâ€™s really the wand that chooses the wizard, of course Oh, Yew.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled? <|end_of_text|>\n","Data 185\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled?\n","\n","### Response:\n","Hagrid: No, they didnâ€™t.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yes, Iâ€™ve still got the pieces, though, <|end_of_text|>\n","Data 186\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: It was, sir, yes,\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled?\n","Hagrid: Yes, Iâ€™ve still got the pieces, though,\n","\n","### Response:\n","Hagrid: It was, sir, yes, Good wand, that one. But I suppose they snapped it in half when you got expelled? Yes, Iâ€™ve still got the pieces, though,<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: But you donâ€™t use them? <|end_of_text|>\n","Data 187\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled?\n","Hagrid: Yes, Iâ€™ve still got the pieces, though,\n","Ollivanders: But you donâ€™t use them?\n","\n","### Response:\n","Hagrid: No, I donâ€™t use them.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Oh, <|end_of_text|>\n","Data 188\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Yes, Iâ€™ve still got the pieces, though,\n","Ollivanders: But you donâ€™t use them?\n","Hagrid: Oh,\n","\n","### Response:\n","Hagrid: No, Iâ€™m not much of a wizard, yeh know.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Well, <|end_of_text|>\n","Data 189\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Oh,\n","Ollivanders: Well,\n","\n","### Response:\n","Hagrid: Well,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Oh, <|end_of_text|>\n","Data 190\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Well,\n","Harry: Oh,\n","\n","### Response:\n","Ollivanders: Well,<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Oh, Oh, Curious . . . curious . . . I remember every wand Iâ€™ve ever sold, Mr. Potter. Every single wand. It so happens that the phoenix whose tail feather is in your wand, gave another feather â€” just one other. It is very curious indeed that you should be destined for this wand when its brother â€” why, its brother gave you that scar. Yes, thirteen-and-a-half inches. Yew. Yew. Curious indeed how these things happen. The wand chooses the wizard, remember.. . . I think we must expect great things from you, Mr. Potter. . . . After all, He-Who-Must-Not-Be-Named did great things â€” terrible, yes, but great. <|end_of_text|>\n","Data 191\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Donâ€™ mention it, Donâ€™ expect youâ€™ve had a lotta presents from them Dursleys. Just Ollivanders left now â€” only place fer wands, Ollivanders, and yeh gotta have the best wand.\n","\n","### Response:\n","Hagrid: Donâ€™ mention it, Donâ€™ expect youâ€™ve had a lotta presents from them Dursleys. Just Ollivanders left now â€” only place fer wands, Ollivanders, and yeh gotta have the best wand.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Good afternoon, <|end_of_text|>\n","Data 192\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Donâ€™ mention it, Donâ€™ expect youâ€™ve had a lotta presents from them Dursleys. Just Ollivanders left now â€” only place fer wands, Ollivanders, and yeh gotta have the best wand.\n","Ollivanders: Good afternoon,\n","\n","### Response:\n","Hagrid: Donâ€™ mention it, Donâ€™ expect youâ€™ve had a lotta presents from them Dursleys. Just Ollivanders left now â€” only place fer wands, Ollivanders, and yeh gotta have the best wand.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Hello, <|end_of_text|>\n","Data 193\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Harry: Hello,\n","\n","### Response:\n","Ollivander: Hello, hello, hello, and who might you be?<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it â€” itâ€™s really the wand that chooses the wizard, of course Oh, Yew. <|end_of_text|>\n","Data 194\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Harry: Hello,\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it â€” itâ€™s really the wand that chooses the wizard, of course Oh, Yew.\n","\n","### Response:\n","Hagrid:<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: It was, sir, yes, <|end_of_text|>\n","Data 195\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it â€” itâ€™s really the wand that chooses the wizard, of course Oh, Yew.\n","Hagrid: It was, sir, yes,\n","\n","### Response:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it â€” itâ€™s really the wand that chooses the wizard, of course Oh, Yew.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled? <|end_of_text|>\n","Data 196\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: It was, sir, yes,\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled?\n","\n","### Response:\n","Hagrid: It was, sir, yes,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yes, Iâ€™ve still got the pieces, though, <|end_of_text|>\n","Data 197\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Yes, Iâ€™ve still got the pieces, though,\n","\n","### Response:\n","Hagrid: Yes, Iâ€™ve still got the pieces, though,<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: But you donâ€™t use them? <|end_of_text|>\n","Data 198\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Yes, Iâ€™ve still got the pieces, though,\n","Ollivanders: But you donâ€™t use them?\n","\n","### Response:\n","Hagrid: No, I donâ€™t.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Oh, <|end_of_text|>\n","Data 199\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: But you donâ€™t use them?\n","Hagrid: Oh,\n","\n","### Response:\n","Hagrid: Oh, no, sir, Iâ€™m not much of a wizard, Iâ€™m afraid.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Well, <|end_of_text|>\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","\n","# ì €ì¥í•  ê²½ë¡œ ì„¤ì •\n","save_path = '/content/drive/MyDrive/Colab Notebooks/test_results(lora).json'\n","\n","# JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥\n","with open(save_path, 'w', encoding='utf-8') as f:\n","    json.dump(test_result, f, ensure_ascii=False, indent=2)\n","\n","print(f'Results saved to: {save_path}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyd7iYlLgmDf","executionInfo":{"status":"ok","timestamp":1733839791907,"user_tz":-540,"elapsed":379,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"12679240-9bbd-4534-8d24-0b95dbee9289"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Results saved to: /content/drive/MyDrive/Colab Notebooks/test_results(lora).json\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"h8JEWkZohpdX"}},{"cell_type":"code","source":["# Install required packages\n","!pip install -q transformers torch sentence-transformers nltk\n","\n","import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from nltk.lm import MLE\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from scipy.spatial.distance import cosine\n","from sentence_transformers import SentenceTransformer\n","import nltk\n","\n","# Download ALL required NLTK data at the start\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger')\n","\n","def calculate_bleu(reference, hypothesis):\n","    \"\"\"\n","    Calculate BLEU score between reference and hypothesis\n","    \"\"\"\n","    # Tokenize the sentences\n","    ref_tokens = nltk.word_tokenize(reference.lower())\n","    hyp_tokens = nltk.word_tokenize(hypothesis.lower())\n","\n","    # Calculate BLEU score with smoothing\n","    smoothing = SmoothingFunction().method1\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoothing)\n","\n","def calculate_meteor(reference, hypothesis):\n","    \"\"\"\n","    Calculate METEOR score between reference and hypothesis\n","    \"\"\"\n","    return meteor_score([reference.split()], hypothesis.split())\n","\n","def calculate_perplexity(text, model_name='gpt2'):\n","    \"\"\"\n","    Calculate perplexity using GPT-2\n","    \"\"\"\n","    # Load model and tokenizer\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    model.eval()\n","\n","    # Encode text\n","    encodings = tokenizer(text, return_tensors='pt')\n","\n","    # Calculate perplexity\n","    max_length = model.config.n_positions\n","    stride = 512\n","    seq_len = encodings.input_ids.size(1)\n","\n","    nlls = []\n","    prev_end_loc = 0\n","    for begin_loc in range(0, seq_len, stride):\n","        end_loc = min(begin_loc + max_length, seq_len)\n","        trg_len = end_loc - prev_end_loc\n","        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n","        target_ids = input_ids.clone()\n","        target_ids[:, :-trg_len] = -100\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, labels=target_ids)\n","            neg_log_likelihood = outputs.loss\n","\n","        nlls.append(neg_log_likelihood)\n","        prev_end_loc = end_loc\n","        if end_loc == seq_len:\n","            break\n","\n","    ppl = torch.exp(torch.stack(nlls).mean())\n","    return ppl.item()\n","\n","def calculate_simile(reference, hypothesis):\n","    \"\"\"\n","    Calculate SIMILE (Semantic Similarity) score using sentence transformers\n","    \"\"\"\n","    # Load sentence transformer model\n","    model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","    # Get embeddings\n","    ref_embedding = model.encode([reference])[0]\n","    hyp_embedding = model.encode([hypothesis])[0]\n","\n","    # Calculate cosine similarity\n","    similarity = 1 - cosine(ref_embedding, hyp_embedding)\n","    return similarity\n","\n","def evaluate_json_responses(test_result):\n","    \"\"\"\n","    Calculate metrics for JSON list containing predictions and ground truths\n","\n","    Args:\n","        test_result (list): List of dictionaries with 'prediction' and 'ground_truth' keys\n","\n","    Returns:\n","        dict: Dictionary containing average scores for all metrics\n","    \"\"\"\n","    scores = {\n","        'bleu': [],\n","        'meteor': [],\n","        'perplexity': [],\n","        'simile': []\n","    }\n","\n","    for item in test_result:\n","        # Extract prediction and ground truth\n","        prediction = item['prediction']\n","        ground_truth = item['ground_truth']\n","\n","        # Remove special tokens if present\n","        ground_truth = ground_truth.replace('<|end_of_text|>', '').strip()\n","\n","        # Calculate scores\n","        scores['bleu'].append(calculate_bleu(ground_truth, prediction))\n","        scores['meteor'].append(calculate_meteor(ground_truth, prediction))\n","        scores['perplexity'].append(calculate_perplexity(prediction))\n","        scores['simile'].append(calculate_simile(ground_truth, prediction))\n","\n","    # Calculate averages\n","    return {metric: np.mean(values) for metric, values in scores.items()}"],"metadata":{"id":"smvIacvzhlU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","# JSON íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n","with open('/content/drive/MyDrive/Colab Notebooks/ë”¥ëŸ¬ë‹ í”„ë¡œì íŠ¸/test_results(lora).json', 'r', encoding='utf-8') as f:\n","    loaded_result = json.load(f)\n","\n","scores = evaluate_json_responses(loaded_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xk2zTBRF6Rbw","executionInfo":{"status":"ok","timestamp":1733841721332,"user_tz":-540,"elapsed":209507,"user":{"displayName":"ë°•ê²½ë¹ˆ","userId":"04876725348542542168"}},"outputId":"35b26f12-0940-4a76-a2d1-5e03cb65e3b5"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Average Metrics:\n","Average BLEU Score: 0.2191\n","Average METEOR Score: 0.2675\n","Average Perplexity: 26.4606\n","Average SIMILE Score: 0.9512\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1efOx_rwZeF3i0YsirhM1xhYLtGNX6Fv3","timestamp":1733403104209},{"file_id":"18KF6yNW9pRS7lwYk8zRLRI_otrpL84ev","timestamp":1713732901332},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1713724264856},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}],"gpuType":"T4","collapsed_sections":["fROHRlcGdfNs"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"52f9b70227734735a77025b1547a4f7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e18f78b0a6c04c8db654ad8abf40856c","IPY_MODEL_13abce7bc961407b80aef01ca37e0fff","IPY_MODEL_6afd34f975714df989c95557bb172114"],"layout":"IPY_MODEL_ea30410ff5b94e36aa7f1ae04c2041cb"}},"e18f78b0a6c04c8db654ad8abf40856c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8e19f6a2b594e67890184c887173466","placeholder":"â€‹","style":"IPY_MODEL_fd8bbe23de63456086beba03a3eb7015","value":"Map:â€‡100%"}},"13abce7bc961407b80aef01ca37e0fff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cba5291efb80400f8528a5a049bb7a31","max":44166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ad660d0f04d4c90a435e222d5a93436","value":44166}},"6afd34f975714df989c95557bb172114":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4246cf13026447c0b60a5c33dacf1b1a","placeholder":"â€‹","style":"IPY_MODEL_96d4081338c04ec19db1142e9b8557b1","value":"â€‡44166/44166â€‡[00:09&lt;00:00,â€‡6916.27â€‡examples/s]"}},"ea30410ff5b94e36aa7f1ae04c2041cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8e19f6a2b594e67890184c887173466":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd8bbe23de63456086beba03a3eb7015":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cba5291efb80400f8528a5a049bb7a31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad660d0f04d4c90a435e222d5a93436":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4246cf13026447c0b60a5c33dacf1b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d4081338c04ec19db1142e9b8557b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c420788c75cb4df0b73057c1f99fc2f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32cce8257910411381ae107f1b272f87","IPY_MODEL_c7f97e1a812c419d814d63ce35342af3","IPY_MODEL_991589b50c8c4cb8b3228397fe25fc42"],"layout":"IPY_MODEL_4f49199d63f7407ca0a9f00fedb6ca69"}},"32cce8257910411381ae107f1b272f87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c09c77a34ae4daba634d6f0922c42e3","placeholder":"â€‹","style":"IPY_MODEL_9881d8fac75446fbbadb75103be04060","value":"Map:â€‡100%"}},"c7f97e1a812c419d814d63ce35342af3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb0db9321a3043e98581240e0b446418","max":2601,"min":0,"orientation":"horizontal","style":"IPY_MODEL_643e63457df14b85a3f96185eb68f849","value":2601}},"991589b50c8c4cb8b3228397fe25fc42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e5d1fac31c1477cac1c32a694e7efdf","placeholder":"â€‹","style":"IPY_MODEL_900a48c9a1fc4dcfa5aa980185b6e4d5","value":"â€‡2601/2601â€‡[00:00&lt;00:00,â€‡26311.26â€‡examples/s]"}},"4f49199d63f7407ca0a9f00fedb6ca69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c09c77a34ae4daba634d6f0922c42e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9881d8fac75446fbbadb75103be04060":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb0db9321a3043e98581240e0b446418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643e63457df14b85a3f96185eb68f849":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e5d1fac31c1477cac1c32a694e7efdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900a48c9a1fc4dcfa5aa980185b6e4d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4e87718aa47491eb9f69a420836f207":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_004f69c8123f445898206cfb4d15ded8","IPY_MODEL_0c9cda1d48dc4561b6671b3408a3c375","IPY_MODEL_4c3c24727a11472582b3119597c24341"],"layout":"IPY_MODEL_926e06cf281e40549fb1db6ab51a80e0"}},"004f69c8123f445898206cfb4d15ded8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4f6744cca874f36be142f33c570e79f","placeholder":"â€‹","style":"IPY_MODEL_87427d5afa494ad58ddb676da98aadd1","value":"Savingâ€‡theâ€‡datasetâ€‡(2/2â€‡shards):â€‡100%"}},"0c9cda1d48dc4561b6671b3408a3c375":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b1d303c7b8e40299675942ca6e8ad6e","max":44166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1b441a11f4c43e89a61e4ee94784664","value":44166}},"4c3c24727a11472582b3119597c24341":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be3ac3e413f441ae8f446eba8b453934","placeholder":"â€‹","style":"IPY_MODEL_570a8e8476554129bf9f2b4545f4b648","value":"â€‡44166/44166â€‡[00:12&lt;00:00,â€‡1279.06â€‡examples/s]"}},"926e06cf281e40549fb1db6ab51a80e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4f6744cca874f36be142f33c570e79f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87427d5afa494ad58ddb676da98aadd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b1d303c7b8e40299675942ca6e8ad6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1b441a11f4c43e89a61e4ee94784664":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be3ac3e413f441ae8f446eba8b453934":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"570a8e8476554129bf9f2b4545f4b648":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65ed847eec544f8dbb809936aa6cbd69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f96ff44f96a44bcb75b11cafb9d268d","IPY_MODEL_c27891e91cb949608bd0e1eef0f1efc8","IPY_MODEL_767002e4ac14423a96a07459745f730c"],"layout":"IPY_MODEL_00b36f1496b74c0a8ff0ce1709256745"}},"6f96ff44f96a44bcb75b11cafb9d268d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f3fd149169248f7a087ec9b18a34ad3","placeholder":"â€‹","style":"IPY_MODEL_1f5f8eebe3b94eb9aa8f6b9578291686","value":"Savingâ€‡theâ€‡datasetâ€‡(1/1â€‡shards):â€‡100%"}},"c27891e91cb949608bd0e1eef0f1efc8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_849df78437854f358bc43511beb4ec89","max":2601,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d0ff024983d456781895bccb2debbc7","value":2601}},"767002e4ac14423a96a07459745f730c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d827420671ac4e14af3fb8d7d106c50b","placeholder":"â€‹","style":"IPY_MODEL_7627743dd5bb4ecb84856bdb54482592","value":"â€‡2601/2601â€‡[00:00&lt;00:00,â€‡58144.31â€‡examples/s]"}},"00b36f1496b74c0a8ff0ce1709256745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f3fd149169248f7a087ec9b18a34ad3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f5f8eebe3b94eb9aa8f6b9578291686":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"849df78437854f358bc43511beb4ec89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d0ff024983d456781895bccb2debbc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d827420671ac4e14af3fb8d7d106c50b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7627743dd5bb4ecb84856bdb54482592":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6a97c45088c4a058ecf4d3eaf9f09f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2072faa03a0b4e729f8d7cc1957d0e5b","IPY_MODEL_eed68d78d3eb4c9eb01e0b9d27dd962d","IPY_MODEL_d875c797d8244582bbbc300da7f9de28"],"layout":"IPY_MODEL_0a4addfb1c7a4bc2a11703600d30da49"}},"2072faa03a0b4e729f8d7cc1957d0e5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_589182e5255b412f9deb87c7b49c8a8a","placeholder":"â€‹","style":"IPY_MODEL_57dd050c574a48f09e9dccf912136f9e","value":"Mapâ€‡(num_proc=2):â€‡100%"}},"eed68d78d3eb4c9eb01e0b9d27dd962d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb9af07731e24ea288a365a03f703802","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7ebb0bee0b147b494a29e1acf792845","value":500}},"d875c797d8244582bbbc300da7f9de28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7ee6c126ad4dd5b0a8a814960170e9","placeholder":"â€‹","style":"IPY_MODEL_670338d4087a44bcbe6430720e070236","value":"â€‡500/500â€‡[00:06&lt;00:00,â€‡42.41â€‡examples/s]"}},"0a4addfb1c7a4bc2a11703600d30da49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"589182e5255b412f9deb87c7b49c8a8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57dd050c574a48f09e9dccf912136f9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb9af07731e24ea288a365a03f703802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ebb0bee0b147b494a29e1acf792845":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d7ee6c126ad4dd5b0a8a814960170e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"670338d4087a44bcbe6430720e070236":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06b0b5c6bd4c4606b96c56586a5a969f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54f71e95d414421c8955d0ed6a72a0be","IPY_MODEL_7804471a616b4b3c82b25fb571cfdbbe","IPY_MODEL_11fe91b689df446db617cd60bc289862"],"layout":"IPY_MODEL_54f9c7b5ff8f47c994275e5e02bfcd9f"}},"54f71e95d414421c8955d0ed6a72a0be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b209a5ce1a4641fdbf9ea503acb0f108","placeholder":"â€‹","style":"IPY_MODEL_737e7fe57c8545bea4c2d7af1099e48e","value":"config.json:â€‡100%"}},"7804471a616b4b3c82b25fb571cfdbbe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3c9246062f147e48ba5f793cb8c1dac","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc6097ac48c54ea3a2da7c8532176b9d","value":665}},"11fe91b689df446db617cd60bc289862":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_248de5138a8243e288d8c5ed9b6b3a37","placeholder":"â€‹","style":"IPY_MODEL_7430be762ab44b9e9ad7476f9b408ead","value":"â€‡665/665â€‡[00:00&lt;00:00,â€‡39.1kB/s]"}},"54f9c7b5ff8f47c994275e5e02bfcd9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b209a5ce1a4641fdbf9ea503acb0f108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"737e7fe57c8545bea4c2d7af1099e48e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3c9246062f147e48ba5f793cb8c1dac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc6097ac48c54ea3a2da7c8532176b9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"248de5138a8243e288d8c5ed9b6b3a37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7430be762ab44b9e9ad7476f9b408ead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1a9193130964a32a15544dab5310d2a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9813b985e97c411fa554f362ee3c42b8","IPY_MODEL_da34e5ba9d4c4342875ab07be2257804","IPY_MODEL_ecc146ea7c744add8845eb093bac824b"],"layout":"IPY_MODEL_3cdc75bbc37b4ec2bed70355d60a9078"}},"9813b985e97c411fa554f362ee3c42b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c949bedfe5f4350b1731e4333d0871e","placeholder":"â€‹","style":"IPY_MODEL_ee457dcaa92b4f73a60408ac12cb3ccd","value":"model.safetensors:â€‡100%"}},"da34e5ba9d4c4342875ab07be2257804":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e9f6090106b4a7aacdc6bce521c9f83","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf9a90bb39d447a4abba2cec4ab6ed94","value":548105119}},"ecc146ea7c744add8845eb093bac824b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0101882a7c024f659558a1fb19244462","placeholder":"â€‹","style":"IPY_MODEL_b280b36a94734adbb1648fbd0d4e4d53","value":"â€‡548M/548Mâ€‡[00:03&lt;00:00,â€‡338MB/s]"}},"3cdc75bbc37b4ec2bed70355d60a9078":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c949bedfe5f4350b1731e4333d0871e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee457dcaa92b4f73a60408ac12cb3ccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e9f6090106b4a7aacdc6bce521c9f83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf9a90bb39d447a4abba2cec4ab6ed94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0101882a7c024f659558a1fb19244462":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b280b36a94734adbb1648fbd0d4e4d53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b5268fcc60d4b4f8ed5287516558f90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_350ad988dcc24b29985684cd87a01128","IPY_MODEL_3f925f435c644a2fbe2f10cb7095c199","IPY_MODEL_4b33ae6dbe3947878789154d3b7f69db"],"layout":"IPY_MODEL_60912685336a4324b19dcf106e8a30ad"}},"350ad988dcc24b29985684cd87a01128":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_786baba186ff40eb9f4923d306493d5f","placeholder":"â€‹","style":"IPY_MODEL_9d144ebfe96045eca3eb0a9cfa0914a8","value":"generation_config.json:â€‡100%"}},"3f925f435c644a2fbe2f10cb7095c199":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6803e762288c427cb0d6a7074473ec22","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c41796fbc16e4c77852bd772e275b1bf","value":124}},"4b33ae6dbe3947878789154d3b7f69db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4676d0e3769f404cb0cbde38a42c37ca","placeholder":"â€‹","style":"IPY_MODEL_6c9b78b2748e4aaeb14ff90f37c03038","value":"â€‡124/124â€‡[00:00&lt;00:00,â€‡4.72kB/s]"}},"60912685336a4324b19dcf106e8a30ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"786baba186ff40eb9f4923d306493d5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d144ebfe96045eca3eb0a9cfa0914a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6803e762288c427cb0d6a7074473ec22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c41796fbc16e4c77852bd772e275b1bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4676d0e3769f404cb0cbde38a42c37ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c9b78b2748e4aaeb14ff90f37c03038":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d16094dc3f81455bb8cf2fc8e6730ca0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd9fb35cf2d2476c89defd096273a5f1","IPY_MODEL_177b85f83eec47beb41e72683e887366","IPY_MODEL_8555042c75a047efa47a9ff6a634a6f3"],"layout":"IPY_MODEL_f8d22dc858494872b01c34bb49563ec2"}},"dd9fb35cf2d2476c89defd096273a5f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f5850588abf498bb45c64c39c75f932","placeholder":"â€‹","style":"IPY_MODEL_15a6cb3a0d534efe973c5e98b6afd3e1","value":"tokenizer_config.json:â€‡100%"}},"177b85f83eec47beb41e72683e887366":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc1c489409eb493d8c5b89068d7ba9ed","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4e4cc5e14304c0a9e656a1ef69410bb","value":26}},"8555042c75a047efa47a9ff6a634a6f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37afa932f1884e77b1ed6e9fbc4a025c","placeholder":"â€‹","style":"IPY_MODEL_47d59a08e75f45c780c241eab5f77417","value":"â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡1.38kB/s]"}},"f8d22dc858494872b01c34bb49563ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f5850588abf498bb45c64c39c75f932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15a6cb3a0d534efe973c5e98b6afd3e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc1c489409eb493d8c5b89068d7ba9ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4e4cc5e14304c0a9e656a1ef69410bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37afa932f1884e77b1ed6e9fbc4a025c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47d59a08e75f45c780c241eab5f77417":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5eb7172adae9467f85a9faf4cc414247":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38bdd48028a14a3192b0e2d2be54642f","IPY_MODEL_eafceacb104e4622b54faaa5a3f00f1f","IPY_MODEL_d9e3fce8db43428097b6592621f02d5f"],"layout":"IPY_MODEL_b699a4911ba649c2a8015a63fe342c2a"}},"38bdd48028a14a3192b0e2d2be54642f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_289408ddb467436f808ec2d62160f843","placeholder":"â€‹","style":"IPY_MODEL_16ed514587a84338a6eb39b96179c57d","value":"vocab.json:â€‡100%"}},"eafceacb104e4622b54faaa5a3f00f1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_605dfc90d21f470484634e125d40de6f","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3eaa26d43e9e431b9f1481fac2b71b86","value":1042301}},"d9e3fce8db43428097b6592621f02d5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fdfc46b60f94d578afdc8408b5b1f38","placeholder":"â€‹","style":"IPY_MODEL_7b82c4f0073b43b7a20a811e390cc6b5","value":"â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡10.1MB/s]"}},"b699a4911ba649c2a8015a63fe342c2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"289408ddb467436f808ec2d62160f843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16ed514587a84338a6eb39b96179c57d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"605dfc90d21f470484634e125d40de6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eaa26d43e9e431b9f1481fac2b71b86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fdfc46b60f94d578afdc8408b5b1f38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b82c4f0073b43b7a20a811e390cc6b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b822ce0dc4942a5b10a38729fc9d940":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_376bccb84a654dd0b63d6f7539763ee1","IPY_MODEL_1156178e280248fd9e33abead2a23e9e","IPY_MODEL_572ba88a54bd452c9e19d06f523e592e"],"layout":"IPY_MODEL_9c21507260914e98b308eee228c82b5c"}},"376bccb84a654dd0b63d6f7539763ee1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9ca2cdc28d1470498186ee6e0ced4f3","placeholder":"â€‹","style":"IPY_MODEL_debb00b747c94b9f91471ab97bbb7420","value":"merges.txt:â€‡100%"}},"1156178e280248fd9e33abead2a23e9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa2d7f795c542d083eb4ef83cc898ac","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0d4403d5bec491aafa25bd51a22daac","value":456318}},"572ba88a54bd452c9e19d06f523e592e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cb597f252a34c83afdde505e9ffdbf9","placeholder":"â€‹","style":"IPY_MODEL_93d89ce3fc8143a680f632ebb4adf540","value":"â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡24.0MB/s]"}},"9c21507260914e98b308eee228c82b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9ca2cdc28d1470498186ee6e0ced4f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"debb00b747c94b9f91471ab97bbb7420":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aa2d7f795c542d083eb4ef83cc898ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0d4403d5bec491aafa25bd51a22daac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2cb597f252a34c83afdde505e9ffdbf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93d89ce3fc8143a680f632ebb4adf540":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb8280f9ce7428b88fd77b49ff948fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e945787c68d4d49948695f490220248","IPY_MODEL_8ef7b9d616c343b3b7dcf7883ff945e2","IPY_MODEL_65917152dc604aeda0edc1c47c367484"],"layout":"IPY_MODEL_f16b291a5d2f4bd4b9635b5aa99b3145"}},"7e945787c68d4d49948695f490220248":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97a267e4f5cf4238bfcdff19b785987e","placeholder":"â€‹","style":"IPY_MODEL_5ae0273b0a834c1c979c9d1b594efd31","value":"tokenizer.json:â€‡100%"}},"8ef7b9d616c343b3b7dcf7883ff945e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_befc06fe73644b4c85635f04ff3ab2d9","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2d9f492d8ad48ee8f6abc4b7b0ee977","value":1355256}},"65917152dc604aeda0edc1c47c367484":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f40ae75ce1f4a309e37cb8e61f6a7e8","placeholder":"â€‹","style":"IPY_MODEL_70929129f1f94438a7ba340a6d403d15","value":"â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡35.5MB/s]"}},"f16b291a5d2f4bd4b9635b5aa99b3145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97a267e4f5cf4238bfcdff19b785987e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ae0273b0a834c1c979c9d1b594efd31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"befc06fe73644b4c85635f04ff3ab2d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2d9f492d8ad48ee8f6abc4b7b0ee977":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f40ae75ce1f4a309e37cb8e61f6a7e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70929129f1f94438a7ba340a6d403d15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91ea0a96d7be4e6882a47bf65e451a56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eed2aa114b494969abbac1cde7fb47fb","IPY_MODEL_5c03fe142ff842979513e5d4918793fb","IPY_MODEL_863264cfb9704716b0650feb18925d7a"],"layout":"IPY_MODEL_0db011e15d94455b92c21c7762fda4c4"}},"eed2aa114b494969abbac1cde7fb47fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26e96f4d96834a44856c9c1bc4c31898","placeholder":"â€‹","style":"IPY_MODEL_f433cad65814441881566a9c18bbae59","value":"modules.json:â€‡100%"}},"5c03fe142ff842979513e5d4918793fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3277da32e874d779948d2aa27c87e56","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3905c9747d84172967ea1a0d94c7406","value":349}},"863264cfb9704716b0650feb18925d7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_866795b0cc554da8acaa63d9ebbd214f","placeholder":"â€‹","style":"IPY_MODEL_fcc7d69a1f35451c8967f3e0a71da2ed","value":"â€‡349/349â€‡[00:00&lt;00:00,â€‡25.5kB/s]"}},"0db011e15d94455b92c21c7762fda4c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26e96f4d96834a44856c9c1bc4c31898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f433cad65814441881566a9c18bbae59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3277da32e874d779948d2aa27c87e56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3905c9747d84172967ea1a0d94c7406":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"866795b0cc554da8acaa63d9ebbd214f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcc7d69a1f35451c8967f3e0a71da2ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcb9e204ae644a6f80fe924e16cdb0fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b00b87e8db4459eb0758d0419fe07ee","IPY_MODEL_84cfed1b59ed4d918ff594947be27adb","IPY_MODEL_b31acc9e55ba41929c7dab203fb79978"],"layout":"IPY_MODEL_939b5ada21bb4b858128a1d4caa9117f"}},"6b00b87e8db4459eb0758d0419fe07ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31f4ebde0fe049c68adc14e8a5b5b83d","placeholder":"â€‹","style":"IPY_MODEL_2859ae351c884351aecac5bfea7a6268","value":"config_sentence_transformers.json:â€‡100%"}},"84cfed1b59ed4d918ff594947be27adb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8788398ad42648eebc21afab6eb43494","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_158bb8aebead4eacbbdcc7d854450ec3","value":116}},"b31acc9e55ba41929c7dab203fb79978":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53613814bcc840629b85df1b81433a49","placeholder":"â€‹","style":"IPY_MODEL_94cf679831484e61a61548e878920c64","value":"â€‡116/116â€‡[00:00&lt;00:00,â€‡8.60kB/s]"}},"939b5ada21bb4b858128a1d4caa9117f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31f4ebde0fe049c68adc14e8a5b5b83d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2859ae351c884351aecac5bfea7a6268":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8788398ad42648eebc21afab6eb43494":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"158bb8aebead4eacbbdcc7d854450ec3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53613814bcc840629b85df1b81433a49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94cf679831484e61a61548e878920c64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0bf3aa31dfe4e84bb8fe6f778e04ebd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0d53a637764468abcd42a4b7436a2eb","IPY_MODEL_69711a6bed4243dcaef1172005affa93","IPY_MODEL_94d40cb5e4ee46719f47453a8a49435a"],"layout":"IPY_MODEL_d720daf786e84ef780f9c54346af1be2"}},"f0d53a637764468abcd42a4b7436a2eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4bc59acfefe4d5587f65a161445ae45","placeholder":"â€‹","style":"IPY_MODEL_96d1b98bf3f346c3bd401f39d4944bd4","value":"README.md:â€‡100%"}},"69711a6bed4243dcaef1172005affa93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18cae444d1e14a34ae33174d301f1b91","max":10659,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f829babaa56e4b6bb670b2fb394be5a6","value":10659}},"94d40cb5e4ee46719f47453a8a49435a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf0f4c95fc974cef9093c2de6c807dfc","placeholder":"â€‹","style":"IPY_MODEL_8973dc3d59504d5fa1f1967ce575bc7c","value":"â€‡10.7k/10.7kâ€‡[00:00&lt;00:00,â€‡643kB/s]"}},"d720daf786e84ef780f9c54346af1be2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4bc59acfefe4d5587f65a161445ae45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d1b98bf3f346c3bd401f39d4944bd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18cae444d1e14a34ae33174d301f1b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f829babaa56e4b6bb670b2fb394be5a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf0f4c95fc974cef9093c2de6c807dfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8973dc3d59504d5fa1f1967ce575bc7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"437af67932df433589d66affbc3da5fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67df030304d94110a92a9036ad9c3ae7","IPY_MODEL_ef3322b1830f4ec8bc06cde267434a7f","IPY_MODEL_84a5197dd9ec4e5c8936551eb21a17c2"],"layout":"IPY_MODEL_f5183736ca124e3ea327c4e1dc8c1e81"}},"67df030304d94110a92a9036ad9c3ae7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3d438d7703b4e1fb11100534b478b85","placeholder":"â€‹","style":"IPY_MODEL_ce1e4e7661144057b56e3e871d9ef6b4","value":"sentence_bert_config.json:â€‡100%"}},"ef3322b1830f4ec8bc06cde267434a7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8944addec5294f62abad29ed983f9d2e","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58d30bff243544caa8d37b39e086e8d9","value":53}},"84a5197dd9ec4e5c8936551eb21a17c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6edefa1eec1411abcf84f2a00b56328","placeholder":"â€‹","style":"IPY_MODEL_f4fb331d752d4add96ba184f9eb1f148","value":"â€‡53.0/53.0â€‡[00:00&lt;00:00,â€‡3.90kB/s]"}},"f5183736ca124e3ea327c4e1dc8c1e81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3d438d7703b4e1fb11100534b478b85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce1e4e7661144057b56e3e871d9ef6b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8944addec5294f62abad29ed983f9d2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d30bff243544caa8d37b39e086e8d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6edefa1eec1411abcf84f2a00b56328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4fb331d752d4add96ba184f9eb1f148":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a983e6264b2c47e5961d6026e03454f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43d96cf8e7c0441dbff06c89f1fab67a","IPY_MODEL_dbee6b6638fc4108b68476e1ab928f40","IPY_MODEL_3782966617394ae2a8c1a2d326e8e023"],"layout":"IPY_MODEL_d542f761d50a48408031f0b3196586fb"}},"43d96cf8e7c0441dbff06c89f1fab67a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84394c3dee9545d783e3f25cc1cfe658","placeholder":"â€‹","style":"IPY_MODEL_6fbcd51dbffb40d1a6bc6b7fc7321b54","value":"config.json:â€‡100%"}},"dbee6b6638fc4108b68476e1ab928f40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a12ce4c1a46b4c90aee55957aa9379b2","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55d206ad7de340059ce19e973cb64647","value":612}},"3782966617394ae2a8c1a2d326e8e023":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc9cec09589240c1a7cca71d22e1dc1c","placeholder":"â€‹","style":"IPY_MODEL_75499456c89d4ef6ac2358d280b519b4","value":"â€‡612/612â€‡[00:00&lt;00:00,â€‡40.0kB/s]"}},"d542f761d50a48408031f0b3196586fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84394c3dee9545d783e3f25cc1cfe658":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fbcd51dbffb40d1a6bc6b7fc7321b54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a12ce4c1a46b4c90aee55957aa9379b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d206ad7de340059ce19e973cb64647":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc9cec09589240c1a7cca71d22e1dc1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75499456c89d4ef6ac2358d280b519b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68e35762c9254b93b5af79b87a1b915d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d542a0a6324f4f2fbd1fa3a4329dc09c","IPY_MODEL_e8ed5fbe7b4248e99924eca3aa782cd6","IPY_MODEL_e35d12fc7b9a4e4689a1ad4091450b5f"],"layout":"IPY_MODEL_a589061c45844ba1b25fd697cfa4df04"}},"d542a0a6324f4f2fbd1fa3a4329dc09c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e5c130e104a4719b8a03779d79d8471","placeholder":"â€‹","style":"IPY_MODEL_63a129ea4f474caeadfd9c613a22158e","value":"model.safetensors:â€‡100%"}},"e8ed5fbe7b4248e99924eca3aa782cd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2eae8b240934a5d82d9a0224427b25d","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50ff39c332b74150ae0f94089d7a2ef3","value":90868368}},"e35d12fc7b9a4e4689a1ad4091450b5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_834cf3587ed442b08003c2d4fda0d89f","placeholder":"â€‹","style":"IPY_MODEL_77d96a7599d34559840ae84f7c541b75","value":"â€‡90.9M/90.9Mâ€‡[00:01&lt;00:00,â€‡115MB/s]"}},"a589061c45844ba1b25fd697cfa4df04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e5c130e104a4719b8a03779d79d8471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63a129ea4f474caeadfd9c613a22158e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2eae8b240934a5d82d9a0224427b25d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50ff39c332b74150ae0f94089d7a2ef3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"834cf3587ed442b08003c2d4fda0d89f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77d96a7599d34559840ae84f7c541b75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23356d2e2a514506a56f12c6c3f75a98":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7047118b19b4276869d3fec71ab4822","IPY_MODEL_35bf59643b70494a82c7abe20b7872ad","IPY_MODEL_27a3eee23cb349c083c90227b333acd2"],"layout":"IPY_MODEL_e8982b572c75466e8e78a366a2ebe474"}},"a7047118b19b4276869d3fec71ab4822":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64752a50060e4768928ae1b553a77d4d","placeholder":"â€‹","style":"IPY_MODEL_f8d9c508a5444eb984372f2dd0f596ba","value":"tokenizer_config.json:â€‡100%"}},"35bf59643b70494a82c7abe20b7872ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92964bfb29d24e15a054b724df7ffbf9","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_712f227f1028439893886da36d2fb6f2","value":350}},"27a3eee23cb349c083c90227b333acd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f758b677ce644579e0d04434ea01ad2","placeholder":"â€‹","style":"IPY_MODEL_e0c07743b6134cc8adafa2287339e4ee","value":"â€‡350/350â€‡[00:00&lt;00:00,â€‡18.2kB/s]"}},"e8982b572c75466e8e78a366a2ebe474":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64752a50060e4768928ae1b553a77d4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8d9c508a5444eb984372f2dd0f596ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92964bfb29d24e15a054b724df7ffbf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"712f227f1028439893886da36d2fb6f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f758b677ce644579e0d04434ea01ad2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0c07743b6134cc8adafa2287339e4ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6698b2f0a0748c593f8266a03e8e3a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a28bc8b706d544f581d4793fe1f44297","IPY_MODEL_6dbbea6f0c0348c88cbd7739774cc324","IPY_MODEL_6c2f09e456ef4b2b8d2e17012e5093b2"],"layout":"IPY_MODEL_95ee80498f87425aa3e4c7b5e9bf36de"}},"a28bc8b706d544f581d4793fe1f44297":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8564cf1b429e49b99c8f52dba6a7f038","placeholder":"â€‹","style":"IPY_MODEL_2f50793d2b264caf9e8b8478f9123d3f","value":"vocab.txt:â€‡100%"}},"6dbbea6f0c0348c88cbd7739774cc324":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b37c73ac2d34886b126481a4b2bb553","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_952bac09ae824f02b127d04bcba8510d","value":231508}},"6c2f09e456ef4b2b8d2e17012e5093b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a99e3fd505014877948e52c120b973cc","placeholder":"â€‹","style":"IPY_MODEL_863e14ba8d2c4f0f9b2eefa009fa76f1","value":"â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡12.8MB/s]"}},"95ee80498f87425aa3e4c7b5e9bf36de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8564cf1b429e49b99c8f52dba6a7f038":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f50793d2b264caf9e8b8478f9123d3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b37c73ac2d34886b126481a4b2bb553":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952bac09ae824f02b127d04bcba8510d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a99e3fd505014877948e52c120b973cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"863e14ba8d2c4f0f9b2eefa009fa76f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f1c42eff3724a0aa7e2c8d9cca3d8f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b86acb21bb84f5d9baef7f96f9fc706","IPY_MODEL_f72de091cb58404995d81cbfeb7561db","IPY_MODEL_b2c94b607c4643778f2f4cb3b4383ebe"],"layout":"IPY_MODEL_5bfec39d57614082bdedb25650d903ca"}},"4b86acb21bb84f5d9baef7f96f9fc706":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80cf5fa1a7b3451785d401e10ff0d77c","placeholder":"â€‹","style":"IPY_MODEL_c2fc3cf71cea4279ab40b555bfbab1f8","value":"tokenizer.json:â€‡100%"}},"f72de091cb58404995d81cbfeb7561db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b283a280e644b0185894d9c83e62fba","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4d7ac82f62147ff9be029a3f7b31f71","value":466247}},"b2c94b607c4643778f2f4cb3b4383ebe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd58f23b33ab48b5bc9691706850ecfc","placeholder":"â€‹","style":"IPY_MODEL_ec1c80734f444e8fba351c0ef5c996d7","value":"â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡31.0MB/s]"}},"5bfec39d57614082bdedb25650d903ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80cf5fa1a7b3451785d401e10ff0d77c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2fc3cf71cea4279ab40b555bfbab1f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b283a280e644b0185894d9c83e62fba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4d7ac82f62147ff9be029a3f7b31f71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd58f23b33ab48b5bc9691706850ecfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1c80734f444e8fba351c0ef5c996d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c760e27bfa44c34a6b58470413ea430":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c45defc9b220461f968e8ff084c39ad0","IPY_MODEL_b9f9509d2a8141099d6e5e1d48385f23","IPY_MODEL_2595f6c665a14f1e81faafab3ab71e94"],"layout":"IPY_MODEL_313b03bd2238456794502432c280265c"}},"c45defc9b220461f968e8ff084c39ad0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4db00b6bbe6044e09b6f6d6517180bf0","placeholder":"â€‹","style":"IPY_MODEL_f00fd8b4d5644ba3a69a662e0da9cb32","value":"special_tokens_map.json:â€‡100%"}},"b9f9509d2a8141099d6e5e1d48385f23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebf5942b5dcf467faa172b1ddd315bf1","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71a84d3ecb504943846915b33fa4fcdb","value":112}},"2595f6c665a14f1e81faafab3ab71e94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4cd4a5c08ae402691a85ae10da59816","placeholder":"â€‹","style":"IPY_MODEL_fcc2e03cf6bf4e56b87354936ff19f1a","value":"â€‡112/112â€‡[00:00&lt;00:00,â€‡4.69kB/s]"}},"313b03bd2238456794502432c280265c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4db00b6bbe6044e09b6f6d6517180bf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f00fd8b4d5644ba3a69a662e0da9cb32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebf5942b5dcf467faa172b1ddd315bf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71a84d3ecb504943846915b33fa4fcdb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4cd4a5c08ae402691a85ae10da59816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcc2e03cf6bf4e56b87354936ff19f1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"300a8e3915344a14a5ee4cc4e9f9c8c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36d2b63258d141919cfecfc38b2587db","IPY_MODEL_6a28307dc08d4ab092661ab023f5beb6","IPY_MODEL_42bb7fab57864aa9809fe9cfd928e708"],"layout":"IPY_MODEL_83830143d44c48fba63c1d5301d71de9"}},"36d2b63258d141919cfecfc38b2587db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1098e11bc01d481f836d6f681980f030","placeholder":"â€‹","style":"IPY_MODEL_bddd129db7584bc584211544a9dd78db","value":"1_Pooling/config.json:â€‡100%"}},"6a28307dc08d4ab092661ab023f5beb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d7a8de016f149ecafc025222f75d467","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c7a5fe6812e4e78814416e26d8b3321","value":190}},"42bb7fab57864aa9809fe9cfd928e708":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ab59cd9b4f445618a0de8f32b8baf48","placeholder":"â€‹","style":"IPY_MODEL_6ef524bde1f546b2824e400244e0016c","value":"â€‡190/190â€‡[00:00&lt;00:00,â€‡7.51kB/s]"}},"83830143d44c48fba63c1d5301d71de9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1098e11bc01d481f836d6f681980f030":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bddd129db7584bc584211544a9dd78db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d7a8de016f149ecafc025222f75d467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c7a5fe6812e4e78814416e26d8b3321":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ab59cd9b4f445618a0de8f32b8baf48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ef524bde1f546b2824e400244e0016c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}