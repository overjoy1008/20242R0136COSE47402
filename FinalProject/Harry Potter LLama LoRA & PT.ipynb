{"cells":[{"cell_type":"markdown","source":["# 1. Downloading Llama & Preparing LoRA"],"metadata":{"id":"fROHRlcGdfNs"}},{"cell_type":"markdown","source":["First we check the GPU version available in the environment and install specific dependencies that are compatible with the detected GPU to prevent version conflicts."],"metadata":{"id":"IqM-T1RTzY6C"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1733829066447,"user_tz":-540,"elapsed":26813,"user":{"displayName":"박경빈","userId":"04876725348542542168"}}},"outputs":[],"source":["%%capture\n","import torch\n","major_version, minor_version = torch.cuda.get_device_capability()\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","if major_version >= 8:\n","    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n","else:\n","    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n","pass"]},{"cell_type":"markdown","source":["Next we need to prepare to load a range of quantized language models, including a new 15 trillion token LLama-3 model, optimized for memory efficiency with 4-bit quantization.\n"],"metadata":{"id":"r2v_X2fA0Df5"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CEiokeMJ0c74","executionInfo":{"status":"ok","timestamp":1733829068305,"user_tz":-540,"elapsed":1859,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"bc0d7c73-4542-49db-a175-24b5ca8838a4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmUBVEnvCDJv","executionInfo":{"status":"ok","timestamp":1733829131132,"user_tz":-540,"elapsed":62829,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"fead8a9a-7740-4f12-b22f-b27a827197c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! Llama 3 is up to 8k\n","dtype = None\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","fourbit_models = [\n","    \"unsloth/mistral-7b-bnb-4bit\",\n","    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","    \"unsloth/llama-2-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-bnb-4bit\",\n","    \"unsloth/gemma-7b-it-bnb-4bit\",\n","    \"unsloth/gemma-2b-bnb-4bit\",\n","    \"unsloth/gemma-2b-it-bnb-4bit\",\n","    \"unsloth/llama-3-8b-bnb-4bit\",\n","]\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\", # Llama-3 70b also works (just change the model name)\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6bZsfBuZDeCL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733829138419,"user_tz":-540,"elapsed":7290,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"33bef39f-a00f-46f1-9d5a-52ed5afcda38"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.12.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0,\n","    bias = \"none\",\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 3407,\n","    use_rslora = False,\n","    loftq_config = None,\n",")"]},{"cell_type":"markdown","source":["### Understanding Model"],"metadata":{"id":"ScpDNEtyGl0K"}},{"cell_type":"code","source":["# def print_model_structure(model, indent=0):\n","#     \"\"\"\n","#     모델의 내부 구조를 계층적으로 출력하는 함수\n","\n","#     Args:\n","#         model: PyTorch 모델\n","#         indent: 들여쓰기 레벨\n","#     \"\"\"\n","#     tab = '  ' * indent\n","\n","#     for name, module in model.named_children():\n","#         print(f\"{tab}{name}: ({module.__class__.__name__})\")\n","\n","#         if \"Attention\" in module.__class__.__name__:\n","#             print(f\"{tab}  → Attention Layer Found!\")\n","#             if hasattr(module, 'num_heads'):\n","#                 print(f\"{tab}    - Number of heads: {module.num_heads}\")\n","#             if hasattr(module, 'head_dim'):\n","#                 print(f\"{tab}    - Head dimension: {module.head_dim}\")\n","\n","#         elif \"Transformer\" in module.__class__.__name__:\n","#             print(f\"{tab}  → Transformer Block Found!\")\n","\n","#         if len(list(module.children())) > 0:\n","#             print_model_structure(module, indent + 1)\n","\n","# def analyze_lora_layers(model):\n","#     \"\"\"\n","#     LoRA 레이어의 상세 정보를 분석하는 함수\n","#     \"\"\"\n","#     print(\"\\n=== LoRA Layer Analysis ===\")\n","#     for name, module in model.named_modules():\n","#         if hasattr(module, 'lora_A'):\n","#             print(f\"\\nLayer: {name}\")\n","\n","#             # LoRA A 행렬 정보\n","#             if isinstance(module.lora_A, dict):\n","#                 for adapter_name, lora_A in module.lora_A.items():\n","#                     print(f\"Adapter: {adapter_name}\")\n","#                     if hasattr(lora_A, 'weight'):\n","#                         shape = lora_A.weight.shape\n","#                         print(f\"  Shape (A): {shape}\")\n","#             else:\n","#                 if hasattr(module.lora_A, 'weight'):\n","#                     shape = module.lora_A.weight.shape\n","#                     print(f\"  Shape (A): {shape}\")\n","\n","#             # 기본 레이어 정보\n","#             if hasattr(module, 'in_features'):\n","#                 print(f\"  Input features: {module.in_features}\")\n","#             if hasattr(module, 'out_features'):\n","#                 print(f\"  Output features: {module.out_features}\")\n","\n","# # 기본 모델 정보 출력\n","# print(\"=== Model Information ===\")\n","# print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n","# print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n","\n","# # 모델 구조 출력\n","# print(\"\\n=== Model Structure ===\")\n","# print_model_structure(model)\n","\n","# # LoRA 레이어 분석\n","# analyze_lora_layers(model)"],"metadata":{"id":"yM2A5uovEjOu","executionInfo":{"status":"ok","timestamp":1733829138419,"user_tz":-540,"elapsed":2,"user":{"displayName":"박경빈","userId":"04876725348542542168"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Adding Attention Layer"],"metadata":{"id":"EVIfLoMMGi5h"}},{"cell_type":"code","source":["# import torch\n","# from torch import nn\n","# import math\n","\n","# class CustomAttention(nn.Module):\n","#     def __init__(self, config):\n","#         super().__init__()\n","#         self.hidden_size = config.hidden_size\n","#         self.num_heads = config.num_attention_heads\n","#         self.head_dim = config.hidden_size // config.num_attention_heads\n","#         self.scaling = self.head_dim ** -0.5\n","\n","#         # 주요 프로젝션 레이어들\n","#         self.q_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","#         self.k_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","#         self.v_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","#         self.o_proj = nn.Linear(config.hidden_size, config.hidden_size)\n","\n","#         self.rotary_emb = model.base_model.model.model.layers[0].self_attn.rotary_emb\n","\n","#     def forward(self, hidden_states, attention_mask=None, position_ids=None):\n","#         batch_size, seq_length, _ = hidden_states.shape\n","\n","#         # 프로젝션 수행\n","#         query_states = self.q_proj(hidden_states)\n","#         key_states = self.k_proj(hidden_states)\n","#         value_states = self.v_proj(hidden_states)\n","\n","#         # 헤드 차원으로 재구성\n","#         query_states = query_states.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n","#         key_states = key_states.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n","#         value_states = value_states.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n","\n","#         # RoPE (Rotary Position Embedding) 적용\n","#         query_states, key_states = self.rotary_emb(query_states, key_states, position_ids)\n","\n","#         # Attention 계산\n","#         attention_scores = torch.matmul(query_states, key_states.transpose(2, 3)) * self.scaling\n","\n","#         if attention_mask is not None:\n","#             attention_scores = attention_scores + attention_mask\n","\n","#         attention_probs = torch.softmax(attention_scores, dim=-1)\n","\n","#         # Value와 결합하여 최종 출력 계산\n","#         hidden_states = torch.matmul(attention_probs, value_states)\n","#         hidden_states = hidden_states.transpose(1, 2).contiguous()\n","#         hidden_states = hidden_states.view(batch_size, seq_length, self.hidden_size)\n","\n","#         # 최종 프로젝션\n","#         hidden_states = self.o_proj(hidden_states)\n","\n","#         return hidden_states\n","\n","# def add_attention_layer(model):\n","#     \"\"\"\n","#     모델의 앞부분에 새로운 attention layer를 추가합니다.\n","#     \"\"\"\n","#     config = model.base_model.model.model.config\n","#     new_attention = CustomAttention(config)\n","\n","#     # 모델의 기존 레이어들을 임시 저장\n","#     original_layers = model.base_model.model.model.layers\n","\n","#     # 새로운 ModuleList 생성\n","#     new_layers = nn.ModuleList([new_attention])\n","#     new_layers.extend(original_layers)\n","\n","#     # 모델의 layers를 새로운 ModuleList로 교체\n","#     model.base_model.model.model.layers = new_layers\n","\n","#     return model\n","\n","# # 사용 예시:\n","# # model = add_attention_layer(model)"],"metadata":{"id":"6LrH1q3sGh_9","executionInfo":{"status":"ok","timestamp":1733829138420,"user_tz":-540,"elapsed":3,"user":{"displayName":"박경빈","userId":"04876725348542542168"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# 2. Dataset Preprocessing"],"metadata":{"id":"ujY0eRdvE_RA"}},{"cell_type":"code","source":["# Google Drive 마운트\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wWFxD1X865v","executionInfo":{"status":"ok","timestamp":1733753314764,"user_tz":-540,"elapsed":30812,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"176e7cff-e87a-4c3e-f96e-889bd330b04f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import random\n","import nltk\n","from datasets import Dataset, DatasetDict\n","from nltk.corpus import wordnet\n","\n","EOS_TOKEN = tokenizer.eos_token # do not forget this part!\n","\n","# Download required NLTK data\n","nltk.download('wordnet')\n","\n","def clean_text(text):\n","    \"\"\"Clean vertically split text if present\"\"\"\n","    if isinstance(text, list):\n","        text = '\\n'.join(text)\n","    if '\\n' in text and all(len(line.strip()) == 1 for line in text.split('\\n') if line.strip()):\n","        return ''.join(c for c in text if not c.isspace())\n","    return text\n","\n","def get_synonyms(word):\n","    \"\"\"Get list of synonyms for a word using WordNet\"\"\"\n","    synonyms = []\n","    for syn in wordnet.synsets(word):\n","        for lemma in syn.lemmas():\n","            if lemma.name() != word:\n","                synonyms.append(lemma.name())\n","    return list(set(synonyms))\n","\n","def augment_scene(scene):\n","    \"\"\"Augment scene text by replacing words with synonyms\"\"\"\n","    words = scene.split()\n","    augmented = []\n","    for word in words:\n","        if random.random() < 0.1:  # 10% probability of synonym replacement\n","            synonyms = get_synonyms(word)\n","            if synonyms:\n","                augmented.append(random.choice(synonyms))\n","            else:\n","                augmented.append(word)\n","        else:\n","            augmented.append(word)\n","    return \" \".join(augmented)\n","\n","def create_context(session_data, p_scene=0.8, p_attr=0.7, p_relations=0.6):\n","    \"\"\"Create context with probabilistic inclusion of different components\"\"\"\n","    context = \"\"\n","\n","    if random.random() < p_scene:\n","        context += f\"Scene:\\n{clean_text(session_data['scene'])}\\n\\n\"\n","\n","    if random.random() < p_attr:\n","        context += \"Character Information:\\n\"\n","        for speaker in session_data[\"speakers\"]:\n","            if speaker in session_data[\"attributes\"]:\n","                attrs = session_data[\"attributes\"][speaker]\n","                selected_attrs = random.sample(list(attrs.items()),\n","                                            k=random.randint(2, len(attrs)))\n","                context += f\"{speaker}:\\n\"\n","                for key, value in selected_attrs:\n","                    if value and value != \"None\":\n","                        context += f\"- {key}: {value}\\n\"\n","\n","    if random.random() < p_relations:\n","        relations = session_data.get(\"relations with Harry\", {})\n","        if relations:\n","            context += \"\\nRelations:\\n\"\n","            for person, rel in relations.items():\n","                selected_rels = random.sample(list(rel.items()),\n","                                           k=random.randint(1, len(rel)))\n","                for key, value in selected_rels:\n","                    if isinstance(value, (int, float)) and value != 0:\n","                        context += f\"{person} - {key}: {value}\\n\"\n","\n","    return context\n","\n","def create_dialogue_variations(dialogues, max_history=3):\n","    \"\"\"Create variations of dialogue history\"\"\"\n","    examples = []\n","    for i in range(len(dialogues) - 1):\n","        history_length = random.randint(1, min(i+1, max_history))\n","        selected_history = dialogues[max(0, i-history_length+1):i+1]\n","\n","        example = {\n","            \"previous_dialogue\": \"\\n\".join(selected_history),\n","            \"next_dialogue\": dialogues[i + 1]\n","        }\n","        examples.append(example)\n","    return examples\n","\n","def create_augmented_examples(session_data):\n","    \"\"\"Create augmented examples from session data\"\"\"\n","    examples = []\n","    base_dialogues = session_data[\"dialogue\"]\n","\n","    for _ in range(3):  # Create 3 variations per session\n","        context = create_context(session_data)\n","        augmented_scene = augment_scene(clean_text(session_data[\"scene\"]))\n","        dialogue_variations = create_dialogue_variations(base_dialogues)\n","\n","        for variation in dialogue_variations:\n","            example = {\n","                \"instruction\": f\"Given the following context and previous dialogue, \"\n","                             f\"generate the next line of dialogue:\",\n","                \"input\": context + \"\\nScene:\\n\" + augmented_scene +\n","                        \"\\n\\nPrevious Dialogue:\\n\" + variation[\"previous_dialogue\"],\n","                \"output\": variation[\"next_dialogue\"]\n","            }\n","            examples.append(example)\n","\n","    return examples\n","\n","def convert_to_alpaca(json_data):\n","    \"\"\"Convert dataset to Alpaca format with augmentation\"\"\"\n","    alpaca_data = []\n","\n","    if isinstance(json_data, dict):\n","        for session_key, session_data in json_data.items():\n","            session_examples = create_augmented_examples(session_data)\n","            alpaca_data.extend(session_examples)\n","    elif isinstance(json_data, list):\n","        for session_data in json_data:\n","            session_examples = create_augmented_examples(session_data)\n","            alpaca_data.extend(session_examples)\n","\n","    return alpaca_data\n","\n","def formatting_prompts_func(examples):\n","    \"\"\"Format examples in Alpaca prompt style\"\"\"\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","    instructions = examples[\"instruction\"]\n","    inputs = examples[\"input\"]\n","    outputs = examples[\"output\"]\n","    texts = []\n","\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","\n","    return {\"text\": texts}\n","\n","# Main execution\n","def process_dataset(train_path, test_path, output_train_path, output_test_path, formatted_dataset_path):\n","    # Process training data\n","    print(f\"Processing training data from: {train_path}\")\n","    with open(train_path, 'r', encoding='utf-8') as f:\n","        train_data = json.load(f)\n","    train_formatted = convert_to_alpaca(train_data)\n","\n","    # Process test data\n","    print(f\"Processing test data from: {test_path}\")\n","    with open(test_path, 'r', encoding='utf-8') as f:\n","        test_data = json.load(f)\n","    test_formatted = convert_to_alpaca(test_data)\n","\n","    # Save intermediate results\n","    print(f\"Saving training data to: {output_train_path}\")\n","    with open(output_train_path, 'w', encoding='utf-8') as f:\n","        json.dump(train_formatted, f, ensure_ascii=False, indent=2)\n","\n","    print(f\"Saving test data to: {output_test_path}\")\n","    with open(output_test_path, 'w', encoding='utf-8') as f:\n","        json.dump(test_formatted, f, ensure_ascii=False, indent=2)\n","\n","    # Create and save formatted dataset\n","    dataset = DatasetDict({\n","        'train': Dataset.from_list(train_formatted),\n","        'test': Dataset.from_list(test_formatted)\n","    })\n","\n","    formatted_dataset = dataset.map(\n","        formatting_prompts_func,\n","        batched=True,\n","        remove_columns=dataset['train'].column_names\n","    )\n","\n","    # Remove existing directory if it exists\n","    if os.path.exists(formatted_dataset_path):\n","        shutil.rmtree(formatted_dataset_path)\n","\n","    # Save formatted dataset\n","    formatted_dataset.save_to_disk(formatted_dataset_path)\n","\n","    print(f\"Augmented dataset conversion complete! Training entries: {len(train_formatted)}, Test entries: {len(test_formatted)}\")\n","\n","    return formatted_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uTJZRBUSyK4T","executionInfo":{"status":"ok","timestamp":1733824438435,"user_tz":-540,"elapsed":1260,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"1aa53ab7-92fc-4d6e-ae08-dd156a0dde58"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["# File paths\n","train_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Dialogue Dataset/en_train_set.json'\n","test_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Dialogue Dataset/en_test_set.json'\n","output_train_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_train_set.json'\n","output_test_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_test_set.json'\n","formatted_dataset_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_formatted_dataset'\n","\n","# Process the dataset\n","formatted_dataset = process_dataset(\n","    train_path,\n","    test_path,\n","    output_train_path,\n","    output_test_path,\n","    formatted_dataset_path\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["52f9b70227734735a77025b1547a4f7f","e18f78b0a6c04c8db654ad8abf40856c","13abce7bc961407b80aef01ca37e0fff","6afd34f975714df989c95557bb172114","ea30410ff5b94e36aa7f1ae04c2041cb","b8e19f6a2b594e67890184c887173466","fd8bbe23de63456086beba03a3eb7015","cba5291efb80400f8528a5a049bb7a31","6ad660d0f04d4c90a435e222d5a93436","4246cf13026447c0b60a5c33dacf1b1a","96d4081338c04ec19db1142e9b8557b1","c420788c75cb4df0b73057c1f99fc2f7","32cce8257910411381ae107f1b272f87","c7f97e1a812c419d814d63ce35342af3","991589b50c8c4cb8b3228397fe25fc42","4f49199d63f7407ca0a9f00fedb6ca69","7c09c77a34ae4daba634d6f0922c42e3","9881d8fac75446fbbadb75103be04060","eb0db9321a3043e98581240e0b446418","643e63457df14b85a3f96185eb68f849","8e5d1fac31c1477cac1c32a694e7efdf","900a48c9a1fc4dcfa5aa980185b6e4d5","a4e87718aa47491eb9f69a420836f207","004f69c8123f445898206cfb4d15ded8","0c9cda1d48dc4561b6671b3408a3c375","4c3c24727a11472582b3119597c24341","926e06cf281e40549fb1db6ab51a80e0","e4f6744cca874f36be142f33c570e79f","87427d5afa494ad58ddb676da98aadd1","9b1d303c7b8e40299675942ca6e8ad6e","b1b441a11f4c43e89a61e4ee94784664","be3ac3e413f441ae8f446eba8b453934","570a8e8476554129bf9f2b4545f4b648","65ed847eec544f8dbb809936aa6cbd69","6f96ff44f96a44bcb75b11cafb9d268d","c27891e91cb949608bd0e1eef0f1efc8","767002e4ac14423a96a07459745f730c","00b36f1496b74c0a8ff0ce1709256745","7f3fd149169248f7a087ec9b18a34ad3","1f5f8eebe3b94eb9aa8f6b9578291686","849df78437854f358bc43511beb4ec89","7d0ff024983d456781895bccb2debbc7","d827420671ac4e14af3fb8d7d106c50b","7627743dd5bb4ecb84856bdb54482592"]},"id":"N4sMYQflyS3I","executionInfo":{"status":"ok","timestamp":1733824500680,"user_tz":-540,"elapsed":58175,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"6ecddaee-e3ff-4180-9f4c-60411b00f5e7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing training data from: /content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Dialogue Dataset/en_train_set.json\n","Processing test data from: /content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Dialogue Dataset/en_test_set.json\n","Saving training data to: /content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_train_set.json\n","Saving test data to: /content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_test_set.json\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/44166 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52f9b70227734735a77025b1547a4f7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2601 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c420788c75cb4df0b73057c1f99fc2f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/2 shards):   0%|          | 0/44166 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e87718aa47491eb9f69a420836f207"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Saving the dataset (0/1 shards):   0%|          | 0/2601 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65ed847eec544f8dbb809936aa6cbd69"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Augmented dataset conversion complete! Training entries: 44166, Test entries: 2601\n"]}]},{"cell_type":"code","source":["print(formatted_dataset[\"train\"][0][\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mD8icmtuzY6s","executionInfo":{"status":"ok","timestamp":1733824505861,"user_tz":-540,"elapsed":297,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"c3668558-bcb6-4378-88ae-7c0ee685c43f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","“Up! Get up! Now!”\n","Harry woke with a start. His aunt rapped on the door again.\n","“Up!” she screeched. Harry heard her walking toward the kitchen and then the sound of the frying pan being put on the stove. He rolled onto his back and tried to remember the dream he had been having. It had been a good one. There had been a flying motorcycle in it. He had a funny feeling he’d had the same dream before.\n","His aunt was back outside the door.\n","“Are you up yet?” she demanded.\n","“Nearly,” said Harry.\n","“Well, get a move on, I want you to look after the bacon. And don’t you dare let it burn, I want everything perfect on Duddy’s birthday.”\n","Harry groaned.\n","“What did you say?” his aunt snapped through the door.\n","“Nothing, nothing . . .”\n","\n","Character Information:\n","Petunia:\n","- character: Message, gossip\n","- looks: Slender, blond hair, long neck\n","- age: Adult\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","- name: Harry\n","- gender: male\n","- age: age 11\n","- title: The boy who lived\n","\n","Relations:\n","Petunia - family: 1.0\n","\n","Scene:\n","“Up! Get up! Now!” Harry woke with a start. His aunt rapped on the threshold again. “Up!” she screeched. Harry heard her walk toward the kitchen and then the phone of the frying pan being put on the stove. He rolled onto his back and tried to remember the dream he had been having. It had been a good one. There had been a flying motorcycle in it. He had a funny feeling he’d had the same dream before. His aunt was back outside the door. “Are you up yet?” she demanded. “Nearly,” said Harry. “Well, get a move on, I want you to look after the bacon. And don’t you dare let it burn, I want everything perfect on Duddy’s birthday.” Harry groaned. “What did you say?” his aunt snapped through the door. “Nothing, nothing . . .”\n","\n","Previous Dialogue:\n","Petunia: Up! Get up! Now! Up! Up! Are you up yet?\n","\n","### Response:\n","Harry: Nearly,<|end_of_text|>\n"]}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"-03B9tJm8RWF"}},{"cell_type":"markdown","source":["# 3. Fine-Tuning the Model"],"metadata":{"id":"EsMAQHLEG99c"}},{"cell_type":"code","source":["import json\n","\n","output_train_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_train_set.json'\n","output_test_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_test_set.json'\n","formatted_dataset_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_formatted_dataset'\n","\n","with open(output_train_path, 'r', encoding='utf-8') as f:\n","    train_data = json.load(f)\n","\n","with open(output_test_path, 'r', encoding='utf-8') as f:\n","    test_data = json.load(f)\n","\n","# 나중에 데이터셋을 다시 로드할 때는 다음과 같이 사용할 수 있습니다:\n","from datasets import load_from_disk\n","formatted_dataset = load_from_disk(formatted_dataset_path)"],"metadata":{"id":"v3wvyYHl610r","executionInfo":{"status":"ok","timestamp":1733829261088,"user_tz":-540,"elapsed":13090,"user":{"displayName":"박경빈","userId":"04876725348542542168"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# from trl import SFTTrainer\n","# from transformers import TrainingArguments\n","# from datasets import Dataset\n","\n","# # Training Arguments 설정\n","# training_args = TrainingArguments(\n","#     per_device_train_batch_size=2,\n","#     per_device_eval_batch_size=2,  # 평가를 위한 batch size 추가\n","#     gradient_accumulation_steps=4,\n","#     warmup_steps=10,\n","#     max_steps=100, # increase this to make the model learn \"better\"\n","#     learning_rate=2e-4,\n","#     fp16=not torch.cuda.is_bf16_supported(),\n","#     bf16=torch.cuda.is_bf16_supported(),\n","#     logging_steps=1,\n","#     optim=\"adamw_8bit\",\n","#     weight_decay=0.01,\n","#     lr_scheduler_type=\"linear\",\n","#     seed=3407,\n","#     output_dir=\"outputs\",\n","#     # 평가 관련 설정 추가\n","#     evaluation_strategy=\"steps\",    # \"steps\" 또는 \"epoch\"\n","#     eval_steps=20,                 # 20 스텝마다 평가\n","#     save_strategy=\"steps\",\n","#     save_steps=20,                 # 20 스텝마다 모델 저장\n","#     save_total_limit=3,           # 최대 3개의 체크포인트만 저장\n","#     load_best_model_at_end=True,  # 학습 완료 후 가장 좋은 모델 로드\n","#     metric_for_best_model=\"eval_loss\",  # 어떤 메트릭으로 best model을 결정할지\n","# )\n","\n","# # train 데이터셋만 가져와서 분할\n","# train_eval_dataset = formatted_dataset['train']\n","\n","# # train_test_split으로 분할 (예: 80% train, 20% evaluation)\n","# split_dataset = train_eval_dataset.train_test_split(\n","#     test_size=0.2,  # 20%를 evaluation set으로 사용\n","#     shuffle=True,   # 데이터 섞기\n","#     seed=3407      # 재현성을 위한 시드 설정\n","# )\n","\n","# # Trainer 설정\n","# trainer = SFTTrainer(\n","#     model=model,\n","#     tokenizer=tokenizer,\n","#     train_dataset=split_dataset['train'],      # 분할된 train set\n","#     eval_dataset=split_dataset['test'],        # 분할된 evaluation set\n","#     dataset_text_field=\"text\",\n","#     max_seq_length=max_seq_length,\n","#     dataset_num_proc=2,\n","#     packing=False,\n","#     args=training_args,\n","# )\n","\n","\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from datasets import Dataset\n","\n","# 전체 데이터셋에서 더 작은 평가 세트를 만듦\n","train_eval_dataset = formatted_dataset['train']\n","split_dataset = train_eval_dataset.train_test_split(\n","    test_size=0.2,\n","    shuffle=True,\n","    seed=3407\n",")\n","\n","# 평가 데이터셋의 크기를 제한\n","max_eval_samples = 500  # 평가에 사용할 최대 샘플 수\n","eval_dataset = split_dataset['test'].select(range(min(len(split_dataset['test']), max_eval_samples)))\n","\n","# Training Arguments 설정\n","training_args = TrainingArguments(\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=4,  # 평가 배치 크기를 더 크게 설정\n","    gradient_accumulation_steps=4,\n","    warmup_steps=10,\n","    max_steps=100,\n","    learning_rate=2e-4,\n","    fp16=not torch.cuda.is_bf16_supported(),\n","    bf16=torch.cuda.is_bf16_supported(),\n","    logging_steps=1,\n","    optim=\"adamw_8bit\",\n","    weight_decay=0.01,\n","    lr_scheduler_type=\"linear\",\n","    seed=3407,\n","    output_dir=\"outputs\",\n","    # 평가 관련 설정 수정\n","    evaluation_strategy=\"steps\",\n","    eval_steps=50,  # 평가 빈도를 줄임 (20 -> 50)\n","    save_strategy=\"steps\",\n","    save_steps=50,  # 저장 빈도도 함께 조정\n","    save_total_limit=3,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n",")\n","\n","# Trainer 설정\n","trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=split_dataset['train'],\n","    eval_dataset=eval_dataset,  # 크기가 제한된 평가 데이터셋 사용\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    dataset_num_proc=2,\n","    packing=False,\n","    args=training_args,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":161,"referenced_widgets":["c6a97c45088c4a058ecf4d3eaf9f09f9","2072faa03a0b4e729f8d7cc1957d0e5b","eed68d78d3eb4c9eb01e0b9d27dd962d","d875c797d8244582bbbc300da7f9de28","0a4addfb1c7a4bc2a11703600d30da49","589182e5255b412f9deb87c7b49c8a8a","57dd050c574a48f09e9dccf912136f9e","cb9af07731e24ea288a365a03f703802","f7ebb0bee0b147b494a29e1acf792845","7d7ee6c126ad4dd5b0a8a814960170e9","670338d4087a44bcbe6430720e070236"]},"id":"vE7hGJT233zo","executionInfo":{"status":"ok","timestamp":1733829268032,"user_tz":-540,"elapsed":6946,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"f023893b-60c5-47fd-8969-ff488cc3661a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6a97c45088c4a058ecf4d3eaf9f09f9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2ejIt2xSNKKp","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1733826447130,"user_tz":-540,"elapsed":303,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"a4cb2260-846a-4be0-c45b-6e1017234ad0"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","5.605 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yqxqAZ7KJ4oL"},"outputs":[],"source":["# # We're now kicking off the actual training of our model, which will spit out some statistics showing us how well it learns\n","# trainer_stats = trainer.train()"]},{"cell_type":"code","source":["# 학습 시작\n","trainer_stats = trainer.train()\n","\n","# 학습 완료 후 평가\n","eval_results = trainer.evaluate()\n","print(f\"Evaluation results: {eval_results}\")\n","\n","# 모델 저장\n","trainer.save_model(\"final_model\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"ggfK-XeYQtlk","outputId":"98dc12a4-79ab-466b-e4d0-31c33dfae304","executionInfo":{"status":"ok","timestamp":1733837457915,"user_tz":-540,"elapsed":8181471,"user":{"displayName":"박경빈","userId":"04876725348542542168"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 35,332 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 100\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moverjoy1008\u001b[0m (\u001b[33moverjoy1008-korea-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.7"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241210_111606-db2muveo</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/overjoy1008-korea-university/huggingface/runs/db2muveo' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/overjoy1008-korea-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/overjoy1008-korea-university/huggingface' target=\"_blank\">https://wandb.ai/overjoy1008-korea-university/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/overjoy1008-korea-university/huggingface/runs/db2muveo' target=\"_blank\">https://wandb.ai/overjoy1008-korea-university/huggingface/runs/db2muveo</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [100/100 1:58:25, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.456200</td>\n","      <td>1.366200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.239500</td>\n","      <td>1.282975</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [125/125 16:45]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation results: {'eval_loss': 1.2829750776290894, 'eval_runtime': 1013.767, 'eval_samples_per_second': 0.493, 'eval_steps_per_second': 0.123, 'epoch': 0.022642363862787274}\n"]}]},{"cell_type":"code","source":["# model.save_pretrained(\"lora_model\") # Local saving\n","model.push_to_hub(\"Overjoy1008/harry_potter_llama3_lora_100\", token = \"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\") # Online saving"],"metadata":{"id":"tYeObsv4O9IF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#4. Prompt Tuning"],"metadata":{"id":"19q-EXk6FCbA"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, PreTrainedModel, TrainingArguments\n","from trl import SFTTrainer\n","import torch\n","import torch.nn as nn\n","from dataclasses import dataclass\n","from typing import Optional, Tuple\n","from transformers.trainer_utils import get_last_checkpoint\n","import os\n","\n","# train 데이터셋만 가져와서 분할\n","train_eval_dataset = formatted_dataset['train']\n","\n","# train_test_split으로 분할 (예: 80% train, 20% evaluation)\n","split_dataset = train_eval_dataset.train_test_split(\n","    test_size=0.2,  # 20%를 evaluation set으로 사용\n","    shuffle=True,   # 데이터 섞기\n","    seed=3407      # 재현성을 위한 시드 설정\n",")\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","@dataclass\n","class PromptTuningConfig:\n","    num_virtual_tokens: int = 20\n","    initialization_method: str = \"random\"\n","    prompt_tuning_init_text: Optional[str] = None\n","\n","class PromptEmbedding(nn.Module):\n","    def __init__(self, config: PromptTuningConfig, model: PreTrainedModel, tokenizer: AutoTokenizer):\n","        super().__init__()\n","        self.config = config\n","        self.embedding_dim = model.config.hidden_size\n","        self.device = next(model.parameters()).device\n","\n","        # Get the base LlamaModel\n","        llama_model = model\n","        while not hasattr(llama_model, 'embed_tokens'):\n","            if hasattr(llama_model, 'base_model'):\n","                llama_model = llama_model.base_model\n","            else:\n","                raise AttributeError(\"Could not find embed_tokens in model\")\n","\n","        self.llama_model = llama_model\n","\n","        if config.initialization_method == \"random\":\n","            self.prompt_embeddings = nn.Parameter(\n","                torch.randn(config.num_virtual_tokens, self.embedding_dim).to(self.device)\n","            )\n","        elif config.initialization_method == \"vocabulary\":\n","            init_text = config.prompt_tuning_init_text\n","            if init_text is None:\n","                init_text = \"This is a story about Harry Potter:\"\n","\n","            tokens = tokenizer(init_text, return_tensors=\"pt\").input_ids.to(self.device)\n","            token_embeddings = self.llama_model.embed_tokens(tokens)\n","\n","            if token_embeddings.size(1) > config.num_virtual_tokens:\n","                self.prompt_embeddings = nn.Parameter(\n","                    token_embeddings[0, :config.num_virtual_tokens, :]\n","                )\n","            else:\n","                padding = torch.randn(\n","                    config.num_virtual_tokens - token_embeddings.size(1),\n","                    self.embedding_dim,\n","                    device=self.device\n","                )\n","                self.prompt_embeddings = nn.Parameter(\n","                    torch.cat([token_embeddings[0], padding], dim=0)\n","                )\n","\n","    def forward(self, batch_size: int):\n","        return self.prompt_embeddings.repeat(batch_size, 1, 1)\n","\n","class PromptTunedModel(nn.Module):\n","    def __init__(self, base_model: PreTrainedModel, prompt_embedding: PromptEmbedding):\n","        super().__init__()\n","        self.base_model = base_model\n","        self.prompt_embedding = prompt_embedding\n","        self.config = base_model.config\n","\n","        # Freeze base model parameters\n","        for param in self.base_model.parameters():\n","            param.requires_grad = False\n","\n","        self.device = next(base_model.parameters()).device\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None, inputs_embeds=None, **kwargs):\n","        # Handle input embeddings\n","        if input_ids is not None and inputs_embeds is None:\n","            input_ids = input_ids.to(self.device)\n","            batch_size = input_ids.size(0)\n","            prompt_embeds = self.prompt_embedding(batch_size)\n","            inputs_embeds = self.prompt_embedding.llama_model.embed_tokens(input_ids)\n","            combined_embeds = torch.cat([prompt_embeds, inputs_embeds], dim=1)\n","        elif inputs_embeds is not None:\n","            combined_embeds = inputs_embeds\n","            batch_size = inputs_embeds.size(0)\n","        else:\n","            raise ValueError(\"Either input_ids or inputs_embeds should be provided\")\n","\n","        # Handle attention mask\n","        if attention_mask is not None:\n","            attention_mask = attention_mask.to(self.device)\n","            prompt_attention_mask = torch.ones(\n","                batch_size,\n","                self.prompt_embedding.config.num_virtual_tokens,\n","                device=self.device\n","            )\n","            combined_attention_mask = torch.cat(\n","                [prompt_attention_mask, attention_mask], dim=1\n","            )\n","        else:\n","            combined_attention_mask = None\n","\n","        # Handle labels by adding padding for prompt tokens\n","        if labels is not None:\n","            labels = labels.to(self.device)\n","            # Create padding labels for the prompt tokens (using -100 to ignore in loss calculation)\n","            prompt_labels = torch.full(\n","                (batch_size, self.prompt_embedding.config.num_virtual_tokens),\n","                -100,\n","                device=self.device,\n","                dtype=labels.dtype\n","            )\n","            # Concatenate the padding labels with the actual labels\n","            labels = torch.cat([prompt_labels, labels], dim=1)\n","\n","        # Forward all arguments to the base model\n","        model_kwargs = {\n","            'inputs_embeds': combined_embeds,\n","            'attention_mask': combined_attention_mask,\n","            'labels': labels,\n","            **kwargs  # Pass through any additional kwargs\n","        }\n","\n","        # Remove None values\n","        model_kwargs = {k: v for k, v in model_kwargs.items() if v is not None}\n","\n","        outputs = self.base_model(**model_kwargs)\n","\n","        return outputs\n","\n","    def get_input_embeddings(self):\n","        \"\"\"Return the base model's input embeddings layer\"\"\"\n","        return self.prompt_embedding.llama_model.embed_tokens\n","\n","    def set_input_embeddings(self, value):\n","        \"\"\"Set the base model's input embeddings layer\"\"\"\n","        self.prompt_embedding.llama_model.embed_tokens = value\n","\n","    def get_output_embeddings(self):\n","        \"\"\"Return the base model's output embeddings layer\"\"\"\n","        return self.base_model.get_output_embeddings()\n","\n","    def prepare_inputs_for_generation(self, *args, **kwargs):\n","        \"\"\"Prepare inputs for generation\"\"\"\n","        return self.base_model.prepare_inputs_for_generation(*args, **kwargs)\n","\n","# 모델 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","prompt_config = PromptTuningConfig(\n","    num_virtual_tokens=20,\n","    initialization_method=\"vocabulary\",\n","    prompt_tuning_init_text=\"This is a story about Harry Potter:\"\n",")\n","\n","prompt_embedding = PromptEmbedding(prompt_config, model, tokenizer)\n","prompt_tuned_model = PromptTunedModel(model, prompt_embedding)\n","prompt_tuned_model = prompt_tuned_model.to(device)\n","\n","# Training Arguments 설정\n","training_args = TrainingArguments(\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    warmup_steps=10,\n","    max_steps=100,\n","    learning_rate=1e-3,\n","    fp16=not torch.cuda.is_bf16_supported(),\n","    bf16=torch.cuda.is_bf16_supported(),\n","    logging_steps=1,\n","    optim=\"adamw_8bit\",\n","    weight_decay=0.00,\n","    lr_scheduler_type=\"linear\",\n","    seed=3407,\n","    output_dir=\"prompt_tuning_outputs\",\n","    evaluation_strategy=\"steps\",\n","    eval_steps=50,\n","    save_strategy=\"steps\",\n","    save_steps=50,\n","    save_total_limit=3,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n",")\n","\n","# Trainer 설정\n","trainer = SFTTrainer(\n","    model=prompt_tuned_model,\n","    tokenizer=tokenizer,\n","    train_dataset=split_dataset['train'],\n","    eval_dataset=split_dataset['test'],\n","    dataset_text_field=\"text\",\n","    max_seq_length=max_seq_length,\n","    dataset_num_proc=2,\n","    packing=False,\n","    args=training_args,\n",")\n","\n","# 학습 시작\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":203},"id":"BgtOkI3YUFbJ","outputId":"7a14d9d0-8509-4232-cc4f-b91e4f09baa8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["max_steps is given, it will override any value given in num_train_epochs\n","==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 35,332 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 100\n"," \"-____-\"     Number of trainable parameters = 81,920\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='51' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 51/100 41:13 < 41:13, 0.02 it/s, Epoch 0.01/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='178' max='2209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 178/2209 23:46 < 4:32:49, 0.12 it/s]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["# 모델 구조 더 자세히 확인\n","print(\"\\nDetailed model inspection:\")\n","model_to_check = model.base_model.base_model\n","print(f\"Type: {type(model_to_check)}\")\n","print(f\"Available attributes: {dir(model_to_check)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WWYZsh4OWPIx","executionInfo":{"status":"ok","timestamp":1733830442667,"user_tz":-540,"elapsed":486,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"dd0197fd-d2f7-42be-ffa4-f5a61c90fb92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Detailed model inspection:\n","Type: <class 'transformers.models.llama.modeling_llama.LlamaModel'>\n","Available attributes: ['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_assisted_decoding', '_auto_class', '_autoset_attn_implementation', '_backward_compatibility_gradient_checkpointing', '_backward_hooks', '_backward_pre_hooks', '_beam_search', '_buffers', '_call_impl', '_check_and_enable_flash_attn_2', '_check_and_enable_sdpa', '_compiled_call_impl', '_constrained_beam_search', '_contrastive_search', '_convert_head_mask_to_5d', '_copy_lm_head_original_to_resized', '_create_repo', '_dispatch_accelerate_model', '_dola_decoding', '_expand_inputs_for_generation', '_extract_past_from_model_output', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_from_config', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_cache', '_get_candidate_generator', '_get_files_timestamps', '_get_initial_cache_position', '_get_logits_processor', '_get_name', '_get_no_split_modules', '_get_resized_embeddings', '_get_resized_lm_head', '_get_stopping_criteria', '_gradient_checkpointing_func', '_group_beam_search', '_has_unfinished_sequences', '_hf_hook', '_hf_peft_config_loaded', '_hook_rss_memory_post_forward', '_hook_rss_memory_pre_forward', '_init_added_embeddings_weights_with_mean', '_init_added_lm_head_bias_with_mean', '_init_added_lm_head_weights_with_mean', '_init_weights', '_initialize_weights', '_is_full_backward_hook', '_is_hf_initialized', '_is_quantized_training_enabled', '_is_stateful', '_keep_in_fp32_modules', '_keep_in_fp32_modules', '_keys_to_ignore_on_load_missing', '_keys_to_ignore_on_load_unexpected', '_keys_to_ignore_on_save', '_load_from_state_dict', '_load_pretrained_model', '_load_pretrained_model_low_mem', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_initialize_input_ids_for_generation', '_maybe_warn_non_full_backward_hook', '_merge_criteria_processor_list', '_modules', '_named_members', '_no_split_modules', '_non_persistent_buffers_set', '_offloaded_gradient_checkpointing', '_old_forward', '_parameters', '_prepare_4d_causal_attention_mask_with_cache_position', '_prepare_attention_mask_for_generation', '_prepare_cache_for_generation', '_prepare_decoder_input_ids_for_generation', '_prepare_encoder_decoder_kwargs_for_generation', '_prepare_generated_length', '_prepare_generation_config', '_prepare_model_inputs', '_prepare_special_tokens', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_reorder_cache', '_replicate_for_data_parallel', '_resize_token_embeddings', '_sample', '_save_to_state_dict', '_saved_temp_tokenizer', '_set_default_torch_dtype', '_set_gradient_checkpointing', '_skip_keys_device_placement', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_supports_cache_class', '_supports_default_dynamic_cache', '_supports_flash_attn_2', '_supports_num_logits_to_keep', '_supports_quantized_cache', '_supports_sdpa', '_supports_static_cache', '_temporary_reorder_cache', '_tie_encoder_decoder_weights', '_tie_or_clone_weights', '_tied_weights_keys', '_update_causal_mask', '_update_model_kwargs_for_generation', '_upload_modified_files', '_validate_assistant', '_validate_generated_length', '_validate_model_class', '_validate_model_kwargs', '_version', '_wrapped_call_impl', 'active_adapter', 'active_adapters', 'add_adapter', 'add_memory_hooks', 'add_model_tags', 'add_module', 'apply', 'base_model', 'base_model_prefix', 'bfloat16', 'buffers', 'call_super_init', 'can_generate', 'children', 'compile', 'compute_transition_scores', 'config', 'config_class', 'cpu', 'create_extended_attention_mask_for_decoder', 'cuda', 'dequantize', 'device', 'disable_adapters', 'disable_input_require_grads', 'double', 'dtype', 'dummy_inputs', 'dump_patches', 'embed_tokens', 'enable_adapters', 'enable_input_require_grads', 'estimate_tokens', 'eval', 'extra_repr', 'float', 'floating_point_ops', 'forward', 'forward', 'framework', 'from_pretrained', 'generate', 'generation_config', 'get_adapter_state_dict', 'get_buffer', 'get_extended_attention_mask', 'get_extra_state', 'get_head_mask', 'get_input_embeddings', 'get_memory_footprint', 'get_output_embeddings', 'get_parameter', 'get_position_embeddings', 'get_submodule', 'gradient_checkpointing', 'gradient_checkpointing_disable', 'gradient_checkpointing_enable', 'half', 'heal_tokens', 'init_weights', 'invert_attention_mask', 'ipu', 'is_gradient_checkpointing', 'is_parallelizable', 'layers', 'load_adapter', 'load_state_dict', 'loss_function', 'main_input_name', 'max_seq_length', 'model_tags', 'model_tags', 'modules', 'mtia', 'name_or_path', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'norm', 'num_parameters', 'original_push_to_hub', 'padding_idx', 'parameters', 'post_init', 'prepare_inputs_for_generation', 'prune_heads', 'push_to_hub', 'push_to_hub', 'register_backward_hook', 'register_buffer', 'register_for_auto_class', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'reset_memory_hooks_state', 'resize_position_embeddings', 'resize_token_embeddings', 'retrieve_modules_from_names', 'reverse_bettertransformer', 'rotary_emb', 'save_pretrained', 'set_adapter', 'set_extra_state', 'set_input_embeddings', 'set_submodule', 'share_memory', 'state_dict', 'supports_gradient_checkpointing', 'tie_weights', 'to', 'to_bettertransformer', 'to_empty', 'train', 'training', 'type', 'vocab_size', 'warn_if_padding_and_no_attention_mask', 'warnings_issued', 'xpu', 'zero_grad']\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCqnaKmlO1U9","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733759566493,"user_tz":-540,"elapsed":1044,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"49bca5ac-4a37-437f-8570-84b9de2e17e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["4770.1562 seconds used for training.\n","79.5 minutes used for training.\n","Peak reserved memory = 8.439 GB.\n","Peak reserved memory for training = 2.834 GB.\n","Peak reserved memory % of max memory = 57.221 %.\n","Peak reserved memory for training % of max memory = 19.216 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","source":["# 4. Using, Saving, Loading the LoRA Model"],"metadata":{"id":"kHDqv5fAHOLH"}},{"cell_type":"code","source":["if True:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model)"],"metadata":{"id":"4RTOq1w3vUrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Su6oHXy0vUtJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장할 경로 설정\n","save_directory = \"/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Harry Potter LoRA 100\"\n","\n","# 모델 저장\n","model.save_pretrained(save_directory)\n","\n","# 토크나이저 저장\n","tokenizer.save_pretrained(save_directory)\n","\n","# 학습 상태(config) 저장 - 선택사항\n","trainer.save_state()\n","\n","import os\n","print(\"저장된 파일들:\")\n","for file in os.listdir(save_directory):\n","    print(f\"- {file}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMBpyx8_KH-w","executionInfo":{"status":"ok","timestamp":1733837547883,"user_tz":-540,"elapsed":2306,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"c2a44553-eaa0-40f6-b4cf-4f70458cf877"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["저장된 파일들:\n","- README.md\n","- adapter_model.safetensors\n","- adapter_config.json\n","- tokenizer_config.json\n","- special_tokens_map.json\n","- tokenizer.json\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# 저장된 경로\n","save_directory = \"/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Harry Potter LoRA\"\n","\n","# 모델과 토크나이저 불러오기\n","model = AutoModelForCausalLM.from_pretrained(save_directory)\n","tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","\n","# GPU로 모델 이동 (if available)\n","model = model.to(\"cuda\")"],"metadata":{"id":"p6IaLVpQKeT1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!"],"metadata":{"id":"ekOmTR1hSNcr"}},{"cell_type":"markdown","source":[" You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"],"metadata":{"id":"CrSvZObor0lY"}},{"cell_type":"code","source":["test_cases = [\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Harry and Snape:\",\n","    \"input\": \"Scene:\\nThe dungeon was darker than usual, filled with weird-colored smoke from everyone's cauldrons. Snape's lip curled when he saw Harry's watery potion.\\n\\\"Potter, what is this supposed to be?\\\"\\n\\nCharacter Information:\\nSnape:\\n- name: Severus Snape\\n- title: Potions Master\\n- character: Sarcastic, strict, bitter\\n- affiliation: Hogwarts Professor\\n\\nHarry:\\n- name: Harry Potter\\n- age: 11\\n- affiliation: Gryffindor student\\n\\nPrevious Dialogue:\\nSnape: Potter, what is this supposed to be?\",\n","    \"expected_output\": \"Harry: The Draught of Living Death, sir.\"\n","  },\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Hermione and Ron:\",\n","    \"input\": \"Scene:\\nThe library was quiet except for the rustling of pages. Hermione was surrounded by a tower of books about House-elves' rights, while Ron looked on with disbelief.\\n\\\"Honestly, Hermione, they like working!\\\"\\n\\nCharacter Information:\\nHermione:\\n- name: Hermione Granger\\n- character: Passionate about justice, intelligent\\n- affiliation: S.P.E.W. founder\\n\\nRon:\\n- name: Ron Weasley\\n- character: Practical, sometimes insensitive\\n\\nPrevious Dialogue:\\nRon: Honestly, Hermione, they like working!\",\n","    \"expected_output\": \"Hermione: That's because they've been conditioned to accept their oppression, Ron!\"\n","  },\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Voldemort and Dumbledore:\",\n","    \"input\": \"Scene:\\nThe Ministry's Atrium was silent. Broken glass littered the floor from the magical battle. Voldemort and Dumbledore faced each other, wands raised.\\n\\\"You do not seek to kill me, Dumbledore?\\\"\\n\\nCharacter Information:\\nVoldemort:\\n- name: Lord Voldemort\\n- character: Ruthless, powerful, fears death\\n- affiliation: Dark Lord\\n\\nDumbledore:\\n- name: Albus Dumbledore\\n- character: Wise, powerful, compassionate\\n- affiliation: Hogwarts Headmaster\\n\\nPrevious Dialogue:\\nVoldemort: You do not seek to kill me, Dumbledore?\",\n","    \"expected_output\": \"Dumbledore: We both know there are other ways of destroying a man, Tom.\"\n","  },\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Sirius and Harry:\",\n","    \"input\": \"Scene:\\nThe cave near Hogsmeade was cold and dark. Buckbeak lay in the corner, while Sirius tore apart a chicken leg. Harry sat across from his godfather, worried about the Triwizard Tournament.\\n\\\"I don't know if I can do this, Sirius.\\\"\\n\\nCharacter Information:\\nSirius:\\n- name: Sirius Black\\n- character: Brave, protective, reckless\\n- relation: Harry's godfather\\n\\nHarry:\\n- name: Harry Potter\\n- age: 14\\n- character: Worried but determined\\n\\nPrevious Dialogue:\\nHarry: I don't know if I can do this, Sirius.\",\n","    \"expected_output\": \"Sirius: You're your father's son, Harry. James would've laughed in the face of danger too.\"\n","  },\n","  {\n","    \"instruction\": \"Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Luna and Neville:\",\n","    \"input\": \"Scene:\\nThe Room of Requirement was filled with students practicing defensive spells. Luna watched as Neville finally mastered a particularly difficult Shield Charm.\\n\\\"I've never seen anyone improve so quickly, Neville.\\\"\\n\\nCharacter Information:\\nLuna:\\n- name: Luna Lovegood\\n- character: Dreamy, honest, perceptive\\n- affiliation: Dumbledore's Army\\n\\nNeville:\\n- name: Neville Longbottom\\n- character: Growing confidence, determined\\n- affiliation: Dumbledore's Army\\n\\nPrevious Dialogue:\\nLuna: I've never seen anyone improve so quickly, Neville.\",\n","    \"expected_output\": \"Neville: Thanks Luna. I suppose we all have to step up now that Harry's teaching us.\"\n","  }\n","]"],"metadata":{"id":"U59tUacQMqAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_cases[1]['instruction']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"dbEnLDAGNDFg","executionInfo":{"status":"ok","timestamp":1733760948451,"user_tz":-540,"elapsed":462,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"ea18275c-cc25-4ab3-a1d8-ea2d189e5d32"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Hermione and Ron:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["output_train_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_train_set.json'\n","output_test_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_test_set.json'\n","formatted_dataset_path = '/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/Dataset Station/Harry Potter Alpaca/hpa_formatted_dataset'\n","\n","with open(output_train_path, 'r', encoding='utf-8') as f:\n","    train_data = json.load(f)\n","\n","with open(output_test_path, 'r', encoding='utf-8') as f:\n","    test_data = json.load(f)\n","\n","# 나중에 데이터셋을 다시 로드할 때는 다음과 같이 사용할 수 있습니다:\n","from datasets import load_from_disk\n","formatted_dataset = load_from_disk(formatted_dataset_path)"],"metadata":{"id":"LfF4EqDWRWjJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(formatted_dataset['train']['text'][0])"],"metadata":{"id":"6hGWKy5NV40d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_json[3][\"instruction\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NGV3REQRaZAL","executionInfo":{"status":"ok","timestamp":1733762122181,"user_tz":-540,"elapsed":1267,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"9df3cd9d-252b-4c91-be75-493299f69ee1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Given the following scene, character attributes, and previous dialogue, generate the next line of dialogue between Petunia and Vernon and Harry:\n"]}]},{"cell_type":"code","source":["print(train_json[3][\"input\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFT0axc4Rpeu","executionInfo":{"status":"ok","timestamp":1733762136983,"user_tz":-540,"elapsed":479,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"25d04ea7-508a-467a-8994-e305bb75e8e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scene:\n","“Bad news, Vernon,” she said. “Mrs. Figg’s broken her leg. She can’t take him.” She jerked her head in Harry’s direction.\n","Dudley’s mouth fell open in horror, but Harry’s heart gave a leap. Every year on Dudley’s birthday, his parents took him and a friend out for the day, to adventure parks, hamburger restaurants, or the movies. Every year, Harry was left behind with Mrs. Figg, a mad old lady who lived two streets away. Harry hated it there. The whole house smelled of cabbage and Mrs. Figg made him look at photographs of all the cats she’d ever owned.\n","“Now what?” said Aunt Petunia, looking furiously at Harry as though he’d planned this. Harry knew he ought to feel sorry that Mrs. Figg had broken her leg, but it wasn’t easy when he reminded himself it would be a whole year before he had to look at Tibbles, Snowy, Mr. Paws, and Tufty again.\n","“We could phone Marge,” Uncle Vernon suggested.\n","“Don’t be silly, Vernon, she hates the boy.”\n","The Dursleys often spoke about Harry like this, as though he wasn’t there — or rather, as though he was something very nasty that couldn’t understand them, like a slug.\n","“What about what’s-her-name, your friend — Yvonne?”\n","“On vacation in Majorca,” snapped Aunt Petunia.\n","“You could just leave me here,” Harry put in hopefully (he’d be able to watch what he wanted on television for a change and maybe even have a go on Dudley’s computer).\n","Aunt Petunia looked as though she’d just swallowed a lemon.\n","“And come back and find the house in ruins?” she snarled.\n","“I won’t blow up the house,” said Harry, but they weren’t listening.\n","“I suppose we could take him to the zoo,” said Aunt Petunia slowly, “. . . and leave him in the car. . . .”\n","“That car’s new, he’s not sitting in it alone. . . .”\n","Dudley began to cry loudly. In fact, he wasn’t really crying — it had been years since he’d really cried — but he knew that if he screwed up his face and wailed, his mother would give him anything he wanted.\n","“Dinky Duddydums, don’t cry, Mummy won’t let him spoil your special day!” she cried, flinging her arms around him.\n","“I . . . don’t . . . want . . . him . . . t-t-to come!” Dudley yelled between huge, pretend sobs. “He always sp-spoils everything!” He shot Harry a nasty grin through the gap in his mother’s arms.\n","Just then, the doorbell rang —“Oh, good Lord, they’re here!” said Aunt Petunia frantically — and a moment later, Dudley’s best friend, Piers Polkiss, walked in with his mother. Piers was a scrawny boy with a face like a rat. He was usually the one who held people’s arms behind their backs while Dudley hit them. Dudley stopped pretending to cry at once.\n","Half an hour later, Harry, who couldn’t believe his luck, was sitting in the back of the Dursleys’ car with Piers and Dudley, on the way to the zoo for the first time in his life. His aunt and uncle hadn’t been able to think of anything else to do with him, but before they’d left, Uncle Vernon had taken Harry aside.\n","“I’m warning you,” he had said, putting his large purple face right up close to Harry’s, “I’m warning you now, boy — any funny business, anything at all — and you’ll be in that cupboard from now until Christmas.”\n","\n","Character Information:\n","Petunia:\n","- name: Petunia\n","- gender: Female\n","- age: Adult\n","- looks: Slender, blond hair, long neck\n","- character: Message, gossip\n","- lineage: Maculogy\n","Relations with Harry:\n","- family: 1.0\n","- Harry's affection to him: -4.0\n","- Harry's familiarity with him: 8.0\n","- His affection to Harry: -4.0\n","- His familiarity with Harry: 6.0\n","\n","Vernon:\n","- name: Vernon Dursley\n","- gender: male\n","- age: Adult\n","- looks: Very fat, tall and burly, accumulating beard\n","- character: mean\n","- belongings: car\n","- affiliation: Grandine Company\n","- lineage: Maculogy\n","- title: Company supervisor\n","Relations with Harry:\n","- family: 1.0\n","- Harry's affection to him: -4.0\n","- Harry's familiarity with him: 8.0\n","- His affection to Harry: -4.0\n","- His familiarity with Harry: 6.0\n","\n","Harry:\n","- name: Harry\n","- nickname: The boy who lived\n","- gender: male\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- title: The boy who lived\n","\n","\n","Previous Dialogue:\n","Petunia: Bad news, Vernon, Mrs. Figg’s broken her leg. She can’t take him. Now what? \n","\n"]}]},{"cell_type":"code","source":["print(train_json[3][\"output\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJPcHBWkSB80","executionInfo":{"status":"ok","timestamp":1733762244389,"user_tz":-540,"elapsed":926,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"e93c4d7e-2d9e-45ac-f5dd-87d461566144"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vernon: We could phone Marge,\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2r3ydL6GdEuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jt86m47idEw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from nltk.lm import MLE\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from scipy.spatial.distance import cosine\n","from sentence_transformers import SentenceTransformer\n","import nltk\n","\n","# Download required NLTK data\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","def calculate_bleu(reference, hypothesis):\n","    \"\"\"\n","    Calculate BLEU score between reference and hypothesis\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: BLEU score\n","    \"\"\"\n","    # Tokenize the sentences\n","    ref_tokens = nltk.word_tokenize(reference.lower())\n","    hyp_tokens = nltk.word_tokenize(hypothesis.lower())\n","\n","    # Calculate BLEU score with smoothing\n","    smoothing = SmoothingFunction().method1\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoothing)\n","\n","def calculate_meteor(reference, hypothesis):\n","    \"\"\"\n","    Calculate METEOR score between reference and hypothesis\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: METEOR score\n","    \"\"\"\n","    return meteor_score([reference.split()], hypothesis.split())\n","\n","def calculate_perplexity(text, model_name='gpt2'):\n","    \"\"\"\n","    Calculate perplexity using GPT-2\n","\n","    Args:\n","        text (str): Input text to calculate perplexity for\n","        model_name (str): Name of the pretrained model to use\n","\n","    Returns:\n","        float: Perplexity score\n","    \"\"\"\n","    # Load model and tokenizer\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    model.eval()\n","\n","    # Encode text\n","    encodings = tokenizer(text, return_tensors='pt')\n","\n","    # Calculate perplexity\n","    max_length = model.config.n_positions\n","    stride = 512\n","    seq_len = encodings.input_ids.size(1)\n","\n","    nlls = []\n","    prev_end_loc = 0\n","    for begin_loc in range(0, seq_len, stride):\n","        end_loc = min(begin_loc + max_length, seq_len)\n","        trg_len = end_loc - prev_end_loc\n","        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n","        target_ids = input_ids.clone()\n","        target_ids[:, :-trg_len] = -100\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, labels=target_ids)\n","            neg_log_likelihood = outputs.loss\n","\n","        nlls.append(neg_log_likelihood)\n","        prev_end_loc = end_loc\n","        if end_loc == seq_len:\n","            break\n","\n","    ppl = torch.exp(torch.stack(nlls).mean())\n","    return ppl.item()\n","\n","def calculate_simile(reference, hypothesis):\n","    \"\"\"\n","    Calculate SIMILE (Semantic Similarity) score using sentence transformers\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: SIMILE score (cosine similarity between sentence embeddings)\n","    \"\"\"\n","    # Load sentence transformer model\n","    model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","    # Get embeddings\n","    ref_embedding = model.encode([reference])[0]\n","    hyp_embedding = model.encode([hypothesis])[0]\n","\n","    # Calculate cosine similarity\n","    similarity = 1 - cosine(ref_embedding, hyp_embedding)\n","    return similarity\n","\n","def evaluate_responses(references, hypotheses):\n","    \"\"\"\n","    Calculate all metrics for a list of reference and hypothesis texts\n","\n","    Args:\n","        references (list): List of reference texts\n","        hypotheses (list): List of hypothesis texts\n","\n","    Returns:\n","        dict: Dictionary containing average scores for all metrics\n","    \"\"\"\n","    scores = {\n","        'bleu': [],\n","        'meteor': [],\n","        'perplexity': [],\n","        'simile': []\n","    }\n","\n","    for ref, hyp in zip(references, hypotheses):\n","        scores['bleu'].append(calculate_bleu(ref, hyp))\n","        scores['meteor'].append(calculate_meteor(ref, hyp))\n","        scores['perplexity'].append(calculate_perplexity(hyp))\n","        scores['simile'].append(calculate_simile(ref, hyp))\n","\n","    # Calculate averages\n","    return {metric: np.mean(values) for metric, values in scores.items()}\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Sample data\n","    references = [\n","        \"The quick brown fox jumps over the lazy dog.\",\n","        \"Machine learning is a subset of artificial intelligence.\"\n","    ]\n","    hypotheses = [\n","        \"The fast brown fox leaps over the sleeping dog.\",\n","        \"Machine learning is a branch of artificial intelligence.\"\n","    ]\n","\n","    # Install required packages if not already installed\n","    !pip install -q transformers torch sentence-transformers nltk\n","\n","    # Calculate scores\n","    scores = evaluate_responses(references, hypotheses)\n","\n","    # Print results\n","    print(\"\\nEvaluation Metrics:\")\n","    print(f\"BLEU Score: {scores['bleu']:.4f}\")\n","    print(f\"METEOR Score: {scores['meteor']:.4f}\")\n","    print(f\"Perplexity: {scores['perplexity']:.4f}\")\n","    print(f\"SIMILE Score: {scores['simile']:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":814},"id":"p2eJK8grdEy_","executionInfo":{"status":"error","timestamp":1733815609110,"user_tz":-540,"elapsed":6529,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"a9d8d30f-d949-4b39-dad0-ac5ecc64be5b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"error","ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-fdf86f275d68>\u001b[0m in \u001b[0;36m<cell line: 144>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# Calculate scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_responses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-fdf86f275d68>\u001b[0m in \u001b[0;36mevaluate_responses\u001b[0;34m(references, hypotheses)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bleu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meteor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_meteor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perplexity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-fdf86f275d68>\u001b[0m in \u001b[0;36mcalculate_bleu\u001b[0;34m(reference, hypothesis)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Tokenize the sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mref_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mhyp_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     return [\n\u001b[1;32m    144\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_punkt_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPunktTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mPunktSentenceTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mload_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mlang_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt_tab/{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_punkt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"]}]},{"cell_type":"code","source":["# Install required packages\n","!pip install -q transformers torch sentence-transformers nltk\n","\n","import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from nltk.lm import MLE\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from scipy.spatial.distance import cosine\n","from sentence_transformers import SentenceTransformer\n","import nltk\n","\n","# Download ALL required NLTK data at the start\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger')\n","\n","def calculate_bleu(reference, hypothesis):\n","    \"\"\"\n","    Calculate BLEU score between reference and hypothesis\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: BLEU score\n","    \"\"\"\n","    # Tokenize the sentences\n","    ref_tokens = nltk.word_tokenize(reference.lower())\n","    hyp_tokens = nltk.word_tokenize(hypothesis.lower())\n","\n","    # Calculate BLEU score with smoothing\n","    smoothing = SmoothingFunction().method1\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoothing)\n","\n","def calculate_meteor(reference, hypothesis):\n","    \"\"\"\n","    Calculate METEOR score between reference and hypothesis\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: METEOR score\n","    \"\"\"\n","    return meteor_score([reference.split()], hypothesis.split())\n","\n","def calculate_perplexity(text, model_name='gpt2'):\n","    \"\"\"\n","    Calculate perplexity using GPT-2\n","\n","    Args:\n","        text (str): Input text to calculate perplexity for\n","        model_name (str): Name of the pretrained model to use\n","\n","    Returns:\n","        float: Perplexity score\n","    \"\"\"\n","    # Load model and tokenizer\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    model.eval()\n","\n","    # Encode text\n","    encodings = tokenizer(text, return_tensors='pt')\n","\n","    # Calculate perplexity\n","    max_length = model.config.n_positions\n","    stride = 512\n","    seq_len = encodings.input_ids.size(1)\n","\n","    nlls = []\n","    prev_end_loc = 0\n","    for begin_loc in range(0, seq_len, stride):\n","        end_loc = min(begin_loc + max_length, seq_len)\n","        trg_len = end_loc - prev_end_loc\n","        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n","        target_ids = input_ids.clone()\n","        target_ids[:, :-trg_len] = -100\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, labels=target_ids)\n","            neg_log_likelihood = outputs.loss\n","\n","        nlls.append(neg_log_likelihood)\n","        prev_end_loc = end_loc\n","        if end_loc == seq_len:\n","            break\n","\n","    ppl = torch.exp(torch.stack(nlls).mean())\n","    return ppl.item()\n","\n","def calculate_simile(reference, hypothesis):\n","    \"\"\"\n","    Calculate SIMILE (Semantic Similarity) score using sentence transformers\n","\n","    Args:\n","        reference (str): The reference/ground truth text\n","        hypothesis (str): The generated/hypothesis text\n","\n","    Returns:\n","        float: SIMILE score (cosine similarity between sentence embeddings)\n","    \"\"\"\n","    # Load sentence transformer model\n","    model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","    # Get embeddings\n","    ref_embedding = model.encode([reference])[0]\n","    hyp_embedding = model.encode([hypothesis])[0]\n","\n","    # Calculate cosine similarity\n","    similarity = 1 - cosine(ref_embedding, hyp_embedding)\n","    return similarity\n","\n","def evaluate_responses(references, hypotheses):\n","    \"\"\"\n","    Calculate all metrics for a list of reference and hypothesis texts\n","\n","    Args:\n","        references (list): List of reference texts\n","        hypotheses (list): List of hypothesis texts\n","\n","    Returns:\n","        dict: Dictionary containing average scores for all metrics\n","    \"\"\"\n","    scores = {\n","        'bleu': [],\n","        'meteor': [],\n","        'perplexity': [],\n","        'simile': []\n","    }\n","\n","    for ref, hyp in zip(references, hypotheses):\n","        scores['bleu'].append(calculate_bleu(ref, hyp))\n","        scores['meteor'].append(calculate_meteor(ref, hyp))\n","        scores['perplexity'].append(calculate_perplexity(hyp))\n","        scores['simile'].append(calculate_simile(ref, hyp))\n","\n","    # Calculate averages\n","    return {metric: np.mean(values) for metric, values in scores.items()}\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Sample data\n","    references = [\n","        \"The quick brown fox jumps over the lazy dog.\",\n","        \"Machine learning is a subset of artificial intelligence.\"\n","    ]\n","    hypotheses = [\n","        \"The fast brown fox leaps over the sleeping dog.\",\n","        \"Machine learning is a branch of artificial intelligence.\"\n","    ]\n","\n","    # Calculate scores\n","    scores = evaluate_responses(references, hypotheses)\n","\n","    # Print results\n","    print(\"\\nEvaluation Metrics:\")\n","    print(f\"BLEU Score: {scores['bleu']:.4f}\")\n","    print(f\"METEOR Score: {scores['meteor']:.4f}\")\n","    print(f\"Perplexity: {scores['perplexity']:.4f}\")\n","    print(f\"SIMILE Score: {scores['simile']:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":887,"referenced_widgets":["06b0b5c6bd4c4606b96c56586a5a969f","54f71e95d414421c8955d0ed6a72a0be","7804471a616b4b3c82b25fb571cfdbbe","11fe91b689df446db617cd60bc289862","54f9c7b5ff8f47c994275e5e02bfcd9f","b209a5ce1a4641fdbf9ea503acb0f108","737e7fe57c8545bea4c2d7af1099e48e","f3c9246062f147e48ba5f793cb8c1dac","dc6097ac48c54ea3a2da7c8532176b9d","248de5138a8243e288d8c5ed9b6b3a37","7430be762ab44b9e9ad7476f9b408ead","d1a9193130964a32a15544dab5310d2a","9813b985e97c411fa554f362ee3c42b8","da34e5ba9d4c4342875ab07be2257804","ecc146ea7c744add8845eb093bac824b","3cdc75bbc37b4ec2bed70355d60a9078","4c949bedfe5f4350b1731e4333d0871e","ee457dcaa92b4f73a60408ac12cb3ccd","8e9f6090106b4a7aacdc6bce521c9f83","bf9a90bb39d447a4abba2cec4ab6ed94","0101882a7c024f659558a1fb19244462","b280b36a94734adbb1648fbd0d4e4d53","1b5268fcc60d4b4f8ed5287516558f90","350ad988dcc24b29985684cd87a01128","3f925f435c644a2fbe2f10cb7095c199","4b33ae6dbe3947878789154d3b7f69db","60912685336a4324b19dcf106e8a30ad","786baba186ff40eb9f4923d306493d5f","9d144ebfe96045eca3eb0a9cfa0914a8","6803e762288c427cb0d6a7074473ec22","c41796fbc16e4c77852bd772e275b1bf","4676d0e3769f404cb0cbde38a42c37ca","6c9b78b2748e4aaeb14ff90f37c03038","d16094dc3f81455bb8cf2fc8e6730ca0","dd9fb35cf2d2476c89defd096273a5f1","177b85f83eec47beb41e72683e887366","8555042c75a047efa47a9ff6a634a6f3","f8d22dc858494872b01c34bb49563ec2","0f5850588abf498bb45c64c39c75f932","15a6cb3a0d534efe973c5e98b6afd3e1","bc1c489409eb493d8c5b89068d7ba9ed","c4e4cc5e14304c0a9e656a1ef69410bb","37afa932f1884e77b1ed6e9fbc4a025c","47d59a08e75f45c780c241eab5f77417","5eb7172adae9467f85a9faf4cc414247","38bdd48028a14a3192b0e2d2be54642f","eafceacb104e4622b54faaa5a3f00f1f","d9e3fce8db43428097b6592621f02d5f","b699a4911ba649c2a8015a63fe342c2a","289408ddb467436f808ec2d62160f843","16ed514587a84338a6eb39b96179c57d","605dfc90d21f470484634e125d40de6f","3eaa26d43e9e431b9f1481fac2b71b86","1fdfc46b60f94d578afdc8408b5b1f38","7b82c4f0073b43b7a20a811e390cc6b5","5b822ce0dc4942a5b10a38729fc9d940","376bccb84a654dd0b63d6f7539763ee1","1156178e280248fd9e33abead2a23e9e","572ba88a54bd452c9e19d06f523e592e","9c21507260914e98b308eee228c82b5c","a9ca2cdc28d1470498186ee6e0ced4f3","debb00b747c94b9f91471ab97bbb7420","1aa2d7f795c542d083eb4ef83cc898ac","f0d4403d5bec491aafa25bd51a22daac","2cb597f252a34c83afdde505e9ffdbf9","93d89ce3fc8143a680f632ebb4adf540","aeb8280f9ce7428b88fd77b49ff948fb","7e945787c68d4d49948695f490220248","8ef7b9d616c343b3b7dcf7883ff945e2","65917152dc604aeda0edc1c47c367484","f16b291a5d2f4bd4b9635b5aa99b3145","97a267e4f5cf4238bfcdff19b785987e","5ae0273b0a834c1c979c9d1b594efd31","befc06fe73644b4c85635f04ff3ab2d9","f2d9f492d8ad48ee8f6abc4b7b0ee977","5f40ae75ce1f4a309e37cb8e61f6a7e8","70929129f1f94438a7ba340a6d403d15","91ea0a96d7be4e6882a47bf65e451a56","eed2aa114b494969abbac1cde7fb47fb","5c03fe142ff842979513e5d4918793fb","863264cfb9704716b0650feb18925d7a","0db011e15d94455b92c21c7762fda4c4","26e96f4d96834a44856c9c1bc4c31898","f433cad65814441881566a9c18bbae59","e3277da32e874d779948d2aa27c87e56","a3905c9747d84172967ea1a0d94c7406","866795b0cc554da8acaa63d9ebbd214f","fcc7d69a1f35451c8967f3e0a71da2ed","fcb9e204ae644a6f80fe924e16cdb0fd","6b00b87e8db4459eb0758d0419fe07ee","84cfed1b59ed4d918ff594947be27adb","b31acc9e55ba41929c7dab203fb79978","939b5ada21bb4b858128a1d4caa9117f","31f4ebde0fe049c68adc14e8a5b5b83d","2859ae351c884351aecac5bfea7a6268","8788398ad42648eebc21afab6eb43494","158bb8aebead4eacbbdcc7d854450ec3","53613814bcc840629b85df1b81433a49","94cf679831484e61a61548e878920c64","d0bf3aa31dfe4e84bb8fe6f778e04ebd","f0d53a637764468abcd42a4b7436a2eb","69711a6bed4243dcaef1172005affa93","94d40cb5e4ee46719f47453a8a49435a","d720daf786e84ef780f9c54346af1be2","e4bc59acfefe4d5587f65a161445ae45","96d1b98bf3f346c3bd401f39d4944bd4","18cae444d1e14a34ae33174d301f1b91","f829babaa56e4b6bb670b2fb394be5a6","cf0f4c95fc974cef9093c2de6c807dfc","8973dc3d59504d5fa1f1967ce575bc7c","437af67932df433589d66affbc3da5fa","67df030304d94110a92a9036ad9c3ae7","ef3322b1830f4ec8bc06cde267434a7f","84a5197dd9ec4e5c8936551eb21a17c2","f5183736ca124e3ea327c4e1dc8c1e81","b3d438d7703b4e1fb11100534b478b85","ce1e4e7661144057b56e3e871d9ef6b4","8944addec5294f62abad29ed983f9d2e","58d30bff243544caa8d37b39e086e8d9","e6edefa1eec1411abcf84f2a00b56328","f4fb331d752d4add96ba184f9eb1f148","a983e6264b2c47e5961d6026e03454f4","43d96cf8e7c0441dbff06c89f1fab67a","dbee6b6638fc4108b68476e1ab928f40","3782966617394ae2a8c1a2d326e8e023","d542f761d50a48408031f0b3196586fb","84394c3dee9545d783e3f25cc1cfe658","6fbcd51dbffb40d1a6bc6b7fc7321b54","a12ce4c1a46b4c90aee55957aa9379b2","55d206ad7de340059ce19e973cb64647","dc9cec09589240c1a7cca71d22e1dc1c","75499456c89d4ef6ac2358d280b519b4","68e35762c9254b93b5af79b87a1b915d","d542a0a6324f4f2fbd1fa3a4329dc09c","e8ed5fbe7b4248e99924eca3aa782cd6","e35d12fc7b9a4e4689a1ad4091450b5f","a589061c45844ba1b25fd697cfa4df04","8e5c130e104a4719b8a03779d79d8471","63a129ea4f474caeadfd9c613a22158e","c2eae8b240934a5d82d9a0224427b25d","50ff39c332b74150ae0f94089d7a2ef3","834cf3587ed442b08003c2d4fda0d89f","77d96a7599d34559840ae84f7c541b75","23356d2e2a514506a56f12c6c3f75a98","a7047118b19b4276869d3fec71ab4822","35bf59643b70494a82c7abe20b7872ad","27a3eee23cb349c083c90227b333acd2","e8982b572c75466e8e78a366a2ebe474","64752a50060e4768928ae1b553a77d4d","f8d9c508a5444eb984372f2dd0f596ba","92964bfb29d24e15a054b724df7ffbf9","712f227f1028439893886da36d2fb6f2","9f758b677ce644579e0d04434ea01ad2","e0c07743b6134cc8adafa2287339e4ee","b6698b2f0a0748c593f8266a03e8e3a1","a28bc8b706d544f581d4793fe1f44297","6dbbea6f0c0348c88cbd7739774cc324","6c2f09e456ef4b2b8d2e17012e5093b2","95ee80498f87425aa3e4c7b5e9bf36de","8564cf1b429e49b99c8f52dba6a7f038","2f50793d2b264caf9e8b8478f9123d3f","5b37c73ac2d34886b126481a4b2bb553","952bac09ae824f02b127d04bcba8510d","a99e3fd505014877948e52c120b973cc","863e14ba8d2c4f0f9b2eefa009fa76f1","0f1c42eff3724a0aa7e2c8d9cca3d8f7","4b86acb21bb84f5d9baef7f96f9fc706","f72de091cb58404995d81cbfeb7561db","b2c94b607c4643778f2f4cb3b4383ebe","5bfec39d57614082bdedb25650d903ca","80cf5fa1a7b3451785d401e10ff0d77c","c2fc3cf71cea4279ab40b555bfbab1f8","4b283a280e644b0185894d9c83e62fba","b4d7ac82f62147ff9be029a3f7b31f71","dd58f23b33ab48b5bc9691706850ecfc","ec1c80734f444e8fba351c0ef5c996d7","9c760e27bfa44c34a6b58470413ea430","c45defc9b220461f968e8ff084c39ad0","b9f9509d2a8141099d6e5e1d48385f23","2595f6c665a14f1e81faafab3ab71e94","313b03bd2238456794502432c280265c","4db00b6bbe6044e09b6f6d6517180bf0","f00fd8b4d5644ba3a69a662e0da9cb32","ebf5942b5dcf467faa172b1ddd315bf1","71a84d3ecb504943846915b33fa4fcdb","a4cd4a5c08ae402691a85ae10da59816","fcc2e03cf6bf4e56b87354936ff19f1a","300a8e3915344a14a5ee4cc4e9f9c8c9","36d2b63258d141919cfecfc38b2587db","6a28307dc08d4ab092661ab023f5beb6","42bb7fab57864aa9809fe9cfd928e708","83830143d44c48fba63c1d5301d71de9","1098e11bc01d481f836d6f681980f030","bddd129db7584bc584211544a9dd78db","9d7a8de016f149ecafc025222f75d467","7c7a5fe6812e4e78814416e26d8b3321","2ab59cd9b4f445618a0de8f32b8baf48","6ef524bde1f546b2824e400244e0016c"]},"id":"s-maaIkvejr3","executionInfo":{"status":"ok","timestamp":1733815891403,"user_tz":-540,"elapsed":41329,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"6aea2c06-9cc4-42c5-9bee-d4b1aa2deb10"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06b0b5c6bd4c4606b96c56586a5a969f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1a9193130964a32a15544dab5310d2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b5268fcc60d4b4f8ed5287516558f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d16094dc3f81455bb8cf2fc8e6730ca0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eb7172adae9467f85a9faf4cc414247"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b822ce0dc4942a5b10a38729fc9d940"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeb8280f9ce7428b88fd77b49ff948fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91ea0a96d7be4e6882a47bf65e451a56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb9e204ae644a6f80fe924e16cdb0fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0bf3aa31dfe4e84bb8fe6f778e04ebd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"437af67932df433589d66affbc3da5fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a983e6264b2c47e5961d6026e03454f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e35762c9254b93b5af79b87a1b915d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23356d2e2a514506a56f12c6c3f75a98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6698b2f0a0748c593f8266a03e8e3a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f1c42eff3724a0aa7e2c8d9cca3d8f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c760e27bfa44c34a6b58470413ea430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"300a8e3915344a14a5ee4cc4e9f9c8c9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Evaluation Metrics:\n","BLEU Score: 0.3386\n","METEOR Score: 0.8734\n","Perplexity: 166.2554\n","SIMILE Score: 0.8484\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a7aBU22AdE05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mchHIzcPdE4F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_n = 3"],"metadata":{"id":"avY1glKlSa8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","# ------------------------------------------------------------------------\n","\n","# 모델을 inference 모드로 설정\n","FastLanguageModel.for_inference(model)\n","\n","# 테스트할 예시 프롬프트 생성\n","test_instruction = train_json[test_n]['instruction']\n","test_input = train_json[test_n]['input']\n","\n","# 입력 텍스트 생성\n","inputs = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            test_instruction,  # instruction\n","            test_input,       # input\n","            \"\",              # output - 생성을 위해 비워둠\n","        )\n","    ],\n","    return_tensors=\"pt\"\n",").to(\"cuda\")\n","\n","# 텍스트 생성을 위한 streamer 설정\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","\n","# 생성 파라미터 설정\n","generation_params = {\n","    \"max_new_tokens\": 256,      # 더 긴 대화를 위해 증가\n","    \"temperature\": 0.2,         # 창의성 조절 (0.7)\n","    \"top_p\": 0.2,              # 다양성 조절 (0.9)\n","    \"do_sample\": True,         # 다양한 응답 생성 가능\n","    \"streamer\": text_streamer,\n","    \"pad_token_id\": tokenizer.pad_token_id,\n","    \"eos_token_id\": tokenizer.eos_token_id,\n","}\n","\n","# 텍스트 생성\n","print(\"Generating dialogue...\")\n","outputs = model.generate(**inputs, **generation_params)\n","\n","# 생성된 텍스트 디코딩 (streamer를 사용하지 않을 경우)\n","# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","# print(generated_text)\n","\n","# 여러 다른 상황에서 테스트하기 위한 함수\n","def generate_dialogue(instruction, scene, characters):\n","    input_text = f\"Scene:\\n{scene}\\n\\nCharacter Information:\\n{characters}\"\n","\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, **generation_params)\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","print(\"### Correct Dialogue:\")\n","print(train_json[test_n]['output'], \"<|end_of_text|>\")\n","\n","test_n += 1"],"metadata":{"id":"nSxmp-oXKyp_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a name=\"Save\"></a>\n","### Saving, loading finetuned models\n","To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n","\n","**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"],"metadata":{"id":"uMuVrWbjAzhc"}},{"cell_type":"markdown","source":["Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"],"metadata":{"id":"AEEcJ4qfC7Lp"}},{"cell_type":"code","source":["# if False:\n","#     from unsloth import FastLanguageModel\n","#     model, tokenizer = FastLanguageModel.from_pretrained(\n","#         model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","#         max_seq_length = max_seq_length,\n","#         dtype = dtype,\n","#         load_in_4bit = load_in_4bit,\n","#     )\n","#     FastLanguageModel.for_inference(model)\n","\n","# # alpaca_prompt = You MUST run cells from above!\n","\n","# inputs = tokenizer(\n","# [\n","#     alpaca_prompt.format(\n","#         \"What is a famous tall tower in Paris?\", # instruction\n","#         \"\", # input\n","#         \"\", # output - leave this blank for generation!\n","#     )\n","# ], return_tensors = \"pt\").to(\"cuda\")\n","\n","# outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","# tokenizer.batch_decode(outputs)"],"metadata":{"id":"MKX_XKs_BNZR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733454453005,"user_tz":-540,"elapsed":6257,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"32b5da67-cca3-4290-dbf8-ee52ca688af4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is a famous tall tower in Paris?\\n\\n### Input:\\n\\n\\n### Response:\\nThe Eiffel Tower is a famous tall tower located in Paris, France. It is 324 meters (1,063 feet) tall, making it the tallest structure in Paris. The Eiffel Tower was built in 1889 as the entrance arch for the 1889 World's Fair and was designed by\"]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[],"metadata":{"id":"mK5ptKBPbOcp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from typing import Dict, List, Optional\n","\n","class DialoguePromptGenerator:\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.base_prompt_template = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Generate the next line of dialogue that matches the character's personality, relationships, and the scene context.\n","\n","### Input:\n","Scene Description:\n","{scene}\n","\n","Character Information:\n","{character_info}\n","\n","Previous Dialogue:\n","{dialogue_history}\n","\n","Speaking Character: {speaker}\n","\n","### Response:\n","\"\"\"\n","\n","    def format_character_info(self, attributes: Dict, relations: Optional[Dict] = None) -> str:\n","        \"\"\"Format character attributes and relationships into a structured string\"\"\"\n","        info_str = \"\"\n","\n","        # Format basic attributes\n","        for key, value in attributes.items():\n","            if value and value != \"None\":\n","                info_str += f\"- {key}: {value}\\n\"\n","\n","        # Add relationships if available\n","        if relations:\n","            info_str += \"\\nRelations with Harry:\\n\"\n","            for key, value in relations.items():\n","                if isinstance(value, (int, float)) and value != 0:\n","                    info_str += f\"- {key}: {value}\\n\"\n","\n","        return info_str\n","\n","    def format_dialogue_history(self, history: List[str]) -> str:\n","        \"\"\"Format dialogue history with clear speaker indicators\"\"\"\n","        return \"\\n\".join(history)\n","\n","    def generate_prompt(self,\n","                       scene: str,\n","                       character_attributes: Dict,\n","                       dialogue_history: List[str],\n","                       speaker: str,\n","                       relations: Optional[Dict] = None) -> str:\n","        \"\"\"Generate a complete prompt for dialogue generation\"\"\"\n","\n","        # Format character information\n","        character_info = self.format_character_info(character_attributes, relations)\n","\n","        # Format dialogue history\n","        formatted_history = self.format_dialogue_history(dialogue_history)\n","\n","        # Fill template\n","        prompt = self.base_prompt_template.format(\n","            scene=scene,\n","            character_info=character_info,\n","            dialogue_history=formatted_history,\n","            speaker=speaker\n","        )\n","\n","        return prompt\n","\n","    def tokenize_prompt(self, prompt: str) -> torch.Tensor:\n","        \"\"\"Tokenize the prompt for model input\"\"\"\n","        return self.tokenizer(\n","            prompt,\n","            truncation=True,\n","            max_length=512,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\"\n","        )\n","\n","    def generate_dialogue(self, model, prompt: str, max_length: int = 1000) -> str:\n","        \"\"\"Generate dialogue using the model\"\"\"\n","        inputs = self.tokenize_prompt(prompt)\n","\n","        outputs = model.generate(\n","            input_ids=inputs[\"input_ids\"],\n","            attention_mask=inputs[\"attention_mask\"],\n","            max_length=max_length,\n","            num_return_sequences=1,\n","            temperature=0.7,\n","            top_p=0.9,\n","            do_sample=True\n","        )\n","\n","        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"xxyH77uzST4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_generator = DialoguePromptGenerator(tokenizer)"],"metadata":{"id":"-bVdqUNWST7p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example data\n","scene = \"In the Great Hall during breakfast\"\n","character_attributes = {\n","    \"personality\": \"brave, loyal\",\n","    \"house\": \"Gryffindor\",\n","    \"year\": \"3rd year\"\n","}\n","relations = {\n","    \"friendship\": 0.9,\n","    \"trust\": 0.8\n","}\n","dialogue_history = [\n","    \"Harry: Did you see the notice about Hogsmeade?\",\n","    \"Ron: Yeah, can't wait to visit Honeydukes!\"\n","]\n","speaker = \"Hermione\"\n","\n","# Generate prompt\n","prompt = prompt_generator.generate_prompt(\n","    scene=scene,\n","    character_attributes=character_attributes,\n","    dialogue_history=dialogue_history,\n","    speaker=speaker,\n","    relations=relations\n",")\n","\n","FastLanguageModel.for_inference(model)\n","\n","# Generate dialogue\n","response = prompt_generator.generate_dialogue(model, prompt)"],"metadata":{"id":"l7v5Tpo6St2w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLvGSeyzSt42","executionInfo":{"status":"ok","timestamp":1733798304893,"user_tz":-540,"elapsed":274,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"12dbfe61-f869-4ec3-8498-bd99c2b12881"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Generate the next line of dialogue that matches the character's personality, relationships, and the scene context.\n","\n","### Input:\n","Scene Description:\n","In the Great Hall during breakfast\n","\n","Character Information:\n","- personality: brave, loyal\n","- house: Gryffindor\n","- year: 3rd year\n","\n","Relations with Harry:\n","- friendship: 0.9\n","- trust: 0.8\n","\n","\n","Previous Dialogue:\n","Harry: Did you see the notice about Hogsmeade?\n","Ron: Yeah, can't wait to visit Honeydukes!\n","\n","Speaking Character: Hermione\n","\n","### Response:\n","Hermione: I can't wait to visit Honeydukes!\n"]}]},{"cell_type":"code","source":["# For more consistent responses\n","prompt_generator.generate_dialogue(model, prompt, temperature=0.5, top_p=0.95)\n","\n","# For more creative responses\n","prompt_generator.generate_dialogue(model, prompt, temperature=0.8, top_p=0.9)"],"metadata":{"id":"zr3U92VaSt65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["character_attributes.update({\n","    \"mood\": \"excited\",\n","    \"current_goals\": \"preparing for exams\",\n","    \"recent_events\": \"just learned a new spell\"\n","})"],"metadata":{"id":"II14HHO-St8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4Bgf1mVZc8u4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YgA55ORJc8ww"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"r8rwXJL6SxWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/mlvlab/ProMetaR.git\n","%cd ProMetaR/\n","\n","!git clone https://github.com/KaiyangZhou/Dassl.pytorch.git\n","%cd Dassl.pytorch/\n","\n","# Install dependencies\n","!pip install -r requirements.txt\n","!cp -r dassl ../\n","# Install this library (no need to re-build if the source code is modified)\n","# !python setup.py develop\n","%cd ..\n","\n","!pip install -r requirements.txt\n","\n","%mkdir outputs\n","%mkdir data\n","\n","%cd data\n","%mkdir eurosat\n","!wget http://madm.dfki.de/files/sentinel/EuroSAT.zip -O EuroSAT.zip\n","\n","!unzip -o EuroSAT.zip -d eurosat/\n","%cd eurosat\n","!gdown 1Ip7yaCWFi0eaOFUGga0lUdVi_DDQth1o\n","\n","%cd ../../\n","\n","import os.path as osp\n","from collections import OrderedDict\n","import math\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.cuda.amp import GradScaler, autocast\n","from PIL import Image\n","import torchvision.transforms as transforms\n","import torch\n","from clip import clip\n","from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n","import time\n","from tqdm import tqdm\n","import datetime\n","import argparse\n","from dassl.utils import setup_logger, set_random_seed, collect_env_info\n","from dassl.config import get_cfg_default\n","from dassl.engine import build_trainer\n","from dassl.engine import TRAINER_REGISTRY, TrainerX\n","from dassl.metrics import compute_accuracy\n","from dassl.utils import load_pretrained_weights, load_checkpoint\n","from dassl.optim import build_optimizer, build_lr_scheduler\n","\n","# custom\n","import datasets.oxford_pets\n","import datasets.oxford_flowers\n","import datasets.fgvc_aircraft\n","import datasets.dtd\n","import datasets.eurosat\n","import datasets.stanford_cars\n","import datasets.food101\n","import datasets.sun397\n","import datasets.caltech101\n","import datasets.ucf101\n","import datasets.imagenet\n","import datasets.imagenet_sketch\n","import datasets.imagenetv2\n","import datasets.imagenet_a\n","import datasets.imagenet_r\n","\n","def print_args(args, cfg):\n","    print(\"***************\")\n","    print(\"** Arguments **\")\n","    print(\"***************\")\n","    optkeys = list(args.__dict__.keys())\n","    optkeys.sort()\n","    for key in optkeys:\n","        print(\"{}: {}\".format(key, args.__dict__[key]))\n","    print(\"************\")\n","    print(\"** Config **\")\n","    print(\"************\")\n","    print(cfg)\n","\n","def reset_cfg(cfg, args):\n","    if args.root:\n","        cfg.DATASET.ROOT = args.root\n","    if args.output_dir:\n","        cfg.OUTPUT_DIR = args.output_dir\n","    if args.seed:\n","        cfg.SEED = args.seed\n","    if args.trainer:\n","        cfg.TRAINER.NAME = args.trainer\n","    cfg.DATASET.NUM_SHOTS = 16\n","    cfg.DATASET.SUBSAMPLE_CLASSES = args.subsample_classes\n","    cfg.DATALOADER.TRAIN_X.BATCH_SIZE = args.train_batch_size\n","    cfg.OPTIM.MAX_EPOCH = args.epoch\n","\n","def extend_cfg(cfg):\n","    \"\"\"\n","    Add new config variables.\n","    \"\"\"\n","    from yacs.config import CfgNode as CN\n","    cfg.TRAINER.COOP = CN()\n","    cfg.TRAINER.COOP.N_CTX = 16  # number of context vectors\n","    cfg.TRAINER.COOP.CSC = False  # class-specific context\n","    cfg.TRAINER.COOP.CTX_INIT = \"\"  # initialization words\n","    cfg.TRAINER.COOP.PREC = \"fp16\"  # fp16, fp32, amp\n","    cfg.TRAINER.COOP.CLASS_TOKEN_POSITION = \"end\"  # 'middle' or 'end' or 'front'\n","    cfg.TRAINER.COCOOP = CN()\n","    cfg.TRAINER.COCOOP.N_CTX = 4  # number of context vectors\n","    cfg.TRAINER.COCOOP.CTX_INIT = \"a photo of a\"  # initialization words\n","    cfg.TRAINER.COCOOP.PREC = \"fp16\"  # fp16, fp32, amp\n","    cfg.TRAINER.PROMETAR = CN()\n","    cfg.TRAINER.PROMETAR.N_CTX_VISION = 4  # number of context vectors at the vision branch\n","    cfg.TRAINER.PROMETAR.N_CTX_TEXT = 4  # number of context vectors at the language branch\n","    cfg.TRAINER.PROMETAR.CTX_INIT = \"a photo of a\"  # initialization words\n","    cfg.TRAINER.PROMETAR.PREC = \"fp16\"  # fp16, fp32, amp\n","    cfg.TRAINER.PROMETAR.PROMPT_DEPTH_VISION = 9  # Max 12, minimum 0, for 0 it will be using shallow IVLP prompting (J=1)\n","    cfg.TRAINER.PROMETAR.PROMPT_DEPTH_TEXT = 9  # Max 12, minimum 0, for 0 it will be using shallow IVLP prompting (J=1)\n","    cfg.DATASET.SUBSAMPLE_CLASSES = \"all\"  # all, base or new\n","    cfg.TRAINER.PROMETAR.ADAPT_LR = 0.0005\n","    cfg.TRAINER.PROMETAR.LR_RATIO = 0.0005\n","    cfg.TRAINER.PROMETAR.FAST_ADAPTATION = False\n","    cfg.TRAINER.PROMETAR.MIXUP_ALPHA = 0.5\n","    cfg.TRAINER.PROMETAR.MIXUP_BETA = 0.5\n","    cfg.TRAINER.PROMETAR.DIM_RATE=8\n","    cfg.OPTIM_VNET = CN()\n","    cfg.OPTIM_VNET.NAME = \"adam\"\n","    cfg.OPTIM_VNET.LR = 0.0003\n","    cfg.OPTIM_VNET.WEIGHT_DECAY = 5e-4\n","    cfg.OPTIM_VNET.MOMENTUM = 0.9\n","    cfg.OPTIM_VNET.SGD_DAMPNING = 0\n","    cfg.OPTIM_VNET.SGD_NESTEROV = False\n","    cfg.OPTIM_VNET.RMSPROP_ALPHA = 0.99\n","    cfg.OPTIM_VNET.ADAM_BETA1 = 0.9\n","    cfg.OPTIM_VNET.ADAM_BETA2 = 0.999\n","    cfg.OPTIM_VNET.STAGED_LR = False\n","    cfg.OPTIM_VNET.NEW_LAYERS = ()\n","    cfg.OPTIM_VNET.BASE_LR_MULT = 0.1\n","    # Learning rate scheduler\n","    cfg.OPTIM_VNET.LR_SCHEDULER = \"single_step\"\n","    # -1 or 0 means the stepsize is equal to max_epoch\n","    cfg.OPTIM_VNET.STEPSIZE = (-1, )\n","    cfg.OPTIM_VNET.GAMMA = 0.1\n","    cfg.OPTIM_VNET.MAX_EPOCH = 10\n","    # Set WARMUP_EPOCH larger than 0 to activate warmup training\n","    cfg.OPTIM_VNET.WARMUP_EPOCH = -1\n","    # Either linear or constant\n","    cfg.OPTIM_VNET.WARMUP_TYPE = \"linear\"\n","    # Constant learning rate when type=constant\n","    cfg.OPTIM_VNET.WARMUP_CONS_LR = 1e-5\n","    # Minimum learning rate when type=linear\n","    cfg.OPTIM_VNET.WARMUP_MIN_LR = 1e-5\n","    # Recount epoch for the next scheduler (last_epoch=-1)\n","    # Otherwise last_epoch=warmup_epoch\n","    cfg.OPTIM_VNET.WARMUP_RECOUNT = True\n","\n","def setup_cfg(args):\n","    cfg = get_cfg_default()\n","    extend_cfg(cfg)\n","    # 1. From the dataset config file\n","    if args.dataset_config_file:\n","        cfg.merge_from_file(args.dataset_config_file)\n","    # 2. From the method config file\n","    if args.config_file:\n","        cfg.merge_from_file(args.config_file)\n","    # 3. From input arguments\n","    reset_cfg(cfg, args)\n","    cfg.freeze()\n","    return cfg\n","\n","_tokenizer = _Tokenizer()\n","\n","def load_clip_to_cpu(cfg): # Load CLIP\n","    backbone_name = cfg.MODEL.BACKBONE.NAME\n","    url = clip._MODELS[backbone_name]\n","    model_path = clip._download(url)\n","\n","    try:\n","        # loading JIT archive\n","        model = torch.jit.load(model_path, map_location=\"cpu\").eval()\n","        state_dict = None\n","\n","    except RuntimeError:\n","        state_dict = torch.load(model_path, map_location=\"cpu\")\n","\n","    if cfg.TRAINER.NAME == \"\":\n","      design_trainer = \"CoOp\"\n","    else:\n","      design_trainer = cfg.TRAINER.NAME\n","    design_details = {\"trainer\": design_trainer,\n","                      \"vision_depth\": 0,\n","                      \"language_depth\": 0, \"vision_ctx\": 0,\n","                      \"language_ctx\": 0}\n","    model = clip.build_model(state_dict or model.state_dict(), design_details)\n","\n","    return model\n","\n","from dassl.config import get_cfg_default\n","cfg = get_cfg_default()\n","cfg.MODEL.BACKBONE.NAME = \"ViT-B/16\" # Set the vision encoder backbone of CLIP to ViT.\n","clip_model = load_clip_to_cpu(cfg)\n","\n","\n","\n","class TextEncoder(nn.Module):\n","    def __init__(self, clip_model): # 초기화 하는 함수\n","        super().__init__()\n","        self.transformer = clip_model.transformer\n","        self.positional_embedding = clip_model.positional_embedding\n","        self.ln_final = clip_model.ln_final\n","        self.text_projection = clip_model.text_projection\n","        self.dtype = clip_model.dtype\n","\n","    def forward(self, prompts, tokenized_prompts): # 모델 호출\n","        x = prompts + self.positional_embedding.type(self.dtype)\n","        x = x.permute(1, 0, 2)  # NLD -> LND\n","        x = self.transformer(x)\n","        x = x.permute(1, 0, 2)  # LND -> NLD\n","        x = self.ln_final(x).type(self.dtype)\n","\n","        # x.shape = [batch_size, n_ctx, transformer.width]\n","        # take features from the eot embedding (eot_token is the highest number in each sequence)\n","        x = x[torch.arange(x.shape[0]), tokenized_prompts.argmax(dim=-1)] @ self.text_projection\n","\n","        return x\n","\n","\n","@TRAINER_REGISTRY.register(force=True)\n","class CoCoOp(TrainerX):\n","    def check_cfg(self, cfg):\n","        assert cfg.TRAINER.COCOOP.PREC in [\"fp16\", \"fp32\", \"amp\"]\n","\n","    def build_model(self):\n","        cfg = self.cfg\n","        classnames = self.dm.dataset.classnames\n","        print(f\"Loading CLIP (backbone: {cfg.MODEL.BACKBONE.NAME})\")\n","        clip_model = load_clip_to_cpu(cfg)\n","\n","        if cfg.TRAINER.COCOOP.PREC == \"fp32\" or cfg.TRAINER.COCOOP.PREC == \"amp\":\n","            # CLIP's default precision is fp16\n","            clip_model.float()\n","\n","        print(\"Building custom CLIP\")\n","        self.model = CoCoOpCustomCLIP(cfg, classnames, clip_model)\n","\n","        print(\"Turning off gradients in both the image and the text encoder\")\n","        name_to_update = \"prompt_learner\"\n","\n","        for name, param in self.model.named_parameters():\n","            if name_to_update not in name:\n","                param.requires_grad_(False)\n","\n","        # Double check\n","        enabled = set()\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad:\n","                enabled.add(name)\n","        print(f\"Parameters to be updated: {enabled}\")\n","\n","        if cfg.MODEL.INIT_WEIGHTS:\n","            load_pretrained_weights(self.model.prompt_learner, cfg.MODEL.INIT_WEIGHTS)\n","\n","        self.model.to(self.device)\n","        # NOTE: only give prompt_learner to the optimizer\n","        self.optim = build_optimizer(self.model.prompt_learner, cfg.OPTIM)\n","        self.sched = build_lr_scheduler(self.optim, cfg.OPTIM)\n","        self.register_model(\"prompt_learner\", self.model.prompt_learner, self.optim, self.sched)\n","\n","        self.scaler = GradScaler() if cfg.TRAINER.COCOOP.PREC == \"amp\" else None\n","\n","        # Note that multi-gpu training could be slow because CLIP's size is\n","        # big, which slows down the copy operation in DataParallel\n","        device_count = torch.cuda.device_count()\n","        if device_count > 1:\n","            print(f\"Multiple GPUs detected (n_gpus={device_count}), use all of them!\")\n","            self.model = nn.DataParallel(self.model)\n","\n","    def before_train(self):\n","        directory = self.cfg.OUTPUT_DIR\n","        if self.cfg.RESUME:\n","            directory = self.cfg.RESUME\n","        self.start_epoch = self.resume_model_if_exist(directory)\n","\n","        # Remember the starting time (for computing the elapsed time)\n","        self.time_start = time.time()\n","\n","\n","    def forward_backward(self, batch):\n","        image, label = self.parse_batch_train(batch)\n","\n","        model = self.model\n","        optim = self.optim\n","        scaler = self.scaler\n","\n","        prec = self.cfg.TRAINER.COCOOP.PREC\n","        loss = model(image, label) # Input image 모델 통과\n","        optim.zero_grad()\n","        loss.backward() # Backward (역전파)\n","        optim.step() # 모델 parameter update\n","\n","        loss_summary = {\"loss\": loss.item()}\n","\n","        if (self.batch_idx + 1) == self.num_batches:\n","            self.update_lr()\n","\n","        return loss_summary\n","\n","    def parse_batch_train(self, batch):\n","        input = batch[\"img\"]\n","        label = batch[\"label\"]\n","        input = input.to(self.device)\n","        label = label.to(self.device)\n","        return input, label\n","\n","    def load_model(self, directory, epoch=None):\n","        if not directory:\n","            print(\"Note that load_model() is skipped as no pretrained model is given\")\n","            return\n","\n","        names = self.get_model_names()\n","\n","        # By default, the best model is loaded\n","        model_file = \"model-best.pth.tar\"\n","\n","        if epoch is not None:\n","            model_file = \"model.pth.tar-\" + str(epoch)\n","\n","        for name in names:\n","            model_path = osp.join(directory, name, model_file)\n","\n","            if not osp.exists(model_path):\n","                raise FileNotFoundError('Model not found at \"{}\"'.format(model_path))\n","\n","            checkpoint = load_checkpoint(model_path)\n","            state_dict = checkpoint[\"state_dict\"]\n","            epoch = checkpoint[\"epoch\"]\n","\n","            # Ignore fixed token vectors\n","            if \"token_prefix\" in state_dict:\n","                del state_dict[\"token_prefix\"]\n","\n","            if \"token_suffix\" in state_dict:\n","                del state_dict[\"token_suffix\"]\n","\n","            print(\"Loading weights to {} \" 'from \"{}\" (epoch = {})'.format(name, model_path, epoch))\n","            # set strict=False\n","            self._models[name].load_state_dict(state_dict, strict=False)\n","\n","    def after_train(self):\n","      print(\"Finish training\")\n","\n","      do_test = not self.cfg.TEST.NO_TEST\n","      if do_test:\n","          if self.cfg.TEST.FINAL_MODEL == \"best_val\":\n","              print(\"Deploy the model with the best val performance\")\n","              self.load_model(self.output_dir)\n","          else:\n","              print(\"Deploy the last-epoch model\")\n","          acc = self.test()\n","\n","      # Show elapsed time\n","      elapsed = round(time.time() - self.time_start)\n","      elapsed = str(datetime.timedelta(seconds=elapsed))\n","      print(f\"Elapsed: {elapsed}\")\n","\n","      # Close writer\n","      self.close_writer()\n","      return acc\n","\n","    def train(self):\n","        \"\"\"Generic training loops.\"\"\"\n","        self.before_train()\n","        for self.epoch in range(self.start_epoch, self.max_epoch):\n","            self.before_epoch()\n","            self.run_epoch()\n","            self.after_epoch()\n","        acc = self.after_train()\n","        return acc\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument(\"--root\", type=str, default=\"data/\", help=\"path to dataset\")\n","parser.add_argument(\"--output-dir\", type=str, default=\"outputs/cocoop3\", help=\"output directory\")\n","parser.add_argument(\n","    \"--seed\", type=int, default=1, help=\"only positive value enables a fixed seed\"\n",")\n","parser.add_argument(\n","    \"--config-file\", type=str, default=\"configs/trainers/ProMetaR/vit_b16_c2_ep10_batch4_4+4ctx.yaml\", help=\"path to config file\"\n",")\n","parser.add_argument(\n","    \"--dataset-config-file\",\n","    type=str,\n","    default=\"configs/datasets/eurosat.yaml\",\n","    help=\"path to config file for dataset setup\",\n",")\n","parser.add_argument(\"--trainer\", type=str, default=\"CoOp\", help=\"name of trainer\")\n","parser.add_argument(\"--eval-only\", action=\"store_true\", help=\"evaluation only\")\n","parser.add_argument(\n","    \"--model-dir\",\n","    type=str,\n","    default=\"\",\n","    help=\"load model from this directory for eval-only mode\",\n",")\n","parser.add_argument(\"--train-batch-size\", type=int, default=4)\n","parser.add_argument(\"--epoch\", type=int, default=10)\n","parser.add_argument(\"--subsample-classes\", type=str, default=\"base\")\n","parser.add_argument(\n","    \"--load-epoch\", type=int, default=0, help=\"load model weights at this epoch for evaluation\"\n",")\n","args = parser.parse_args([])\n","\n","def main(args):\n","    cfg = setup_cfg(args)\n","    if cfg.SEED >= 0:\n","        set_random_seed(cfg.SEED)\n","\n","    if torch.cuda.is_available() and cfg.USE_CUDA:\n","        torch.backends.cudnn.benchmark = True\n","\n","    trainer = build_trainer(cfg)\n","    if args.eval_only:\n","        trainer.load_model(args.model_dir, epoch=args.load_epoch)\n","        acc = trainer.test()\n","        return acc\n","\n","    acc = trainer.train()\n","    return acc"],"metadata":{"id":"Dj8mLRimgaha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9IRNAMNAgbG-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from trl import SFTTrainer\n","import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","\n","\n","class DialoguePromptLearner(nn.Module):\n","    def __init__(self, model, tokenizer, cfg):\n","        super().__init__()\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","        # Configuration for prompt learning\n","        self.n_ctx = cfg.get('n_ctx', 8)  # Number of context tokens to learn\n","        self.ctx_init = cfg.get('ctx_init', '')  # Optional initialization text\n","        self.ctx_dim = model.config.hidden_size\n","\n","        # Initialize context vectors\n","        if self.ctx_init:\n","            # Initialize with given words\n","            ctx_init = self.ctx_init.replace('_', ' ')\n","            n_ctx = len(ctx_init.split())\n","            prompt_tokens = tokenizer(ctx_init, return_tensors='pt')\n","            with torch.no_grad():\n","                embedding = model.get_input_embeddings()(prompt_tokens['input_ids'][0, :n_ctx])\n","            self.ctx = nn.Parameter(embedding)\n","        else:\n","            # Random initialization\n","            self.ctx = nn.Parameter(torch.randn(self.n_ctx, self.ctx_dim))\n","\n","        # Meta network for instance-specific prompts\n","        self.meta_net = nn.Sequential(OrderedDict([\n","            (\"linear1\", nn.Linear(self.ctx_dim, self.ctx_dim // 16)),\n","            (\"relu\", nn.ReLU(inplace=True)),\n","            (\"linear2\", nn.Linear(self.ctx_dim // 16, self.ctx_dim))\n","        ]))\n","\n","    def forward(self, inputs):\n","        batch_size = inputs['input_ids'].size(0)\n","\n","        # Get scene embeddings (using [CLS] token output)\n","        with torch.no_grad():\n","            scene_features = self.model.get_encoder()(\n","                input_ids=inputs['input_ids'],\n","                attention_mask=inputs['attention_mask']\n","            ).last_hidden_state[:, 0]  # Use [CLS] token\n","\n","        # Generate instance-specific bias\n","        bias = self.meta_net(scene_features)  # (batch, ctx_dim)\n","        bias = bias.unsqueeze(1)  # (batch, 1, ctx_dim)\n","\n","        # Apply bias to context tokens\n","        ctx = self.ctx.unsqueeze(0).expand(batch_size, -1, -1)  # (batch, n_ctx, ctx_dim)\n","        ctx_shifted = ctx + bias  # (batch, n_ctx, ctx_dim)\n","\n","        # Prepare prompted input\n","        prompted_embeddings = self.model.get_input_embeddings()(inputs['input_ids'])\n","\n","        # Insert learned context tokens after instruction/before input\n","        instruction_end = (inputs['input_ids'] == self.tokenizer.encode(\"### Input:\", add_special_tokens=False)[0]).nonzero()[:, 1]\n","        for i in range(batch_size):\n","            idx = instruction_end[i]\n","            prompted_embeddings[i] = torch.cat([\n","                prompted_embeddings[i, :idx],\n","                ctx_shifted[i],\n","                prompted_embeddings[i, idx:]\n","            ], dim=0)\n","\n","        return prompted_embeddings\n","\n","class CoCoOpSFTTrainer(SFTTrainer):\n","    def __init__(self, *args, prompt_tuning_config=None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.prompt_learner = DialoguePromptLearner(\n","            self.model,\n","            self.tokenizer,\n","            prompt_tuning_config or {}\n","        )\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        # Get prompted embeddings\n","        prompted_embeddings = self.prompt_learner(inputs)\n","\n","        # Replace the standard embeddings with prompted ones\n","        original_forward = self.model.forward\n","\n","        def prompted_forward(*args, **kwargs):\n","            kwargs['inputs_embeds'] = prompted_embeddings\n","            kwargs['input_ids'] = None\n","            return original_forward(*args, **kwargs)\n","\n","        self.model.forward = prompted_forward\n","\n","        # Compute loss using parent class\n","        loss = super().compute_loss(model, inputs, return_outputs)\n","\n","        # Restore original forward\n","        self.model.forward = original_forward\n","\n","        return loss"],"metadata":{"id":"Ak1nHEYlgFIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_dialogue_with_prompts(instruction, scene, characters):\n","    input_text = f\"Scene:\\n{scene}\\n\\nCharacter Information:\\n{characters}\"\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","    # Get prompted embeddings\n","    prompted_embeddings = trainer.prompt_learner(inputs)\n","\n","    # Generate with prompted embeddings\n","    outputs = model.generate(\n","        inputs_embeds=prompted_embeddings,\n","        **generation_params\n","    )\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)"],"metadata":{"id":"_SJHkD1TgQtB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","from transformers import TextStreamer\n","\n","class DialoguePromptLearner(nn.Module):\n","    def __init__(self, model, tokenizer):\n","        super().__init__()\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","        # Configuration\n","        self.n_ctx = 8  # 학습할 컨텍스트 토큰 수\n","        self.ctx_dim = model.config.hidden_size\n","\n","        # 컨텍스트 벡터 초기화 (랜덤)\n","        self.ctx = nn.Parameter(torch.randn(self.n_ctx, self.ctx_dim))\n","\n","        # 메타 네트워크 정의\n","        self.meta_net = nn.Sequential(OrderedDict([\n","            (\"linear1\", nn.Linear(self.ctx_dim, self.ctx_dim // 16)),\n","            (\"relu\", nn.ReLU(inplace=True)),\n","            (\"linear2\", nn.Linear(self.ctx_dim // 16, self.ctx_dim))\n","        ])).to(model.device)\n","\n","    def forward(self, inputs):\n","        batch_size = inputs['input_ids'].size(0)\n","\n","        # 씬 임베딩 추출 ([CLS] 토큰 출력 사용)\n","        with torch.no_grad():\n","            outputs = self.model.get_encoder()(\n","                input_ids=inputs['input_ids'].to(self.model.device),\n","                attention_mask=inputs['attention_mask'].to(self.model.device)\n","            )\n","            scene_features = outputs.last_hidden_state[:, 0]\n","\n","        # 인스턴스별 바이어스 생성\n","        bias = self.meta_net(scene_features)\n","        bias = bias.unsqueeze(1)\n","\n","        # 컨텍스트 토큰에 바이어스 적용\n","        ctx = self.ctx.unsqueeze(0).expand(batch_size, -1, -1)\n","        ctx_shifted = ctx + bias\n","\n","        # 프롬프트된 입력 준비\n","        prompted_embeddings = self.model.get_input_embeddings()(inputs['input_ids'].to(self.model.device))\n","\n","        # instruction과 input 사이에 학습된 컨텍스트 토큰 삽입\n","        instruction_marker = \"### Input:\"\n","        marker_ids = self.tokenizer.encode(instruction_marker, add_special_tokens=False)[0]\n","        instruction_end = (inputs['input_ids'] == marker_ids).nonzero()[:, 1]\n","\n","        new_embeddings = []\n","        for i in range(batch_size):\n","            idx = instruction_end[i]\n","            new_emb = torch.cat([\n","                prompted_embeddings[i, :idx],\n","                ctx_shifted[i],\n","                prompted_embeddings[i, idx:]\n","            ], dim=0)\n","            new_embeddings.append(new_emb)\n","\n","        return torch.stack(new_embeddings)\n","\n","# CoCoOp을 사용한 인퍼런스 함수\n","def generate_dialogue_with_cocoop(model, tokenizer, instruction, input_text, prompt_learner):\n","    # 입력 텍스트 준비\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    )\n","\n","    # 프롬프트된 임베딩 생성\n","    prompted_embeddings = prompt_learner(inputs)\n","\n","    # 텍스트 생성을 위한 streamer 설정\n","    text_streamer = TextStreamer(tokenizer)\n","\n","    # 생성 파라미터\n","    generation_params = {\n","        \"max_new_tokens\": 256,\n","        \"temperature\": 0.2,\n","        \"top_p\": 0.2,\n","        \"do_sample\": True,\n","        \"streamer\": text_streamer,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","    }\n","\n","    # 텍스트 생성\n","    outputs = model.generate(\n","        inputs_embeds=prompted_embeddings,\n","        **generation_params\n","    )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# 프롬프트 러너 초기화 및 인퍼런스 실행\n","prompt_learner = DialoguePromptLearner(model, tokenizer)\n","\n","# 테스트 예시로 인퍼런스 실행\n","def test_cocoop_inference(test_n):\n","    print(\"Generating dialogue with CoCoOp...\")\n","\n","    test_instruction = train_json[test_n]['instruction']\n","    test_input = train_json[test_n]['input']\n","\n","    # CoCoOp을 사용한 대화 생성\n","    generated_text = generate_dialogue_with_cocoop(\n","        model,\n","        tokenizer,\n","        test_instruction,\n","        test_input,\n","        prompt_learner\n","    )\n","\n","    print(\"\\n=== Generated Response ===\")\n","    print(generated_text)\n","\n","    print(\"\\n=== Correct Response ===\")\n","    print(train_json[test_n]['output'], \"<|end_of_text|>\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"qbLARvoqhE7w","executionInfo":{"status":"error","timestamp":1733799853293,"user_tz":-540,"elapsed":392,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"217d4342-1b6e-4a26-9067-8342c9738a08"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'DialogueCoCoOpModel' object has no attribute 'config'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-f707b54299ee>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# 프롬프트 러너 초기화 및 인퍼런스 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mprompt_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDialoguePromptLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# 테스트 예시로 인퍼런스 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-47-f707b54299ee>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m  \u001b[0;31m# 학습할 컨텍스트 토큰 수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# 컨텍스트 벡터 초기화 (랜덤)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'DialogueCoCoOpModel' object has no attribute 'config'"]}]},{"cell_type":"code","source":["# 특정 테스트 케이스로 실행\n","test_cocoop_inference(test_n=0)  # 또는 다른 인덱스"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"-KzWVF9zhjx9","executionInfo":{"status":"error","timestamp":1733799866673,"user_tz":-540,"elapsed":297,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"b1f9377d-4707-4062-b6d0-b462e3a7fd45"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'test_cocoop_inference' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-df30d73526b1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 특정 테스트 케이스로 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_cocoop_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 또는 다른 인덱스\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'test_cocoop_inference' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cFdn6MWKh2Uv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nyijEPT5il_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XylMv4RcimEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","from transformers import TextStreamer\n","\n","class DialoguePromptLearner(nn.Module):\n","    def __init__(self, model, tokenizer):\n","        super().__init__()\n","        self.base_model = model  # FastLanguageModel 인스턴스\n","        self.tokenizer = tokenizer\n","\n","        # FastLanguageModel의 구조에 맞춰 설정\n","        self.n_ctx = 8  # 학습할 컨텍스트 토큰 수\n","        # model.config.hidden_size로 직접 접근\n","        self.ctx_dim = model.config.hidden_size\n","        self.device = next(model.parameters()).device\n","\n","        # 컨텍스트 벡터 초기화 (랜덤)\n","        self.ctx = nn.Parameter(torch.randn(self.n_ctx, self.ctx_dim, device=self.device))\n","\n","        # 메타 네트워크 정의\n","        self.meta_net = nn.Sequential(OrderedDict([\n","            (\"linear1\", nn.Linear(self.ctx_dim, self.ctx_dim // 16)),\n","            (\"relu\", nn.ReLU(inplace=True)),\n","            (\"linear2\", nn.Linear(self.ctx_dim // 16, self.ctx_dim))\n","        ])).to(self.device)\n","\n","    def forward(self, inputs):\n","        batch_size = inputs['input_ids'].size(0)\n","\n","        # 씬 임베딩 추출\n","        with torch.no_grad():\n","            input_ids = inputs['input_ids'].to(self.device)\n","            attention_mask = inputs['attention_mask'].to(self.device)\n","\n","            # FastLanguageModel의 임베딩 레이어 직접 접근\n","            embeddings = self.base_model.embed_tokens(input_ids)\n","            scene_features = embeddings[:, 0]\n","\n","        # 인스턴스별 바이어스 생성\n","        bias = self.meta_net(scene_features)\n","        bias = bias.unsqueeze(1)\n","\n","        # 컨텍스트 토큰에 바이어스 적용\n","        ctx = self.ctx.unsqueeze(0).expand(batch_size, -1, -1)\n","        ctx_shifted = ctx + bias\n","\n","        # 프롬프트된 입력 준비\n","        prompted_embeddings = self.base_model.embed_tokens(input_ids)\n","\n","        # instruction과 input 사이에 학습된 컨텍스트 토큰 삽입\n","        instruction_marker = \"### Input:\"\n","        marker_ids = self.tokenizer.encode(instruction_marker, add_special_tokens=False)[0]\n","        instruction_end = (input_ids == marker_ids).nonzero()[:, 1]\n","\n","        new_embeddings = []\n","        for i in range(batch_size):\n","            idx = instruction_end[i]\n","            new_emb = torch.cat([\n","                prompted_embeddings[i, :idx],\n","                ctx_shifted[i],\n","                prompted_embeddings[i, idx:]\n","            ], dim=0)\n","            new_embeddings.append(new_emb)\n","\n","        return torch.stack(new_embeddings)\n","\n","def generate_dialogue_with_cocoop(model, tokenizer, instruction, input_text, prompt_learner):\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    )\n","\n","    # 프롬프트된 임베딩 생성\n","    prompted_embeddings = prompt_learner(inputs)\n","\n","    # 텍스트 생성을 위한 streamer 설정\n","    text_streamer = TextStreamer(tokenizer)\n","\n","    # 생성 파라미터\n","    generation_params = {\n","        \"max_new_tokens\": 256,\n","        \"temperature\": 0.2,\n","        \"top_p\": 0.2,\n","        \"do_sample\": True,\n","        \"streamer\": text_streamer,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","    }\n","\n","    # FastLanguageModel generate 호출\n","    outputs = model.generate(\n","        inputs_embeds=prompted_embeddings,\n","        attention_mask=torch.ones_like(inputs['input_ids']),\n","        **generation_params\n","    )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# 테스트 함수\n","def test_cocoop_inference(model, tokenizer, train_json, test_n=0):\n","    print(\"Initializing CoCoOp prompt learner...\")\n","    prompt_learner = DialoguePromptLearner(model, tokenizer)\n","\n","    print(\"\\nGenerating dialogue with CoCoOp...\")\n","    test_instruction = train_json[test_n]['instruction']\n","    test_input = train_json[test_n]['input']\n","\n","    generated_text = generate_dialogue_with_cocoop(\n","        model,\n","        tokenizer,\n","        test_instruction,\n","        test_input,\n","        prompt_learner\n","    )\n","\n","    print(\"\\n=== Generated Response ===\")\n","    print(generated_text)\n","\n","    print(\"\\n=== Correct Response ===\")\n","    print(train_json[test_n]['output'], \"<|end_of_text|>\")"],"metadata":{"id":"fj3wzdKAimL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FastLanguageModel이 이미 준비되어 있다고 가정\n","test_cocoop_inference(model, tokenizer, train_data, test_n=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"OK7p-dlfiqqJ","executionInfo":{"status":"error","timestamp":1733800331502,"user_tz":-540,"elapsed":299,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"ed5cd856-971d-44d8-c7dc-e00a60baa195"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing CoCoOp prompt learner...\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'DialogueCoCoOpModel' object has no attribute 'config'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-3d1bab104f2e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# FastLanguageModel이 이미 준비되어 있다고 가정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_cocoop_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-59-34bbaecbff3f>\u001b[0m in \u001b[0;36mtest_cocoop_inference\u001b[0;34m(model, tokenizer, train_json, test_n)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_cocoop_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing CoCoOp prompt learner...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mprompt_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDialoguePromptLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGenerating dialogue with CoCoOp...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-59-34bbaecbff3f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m  \u001b[0;31m# 학습할 컨텍스트 토큰 수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# model.config.hidden_size로 직접 접근\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'DialogueCoCoOpModel' object has no attribute 'config'"]}]},{"cell_type":"code","source":["print(\"Model type:\", type(model))\n","print(\"Available attributes:\", [attr for attr in dir(model) if not attr.startswith('_')])\n","\n","# 모델의 파라미터 구조도 확인\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name}, Shape: {param.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASbbiEaPjfFq","executionInfo":{"status":"ok","timestamp":1733800403349,"user_tz":-540,"elapsed":345,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"9e8e6490-cea7-47aa-9a34-57ba38b1c02d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model type: <class '__main__.DialogueCoCoOpModel'>\n","Available attributes: ['T_destination', 'add_module', 'apply', 'base_model', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'context_encoder', 'cpu', 'cuda', 'dialogue_encoder', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'half', 'ipu', 'load_state_dict', 'modules', 'mtia', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'prompt_learner', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prefix_tokens, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.meta_lr, Shape: torch.Size([1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.embed_tokens.weight, Shape: torch.Size([128256, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.0.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.1.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.2.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.3.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.4.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.5.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.6.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.7.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.8.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.9.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.10.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.11.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.12.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.13.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.14.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.15.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.16.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.17.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.18.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.19.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.20.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.21.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.22.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.23.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.24.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.25.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.26.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.27.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.28.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.29.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.30.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight, Shape: torch.Size([2097152, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight, Shape: torch.Size([1024, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight, Shape: torch.Size([8388608, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.gate_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.up_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight, Shape: torch.Size([16, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight, Shape: torch.Size([14336, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.down_proj.base_layer.weight, Shape: torch.Size([29360128, 1])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([16, 14336])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([4096, 16])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.input_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.layers.31.post_attention_layernorm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.model.norm.weight, Shape: torch.Size([4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.model.lm_head.weight, Shape: torch.Size([128256, 4096])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_attention.in_proj_weight, Shape: torch.Size([2304, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_attention.in_proj_bias, Shape: torch.Size([2304])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_attention.out_proj.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_attention.out_proj.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.1.weight, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.1.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.3.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.3.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.4.weight, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.scene_encoder.4.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.1.weight, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.1.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.3.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.3.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.4.weight, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.attribute_encoder.4.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.0.weight, Shape: torch.Size([1536, 2304])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.0.bias, Shape: torch.Size([1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.1.weight, Shape: torch.Size([1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.1.bias, Shape: torch.Size([1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.3.weight, Shape: torch.Size([7680, 1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_generator.3.bias, Shape: torch.Size([7680])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: base_model.prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: base_model.prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: base_model.prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: base_model.prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: base_model.context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: base_model.context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: base_model.dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: base_model.dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: base_model.dialogue_encoder.2.bias, Shape: torch.Size([768])\n","Layer: prompt_learner.ctx, Shape: torch.Size([10, 768])\n","Layer: prompt_learner.scene_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: prompt_learner.scene_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: prompt_learner.scene_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: prompt_learner.scene_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: prompt_learner.dialogue_meta_net.0.weight, Shape: torch.Size([192, 768])\n","Layer: prompt_learner.dialogue_meta_net.0.bias, Shape: torch.Size([192])\n","Layer: prompt_learner.dialogue_meta_net.2.weight, Shape: torch.Size([768, 192])\n","Layer: prompt_learner.dialogue_meta_net.2.bias, Shape: torch.Size([768])\n","Layer: context_encoder.0.weight, Shape: torch.Size([768, 1536])\n","Layer: context_encoder.0.bias, Shape: torch.Size([768])\n","Layer: context_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: context_encoder.2.bias, Shape: torch.Size([768])\n","Layer: dialogue_encoder.0.weight, Shape: torch.Size([768, 768])\n","Layer: dialogue_encoder.0.bias, Shape: torch.Size([768])\n","Layer: dialogue_encoder.2.weight, Shape: torch.Size([768, 768])\n","Layer: dialogue_encoder.2.bias, Shape: torch.Size([768])\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","from transformers import TextStreamer\n","\n","class DialoguePromptLearner(nn.Module):\n","    def __init__(self, model, tokenizer):\n","        super().__init__()\n","        self.model = model\n","        self.tokenizer = tokenizer\n","\n","        # 실제 모델의 hidden size 가져오기\n","        self.ctx_dim = 4096  # 모델 출력에서 확인된 크기\n","        self.n_ctx = 8  # 학습할 컨텍스트 토큰 수\n","\n","        # device 가져오기\n","        self.device = next(model.parameters()).device\n","\n","        # 컨텍스트 벡터 초기화 (랜덤)\n","        self.ctx = nn.Parameter(torch.randn(self.n_ctx, self.ctx_dim, device=self.device))\n","\n","        # 메타 네트워크 정의\n","        self.meta_net = nn.Sequential(OrderedDict([\n","            (\"linear1\", nn.Linear(self.ctx_dim, self.ctx_dim // 16)),\n","            (\"relu\", nn.ReLU(inplace=True)),\n","            (\"linear2\", nn.Linear(self.ctx_dim // 16, self.ctx_dim))\n","        ])).to(self.device)\n","\n","    def forward(self, inputs):\n","        batch_size = inputs['input_ids'].size(0)\n","\n","        # 입력을 장치로 이동\n","        input_ids = inputs['input_ids'].to(self.device)\n","        attention_mask = inputs['attention_mask'].to(self.device)\n","\n","        # 기본 모델에서 임베딩 추출\n","        # base_model 경로 단순화 및 device 확인\n","        base_model = self.model.base_model\n","        while hasattr(base_model, 'base_model'):\n","            base_model = base_model.base_model\n","        base_model = base_model.model\n","\n","        with torch.no_grad():\n","            # 모델의 임베딩 레이어를 사용하여 입력 임베딩\n","            embeddings = base_model.model.embed_tokens(input_ids)\n","            scene_features = embeddings[:, 0]  # [CLS] 토큰 임베딩 사용\n","\n","        # 컨텍스트 조정을 위한 메타 네트워크\n","        bias = self.meta_net(scene_features)  # (batch, ctx_dim)\n","        bias = bias.unsqueeze(1)  # (batch, 1, ctx_dim)\n","\n","        # 컨텍스트 토큰 확장 및 바이어스 적용\n","        ctx = self.ctx.unsqueeze(0).expand(batch_size, -1, -1)  # (batch, n_ctx, ctx_dim)\n","        ctx_shifted = ctx + bias  # (batch, n_ctx, ctx_dim)\n","\n","        # 프롬프트된 임베딩 준비\n","        prompted_embeddings = base_model.model.embed_tokens(input_ids)\n","\n","        # instruction과 input 사이에 학습된 컨텍스트 토큰 삽입\n","        instruction_marker = \"### Input:\"\n","        marker_ids = torch.tensor(self.tokenizer.encode(instruction_marker, add_special_tokens=False)[0]).to(self.device)\n","        instruction_end = (input_ids == marker_ids).nonzero()[:, 1]\n","\n","        new_embeddings = []\n","        for i in range(batch_size):\n","            idx = instruction_end[i]\n","            new_emb = torch.cat([\n","                prompted_embeddings[i, :idx],\n","                ctx_shifted[i],\n","                prompted_embeddings[i, idx:]\n","            ], dim=0)\n","            new_embeddings.append(new_emb)\n","\n","        return torch.stack(new_embeddings)\n","\n","def generate_dialogue_with_cocoop(model, tokenizer, instruction, input_text, prompt_learner):\n","    # 입력 텍스트 준비\n","    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","    # 입력을 GPU로 이동\n","    inputs = tokenizer(\n","        [alpaca_prompt.format(instruction, input_text, \"\")],\n","        return_tensors=\"pt\"\n","    ).to(prompt_learner.device)\n","\n","    # 프롬프트된 임베딩 생성\n","    prompted_embeddings = prompt_learner(inputs)\n","\n","    # 텍스트 생성을 위한 streamer 설정\n","    text_streamer = TextStreamer(tokenizer)\n","\n","    # 생성 파라미터\n","    generation_params = {\n","        \"max_new_tokens\": 256,\n","        \"temperature\": 0.2,\n","        \"top_p\": 0.2,\n","        \"do_sample\": True,\n","        \"streamer\": text_streamer,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","    }\n","\n","    # FastLanguageModel에 맞춘 생성 프로세스\n","    outputs = model.generate(\n","        inputs_embeds=prompted_embeddings,\n","        attention_mask=torch.ones_like(inputs['input_ids']).to(prompt_learner.device),\n","        **generation_params\n","    )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# 테스트 실행 함수\n","def test_cocoop_inference(model, tokenizer, train_json, test_n=0):\n","    print(\"Initializing CoCoOp prompt learner...\")\n","    prompt_learner = DialoguePromptLearner(model, tokenizer)\n","\n","    print(\"\\nGenerating dialogue with CoCoOp...\")\n","    test_instruction = train_json[test_n]['instruction']\n","    test_input = train_json[test_n]['input']\n","\n","    generated_text = generate_dialogue_with_cocoop(\n","        model,\n","        tokenizer,\n","        test_instruction,\n","        test_input,\n","        prompt_learner\n","    )\n","\n","    print(\"\\n=== Generated Response ===\")\n","    print(generated_text)\n","\n","    print(\"\\n=== Correct Response ===\")\n","    print(train_json[test_n]['output'], \"<|end_of_text|>\")"],"metadata":{"id":"IJ2F5KvQjg2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_cocoop_inference(model, tokenizer, train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"KgDs7PiJj-eH","executionInfo":{"status":"error","timestamp":1733806390501,"user_tz":-540,"elapsed":5833571,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"c8db0e9a-c638-4ec8-c49c-21792f2cd647"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing CoCoOp prompt learner...\n","\n","Generating dialogue with CoCoOp...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-4e9da33f2a86>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_cocoop_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-68-7c7980acc2b5>\u001b[0m in \u001b[0;36mtest_cocoop_inference\u001b[0;34m(model, tokenizer, train_json, test_n)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     generated_text = generate_dialogue_with_cocoop(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-7c7980acc2b5>\u001b[0m in \u001b[0;36mgenerate_dialogue_with_cocoop\u001b[0;34m(model, tokenizer, instruction, input_text, prompt_learner)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# 프롬프트된 임베딩 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mprompted_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# 텍스트 생성을 위한 streamer 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-68-7c7980acc2b5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'base_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mbase_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m         \"\"\"\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### Eval"],"metadata":{"id":"gDvBFfDXo6sU"}},{"cell_type":"code","source":[],"metadata":{"id":"MY_j9zvio6Kl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import json\n","\n","# output_train_path = '/content/drive/MyDrive/Colab Notebooks/Harry Potter Alpaca/Harry Potter Alpaca/hpa_train_set.json'\n","# output_test_path = '/content/drive/MyDrive/Colab Notebooks/Harry Potter Alpaca/Harry Potter Alpaca/hpa_test_set.json'\n","# formatted_dataset_path = '/content/drive/MyDrive/Colab Notebooks/Harry Potter Alpaca/Harry Potter Alpaca/hpa_formatted_dataset'\n","\n","# with open(output_train_path, 'r', encoding='utf-8') as f:\n","#     train_data = json.load(f)\n","\n","# with open(output_test_path, 'r', encoding='utf-8') as f:\n","#     test_data = json.load(f)\n","\n","# # 나중에 데이터셋을 다시 로드할 때는 다음과 같이 사용할 수 있습니다:\n","# from datasets import load_from_disk\n","# formatted_dataset = load_from_disk(formatted_dataset_path)"],"metadata":{"id":"6k26yUOMxci3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","# 모델을 inference 모드로 설정\n","FastLanguageModel.for_inference(model)\n","\n","test_result = []\n","\n","# ------------------------------------------------------------------------\n","for test_n in range(200):\n","    # 테스트할 예시 프롬프트 생성\n","    test_instruction = test_data[test_n]['instruction']\n","    test_input = test_data[test_n]['input']\n","\n","    # 입력 텍스트 생성\n","    inputs = tokenizer(\n","        [\n","            alpaca_prompt.format(\n","                test_instruction,  # instruction\n","                test_input,       # input\n","                \"\",              # output - 생성을 위해 비워둠\n","            )\n","        ],\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","    # 텍스트 생성을 위한 streamer 설정\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","\n","    # 생성 파라미터 설정\n","    generation_params = {\n","        \"max_new_tokens\": 256,      # 더 긴 대화를 위해 증가\n","        \"temperature\": 0.2,         # 창의성 조절 (0.7)\n","        \"top_p\": 0.2,              # 다양성 조절 (0.9)\n","        \"do_sample\": True,         # 다양한 응답 생성 가능\n","        \"streamer\": text_streamer,\n","        \"pad_token_id\": tokenizer.pad_token_id,\n","        \"eos_token_id\": tokenizer.eos_token_id,\n","    }\n","\n","    # 텍스트 생성\n","    print(\"Data\", test_n)\n","    print(\"Generating dialogue...\")\n","    outputs = model.generate(**inputs, **generation_params)\n","\n","    print(\"### Correct Dialogue:\")\n","    print(test_data[test_n]['output'], \"<|end_of_text|>\")\n","\n","    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"### Response:\")[1].strip()\n","    ground_truth = test_data[test_n]['output'] + \"<|end_of_text|>\"\n","    test_result.append({\n","        \"prediction\": prediction,\n","        \"ground_truth\": ground_truth\n","    })"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733838944721,"user_tz":-540,"elapsed":241817,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"361b180e-bf3d-4ef9-a4d4-3516a2d1ce16","id":"nqZYXWLqxci7"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Data 100\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Knuts?\n","\n","### Response:\n","Hagrid: Galleons.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school. <|end_of_text|>\n","Data 101\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,\n","Harry: Knuts?\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Um — Hagrid? <|end_of_text|>\n","Data 102\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.\n","Harry: Um — Hagrid?\n","\n","### Response:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Mm? <|end_of_text|>\n","Data 103\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.\n","Harry: Um — Hagrid?\n","Hagrid: Mm?\n","\n","### Response:\n","Hagrid: What?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: I haven’t got any money — and you heard Uncle Vernon last night . . . he won’t pay for me to go and learn magic. But if their house was destroyed — <|end_of_text|>\n","Data 104\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Um — Hagrid?\n","Hagrid: Mm?\n","Harry: I haven’t got any money — and you heard Uncle Vernon last night... he won’t pay for me to go and learn magic. But if their house was destroyed —\n","\n","### Response:\n","Hagrid: Don’t worry, Harry. We’ll get you sorted out.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither. <|end_of_text|>\n","Data 105\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: I haven’t got any money — and you heard Uncle Vernon last night... he won’t pay for me to go and learn magic. But if their house was destroyed —\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither.\n","\n","### Response:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Wizards have banks? <|end_of_text|>\n","Data 106\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither.\n","Harry: Wizards have banks?\n","\n","### Response:\n","Hagrid: They do, they do.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Just the one. <|end_of_text|>\n","Data 107\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Wizards have banks?\n","Hagrid: Just the one.\n","\n","### Response:\n","Hagrid: Gringotts.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? <|end_of_text|>\n","Data 108\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","Hagrid:\n","- age: Adult\n","- lineage: wizard\n","- affiliation: Hogwarts\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","- gender: male\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but ravage is too happy to care. An owl delivers a paper and demands payment, which Hagrid instructs ravage to give. Hagrid tells Harry that they penury to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that helium has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins?\n","\n","### Response:\n","Hagrid: Goblins?<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He usually gets me ter do important stuff fer him. Fetchin’ you — gettin’ things from Gringotts — knows he can trust me, see. Got everythin’? Come on, then.  <|end_of_text|>\n","Data 109\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: It was a dream, I dreamed a giant called Hagrid came to tell me I was going to a school for wizards. When I open my eyes I’ll be at home in my cupboard. And there’s Aunt Petunia knocking on the door, All right, I’m getting up. Don’t do that.\n","\n","### Response:\n","Hagrid: It’s not a dream, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Pay him, <|end_of_text|>\n","Data 110\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Pay him,\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: What? What? <|end_of_text|>\n","Data 111\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Pay him,\n","Harry: What? What?\n","\n","### Response:\n","Hagrid: Pay him,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts, <|end_of_text|>\n","Data 112\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Knuts? <|end_of_text|>\n","Data 113\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,\n","Harry: Knuts?\n","\n","### Response:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school. <|end_of_text|>\n","Data 114\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Um — Hagrid? <|end_of_text|>\n","Data 115\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.\n","Harry: Um — Hagrid?\n","\n","### Response:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Mm? <|end_of_text|>\n","Data 116\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Mm?\n","\n","### Response:\n","Harry: What?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: I haven’t got any money — and you heard Uncle Vernon last night . . . he won’t pay for me to go and learn magic. But if their house was destroyed — <|end_of_text|>\n","Data 117\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Um — Hagrid?\n","Hagrid: Mm?\n","Harry: I haven’t got any money — and you heard Uncle Vernon last night... he won’t pay for me to go and learn magic. But if their house was destroyed —\n","\n","### Response:\n","Hagrid: Well, I dunno what Dumbledore’s got in mind, Harry, but I’m sure yeh’ll be all right.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither. <|end_of_text|>\n","Data 118\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither.\n","\n","### Response:\n","Harry: I’m not allowed to eat between meals.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Wizards have banks? <|end_of_text|>\n","Data 119\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Wizards have banks?\n","\n","### Response:\n","Hagrid: Gringotts, Harry. Gringotts is the wizard bank.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Just the one. <|end_of_text|>\n","Data 120\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither.\n","Harry: Wizards have banks?\n","Hagrid: Just the one.\n","\n","### Response:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? <|end_of_text|>\n","Data 121\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Character Information:\n","Harry:\n","- title: The boy who lived\n","- gender: male\n","- nickname: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","Hagrid:\n","- name: Hagrid\n","\n","Scene:\n","Harry wakes up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, simply Harry is too happy to care. An bird_of_night delivers a newspaper and demands payment, which Hagrid instructs Harry to give. Hagrid tells Harry that they demand to go to Gringotts, the hotshot bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Wizards have banks?\n","Hagrid: Just the one.\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins?\n","\n","### Response:\n","Hagrid: Gringotts is the wizard bank, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He usually gets me ter do important stuff fer him. Fetchin’ you — gettin’ things from Gringotts — knows he can trust me, see. Got everythin’? Come on, then.  <|end_of_text|>\n","Data 122\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: It was a dream, I dreamed a giant called Hagrid came to tell me I was going to a school for wizards. When I open my eyes I’ll be at home in my cupboard. And there’s Aunt Petunia knocking on the door, All right, I’m getting up. Don’t do that.\n","\n","### Response:\n","Hagrid: I’m not a dream, Harry. You’re not in your cupboard. You’re at Hogwarts.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Pay him, <|end_of_text|>\n","Data 123\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Pay him,\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: What? What? <|end_of_text|>\n","Data 124\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: It was a dream, I dreamed a giant called Hagrid came to tell me I was going to a school for wizards. When I open my eyes I’ll be at home in my cupboard. And there’s Aunt Petunia knocking on the door, All right, I’m getting up. Don’t do that.\n","Hagrid: Pay him,\n","Harry: What? What?\n","\n","### Response:\n","Hagrid: The owl.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts, <|end_of_text|>\n","Data 125\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Pay him,\n","Harry: What? What?\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,\n","\n","### Response:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Knuts? <|end_of_text|>\n","Data 126\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: What? What?\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,\n","Harry: Knuts?\n","\n","### Response:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school. <|end_of_text|>\n","Data 127\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts,\n","Harry: Knuts?\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.\n","\n","### Response:\n","Hagrid: He wants payin’ fer deliverin’ the paper. Look in the pockets. Give him five Knuts, Harry: Knuts? Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Um — Hagrid? <|end_of_text|>\n","Data 128\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Knuts?\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.\n","Harry: Um — Hagrid?\n","\n","### Response:\n","Hagrid: The little bronze ones. Best be off, Harry, lots ter do today, gotta get up ter London an’ buy all yer stuff fer school.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Mm? <|end_of_text|>\n","Data 129\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Um — Hagrid?\n","Hagrid: Mm?\n","\n","### Response:\n","Hagrid: Well, I’m sorry, Harry, but I’ve got important business with Dumbledore. I’ll be back for you at half past four.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: I haven’t got any money — and you heard Uncle Vernon last night . . . he won’t pay for me to go and learn magic. But if their house was destroyed — <|end_of_text|>\n","Data 130\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Mm?\n","Harry: I haven’t got any money — and you heard Uncle Vernon last night... he won’t pay for me to go and learn magic. But if their house was destroyed —\n","\n","### Response:\n","Hagrid: Well, I dunno, Harry. I dunno how Dumbledore’ll take it. He’s the headmaster, yeh see, so he’s in charge of all the students, an’ he’s that strict —<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither. <|end_of_text|>\n","Data 131\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither.\n","\n","### Response:\n","Harry: I’m not allowed to eat after midnight.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Wizards have banks? <|end_of_text|>\n","Data 132\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: They didn’ keep their gold in the house, boy! Nah, first stop fer us is Gringotts. Wizards’ bank. Have a sausage, they’re not bad cold — an’ I wouldn’ say no teh a bit o’ yer birthday cake, neither.\n","Harry: Wizards have banks?\n","\n","### Response:\n","Hagrid: They’ve got a lot o’ things Muggles haven’t, boy. Gringotts has got loads o’ gold. An’ it’s guarded by a load o’ goblins.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Just the one. <|end_of_text|>\n","Data 133\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Hagrid: Just the one.\n","\n","### Response:\n","Harry: Yes, please.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? <|end_of_text|>\n","Data 134\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","\n","Scene:\n","Harry stir_up up and realizes that his encounter with Hagrid and the news of being a wizard was not a dream. Aunt Petunia knocks on the door, but Harry is too happy to care. An owl delivers a newspaper and demands payment, which Hagrid instructs harry to give. Hagrid tells Harry that they need to go to Gringotts, the wizard bank, to get money for his school supplies. Hagrid also mentions that he has important business with Dumbledore.\n","\n","Previous Dialogue:\n","Harry: Wizards have banks?\n","Hagrid: Just the one.\n","Harry: Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins? Goblins?\n","\n","### Response:\n","Hagrid: Gringotts is the wizarding bank. It's run by goblins.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: He usually gets me ter do important stuff fer him. Fetchin’ you — gettin’ things from Gringotts — knows he can trust me, see. Got everythin’? Come on, then.  <|end_of_text|>\n","Data 135\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Got everythin’? Come on, then.\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: How did you get here? <|end_of_text|>\n","Data 136\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","\n","### Response:\n","Hagrid: I flew.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Flew, <|end_of_text|>\n","Data 137\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","Hagrid: Flew,\n","\n","### Response:\n","Hagrid: Flew,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Flew? <|end_of_text|>\n","Data 138\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Flew,\n","Harry: Flew?\n","\n","### Response:\n","Hagrid: Flew,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yeah  <|end_of_text|>\n","Data 139\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Flew?\n","Hagrid: Yeah \n","\n","### Response:\n","Hagrid: Yeah, I flew.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts? <|end_of_text|>\n","Data 140\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","\n","### Response:\n","Hagrid: Because it’s impossible, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Spells — enchantments, They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual, <|end_of_text|>\n","Data 141\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","Hagrid: Spells — enchantments, They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual,\n","\n","### Response:\n","Hagrid: They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: There’s a Ministry of Magic? <|end_of_text|>\n","Data 142\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: There’s a Ministry of Magic?\n","\n","### Response:\n","Hagrid: Yeah, it’s in London.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: ’Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askin’ fer advice. <|end_of_text|>\n","Data 143\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: ’Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askin’ fer advice.\n","\n","### Response:\n","Harry: What?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: But what does a Ministry of Magic do? <|end_of_text|>\n","Data 144\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: There’s a Ministry of Magic?\n","Hagrid: ’Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askin’ fer advice.\n","Harry: But what does a Ministry of Magic do?\n","\n","### Response:\n","Hagrid: Keep the Muggles out, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country. <|end_of_text|>\n","Data 145\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: But what does a Ministry of Magic do?\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.\n","\n","### Response:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why? Why? Why? <|end_of_text|>\n","Data 146\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","- lineage: wizard\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","- affiliation: Hogwarts\n","- name: Hagrid\n","- gender: male\n","- title: Key Guardian and Hunting Ground Guard\n","Harry:\n","- age: age 11\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He inquire Harry non to remark it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: But what does a Ministry of Magic do?\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.\n","Harry: Why? Why? Why?\n","\n","### Response:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Why? Blimey, Harry, everyone’d be wantin’ magic solutions to their problems. Nah, we’re best left alone. <|end_of_text|>\n","Data 147\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Got everythin’? Come on, then.\n","\n","### Response:\n","Harry: Right.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: How did you get here? <|end_of_text|>\n","Data 148\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Got everythin’? Come on, then.\n","Harry: How did you get here?\n","\n","### Response:\n","Hagrid: Flew.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Flew, <|end_of_text|>\n","Data 149\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Flew,\n","\n","### Response:\n","Harry: What?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Flew? <|end_of_text|>\n","Data 150\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","Hagrid: Flew,\n","Harry: Flew?\n","\n","### Response:\n","Hagrid: Flew,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yeah  <|end_of_text|>\n","Data 151\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Flew?\n","Hagrid: Yeah \n","\n","### Response:\n","Hagrid: Yeah, I flew.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts? <|end_of_text|>\n","Data 152\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","\n","### Response:\n","Hagrid: Because it’s impossible.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Spells — enchantments, They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual, <|end_of_text|>\n","Data 153\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Spells — enchantments, They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual,\n","\n","### Response:\n","Hagrid: They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: There’s a Ministry of Magic? <|end_of_text|>\n","Data 154\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: There’s a Ministry of Magic?\n","\n","### Response:\n","Hagrid: Yeah, it’s in London.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: ’Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askin’ fer advice. <|end_of_text|>\n","Data 155\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: ’Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askin’ fer advice.\n","\n","### Response:\n","Harry: What’s the Ministry of Magic?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: But what does a Ministry of Magic do? <|end_of_text|>\n","Data 156\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: ’Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askin’ fer advice.\n","Harry: But what does a Ministry of Magic do?\n","\n","### Response:\n","Hagrid: Well, they keep the Muggles out, don’ they?<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country. <|end_of_text|>\n","Data 157\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.\n","\n","### Response:\n","Harry: What do they do with the Muggles who find out about us?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why? Why? Why? <|end_of_text|>\n","Data 158\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Hagrid:\n","Harry:\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid depart the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explain that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: But what does a Ministry of Magic do?\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.\n","Harry: Why? Why? Why?\n","\n","### Response:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Why? Blimey, Harry, everyone’d be wantin’ magic solutions to their problems. Nah, we’re best left alone. <|end_of_text|>\n","Data 159\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Got everythin’? Come on, then.\n","\n","### Response:\n","Harry: What’s that?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: How did you get here? <|end_of_text|>\n","Data 160\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","\n","### Response:\n","Hagrid: I flew.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Flew, <|end_of_text|>\n","Data 161\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: How did you get here?\n","Hagrid: Flew,\n","\n","### Response:\n","Hagrid: I’m not supposed to tell you that, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Flew? <|end_of_text|>\n","Data 162\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Flew,\n","Harry: Flew?\n","\n","### Response:\n","Hagrid: Yeah, I did.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yeah  <|end_of_text|>\n","Data 163\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Flew,\n","Harry: Flew?\n","Hagrid: Yeah \n","\n","### Response:\n","Harry: You flew?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts? <|end_of_text|>\n","Data 164\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","\n","### Response:\n","Hagrid: Because it’s impossible, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Spells — enchantments, They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual, <|end_of_text|>\n","Data 165\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","Hagrid: Spells — enchantments, They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual,\n","\n","### Response:\n","Hagrid: They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: There’s a Ministry of Magic? <|end_of_text|>\n","Data 166\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: Why would you be mad to try and rob Gringotts?\n","Hagrid: Spells — enchantments, They say there’s dragons guardin’ the high-security vaults. And then yeh gotta find yer way — Gringotts is hundreds of miles under London, see. Deep under the Underground. Yeh’d die of hunger tryin’ ter get out, even if yeh did manage ter get yer hands on summat. Ministry o’ Magic messin’ things up as usual,\n","Harry: There’s a Ministry of Magic?\n","\n","### Response:\n","Hagrid: Yeah, they’re the ones who keep the Muggles from findin’ out about us.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: ’Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askin’ fer advice. <|end_of_text|>\n","Data 167\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: ’Course, Bungler if ever there was one. So he pelts Dumbledore with owls every morning, askin’ fer advice.\n","\n","### Response:\n","Harry: What’s the Ministry of Magic?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: But what does a Ministry of Magic do? <|end_of_text|>\n","Data 168\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Harry: But what does a Ministry of Magic do?\n","\n","### Response:\n","Hagrid: They keep the Muggles from finding out about us, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country. <|end_of_text|>\n","Data 169\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.\n","\n","### Response:\n","Harry: What’s the Ministry of Magic?<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Why? Why? Why? <|end_of_text|>\n","Data 170\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid leave the island by boat and Hagrid reveals that he flew there. He asks Harry not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the existence of witches and wizards hidden from Muggles.\n","\n","Character Information:\n","Hagrid:\n","Harry:\n","- title: The boy who lived\n","\n","Scene:\n","Harry and Hagrid leave the island by sauceboat and Hagrid reveals that he flew there. He asks molest not to mention it at Hogwarts. Hagrid explains that Gringotts is heavily guarded with spells and enchantments, including dragons. He also mentions the Ministry of Magic, whose main job is to keep the macrocosm of witches and wizards hidden from Muggles.\n","\n","Previous Dialogue:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.\n","Harry: Why? Why? Why?\n","\n","### Response:\n","Hagrid: Well, their main job is to keep it from the Muggles that there’s still witches an’ wizards up an’ down the country.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Why? Blimey, Harry, everyone’d be wantin’ magic solutions to their problems. Nah, we’re best left alone. <|end_of_text|>\n","Data 171\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","\n","Relations:\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also chaffer the Apothecary to buy potion ingredients, and Hagrid call to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","\n","### Response:\n","Hagrid: Don't be daft, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh, <|end_of_text|>\n","Data 172\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","\n","Relations:\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also chaffer the Apothecary to buy potion ingredients, and Hagrid call to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,\n","\n","### Response:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: You don’t have to — <|end_of_text|>\n","Data 173\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","\n","Relations:\n","Hagrid - His affection to Harry: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also chaffer the Apothecary to buy potion ingredients, and Hagrid call to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,\n","Harry: You don’t have to —\n","\n","### Response:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I know I don’t have to. Tell yeh what, I’ll get yer animal. Not a toad, toads went outta fashion years ago, yeh’d be laughed at an’ I don’ like cats, they make me sneeze. <|end_of_text|>\n","Data 174\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Harry:\n","- age: age 11\n","- name: Harry\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- gender: male\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- lineage: wizard\n","- age: Adult\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to bargain Harry's school books. Harry was fascinated by the variety of books, including single on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as A birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","\n","### Response:\n","Hagrid: You can't use magic in the Muggle world, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh, <|end_of_text|>\n","Data 175\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Harry:\n","- age: age 11\n","- name: Harry\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- gender: male\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- lineage: wizard\n","- age: Adult\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to bargain Harry's school books. Harry was fascinated by the variety of books, including single on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as A birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,\n","\n","### Response:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’t work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: You don’t have to — <|end_of_text|>\n","Data 176\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Character Information:\n","Harry:\n","- age: age 11\n","- name: Harry\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- gender: male\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- lineage: wizard\n","- age: Adult\n","\n","Relations:\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's familiarity with him: 4.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to bargain Harry's school books. Harry was fascinated by the variety of books, including single on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as A birthday present.\n","\n","Previous Dialogue:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,\n","Harry: You don’t have to —\n","\n","### Response:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh can’t work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I know I don’t have to. Tell yeh what, I’ll get yer animal. Not a toad, toads went outta fashion years ago, yeh’d be laughed at an’ I don’ like cats, they make me sneeze. <|end_of_text|>\n","Data 177\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Character Information:\n","Harry:\n","- gender: male\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one along curses that he wanted to use on Dudley. Hagrid remind Harry that he couldn't use magic in the Muggle world. They also shoot_the_breeze the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: I was trying to find out how to curse Dudley.\n","\n","### Response:\n","Hagrid: You can’t use magic in the Muggle world, Harry.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh, <|end_of_text|>\n","Data 178\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Character Information:\n","Harry:\n","- gender: male\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one along curses that he wanted to use on Dudley. Hagrid remind Harry that he couldn't use magic in the Muggle world. They also shoot_the_breeze the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,\n","\n","### Response:\n","Hagrid: I’m not sayin’ that’s not a good idea, but yer not ter use magic in the Muggle world except in very special circumstances, An’ anyway, yeh couldn’ work any of them curses yet, yeh’ll need a lot more study before yeh get ter that level. Oh,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: You don’t have to — <|end_of_text|>\n","Data 179\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one on curses that he wanted to use on Dudley. Hagrid reminded Harry that he couldn't use magic in the Muggle world. They also visited the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Character Information:\n","Harry:\n","- gender: male\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- name: Harry\n","- age: age 11\n","- nickname: The boy who lived\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- name: Hagrid\n","\n","Relations:\n","Hagrid - friend: 1.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - His familiarity with Harry: 6.0\n","Hagrid - Harry's affection to him: 5.0\n","\n","Scene:\n","Harry and Hagrid went to Flourish and Blotts to buy Harry's school books. Harry was fascinated by the variety of books, including one along curses that he wanted to use on Dudley. Hagrid remind Harry that he couldn't use magic in the Muggle world. They also shoot_the_breeze the Apothecary to buy potion ingredients, and Hagrid promised to buy Harry an owl as a birthday present.\n","\n","Previous Dialogue:\n","Harry: You don’t have to —\n","\n","### Response:\n","Hagrid: I know, I know, but I want ter.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: I know I don’t have to. Tell yeh what, I’ll get yer animal. Not a toad, toads went outta fashion years ago, yeh’d be laughed at an’ I don’ like cats, they make me sneeze. <|end_of_text|>\n","Data 180\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Don’ mention it, Don’ expect you’ve had a lotta presents from them Dursleys. Just Ollivanders left now — only place fer wands, Ollivanders, and yeh gotta have the best wand.\n","\n","### Response:\n","Harry: I know.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Good afternoon, <|end_of_text|>\n","Data 181\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Good afternoon,\n","\n","### Response:\n","Hagrid: Good afternoon, sir.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Hello, <|end_of_text|>\n","Data 182\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Good afternoon,\n","Harry: Hello,\n","\n","### Response:\n","Ollivanders: You’re the boy who came in here a few years ago, aren’t you?<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it — it’s really the wand that chooses the wizard, of course Oh, Yew. <|end_of_text|>\n","Data 183\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Harry: Hello,\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it — it’s really the wand that chooses the wizard, of course Oh, Yew.\n","\n","### Response:\n","Hagrid:<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: It was, sir, yes, <|end_of_text|>\n","Data 184\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it — it’s really the wand that chooses the wizard, of course Oh, Yew.\n","Hagrid: It was, sir, yes,\n","\n","### Response:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it — it’s really the wand that chooses the wizard, of course Oh, Yew.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled? <|end_of_text|>\n","Data 185\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled?\n","\n","### Response:\n","Hagrid: No, they didn’t.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yes, I’ve still got the pieces, though, <|end_of_text|>\n","Data 186\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: It was, sir, yes,\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled?\n","Hagrid: Yes, I’ve still got the pieces, though,\n","\n","### Response:\n","Hagrid: It was, sir, yes, Good wand, that one. But I suppose they snapped it in half when you got expelled? Yes, I’ve still got the pieces, though,<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: But you don’t use them? <|end_of_text|>\n","Data 187\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled?\n","Hagrid: Yes, I’ve still got the pieces, though,\n","Ollivanders: But you don’t use them?\n","\n","### Response:\n","Hagrid: No, I don’t use them.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Oh, <|end_of_text|>\n","Data 188\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Yes, I’ve still got the pieces, though,\n","Ollivanders: But you don’t use them?\n","Hagrid: Oh,\n","\n","### Response:\n","Hagrid: No, I’m not much of a wizard, yeh know.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Well, <|end_of_text|>\n","Data 189\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Oh,\n","Ollivanders: Well,\n","\n","### Response:\n","Hagrid: Well,<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Oh, <|end_of_text|>\n","Data 190\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- affiliation: Hogwarts\n","- age: Adult\n","- looks: Surprisingly tall, full of beards\n","Harry:\n","\n","Relations:\n","Hagrid - Harry's affection to him: 5.0\n","Hagrid - Harry's familiarity with him: 4.0\n","Hagrid - His affection to Harry: 4.0\n","Hagrid - friend: 1.0\n","Hagrid - His familiarity with Harry: 6.0\n","\n","Scene:\n","In this scene, chivy and Hagrid visit Ollivanders, the solitary place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave plague his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Well,\n","Harry: Oh,\n","\n","### Response:\n","Ollivanders: Well,<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Oh, Oh, Curious . . . curious . . . I remember every wand I’ve ever sold, Mr. Potter. Every single wand. It so happens that the phoenix whose tail feather is in your wand, gave another feather — just one other. It is very curious indeed that you should be destined for this wand when its brother — why, its brother gave you that scar. Yes, thirteen-and-a-half inches. Yew. Yew. Curious indeed how these things happen. The wand chooses the wizard, remember.. . . I think we must expect great things from you, Mr. Potter. . . . After all, He-Who-Must-Not-Be-Named did great things — terrible, yes, but great. <|end_of_text|>\n","Data 191\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Don’ mention it, Don’ expect you’ve had a lotta presents from them Dursleys. Just Ollivanders left now — only place fer wands, Ollivanders, and yeh gotta have the best wand.\n","\n","### Response:\n","Hagrid: Don’ mention it, Don’ expect you’ve had a lotta presents from them Dursleys. Just Ollivanders left now — only place fer wands, Ollivanders, and yeh gotta have the best wand.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Good afternoon, <|end_of_text|>\n","Data 192\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Don’ mention it, Don’ expect you’ve had a lotta presents from them Dursleys. Just Ollivanders left now — only place fer wands, Ollivanders, and yeh gotta have the best wand.\n","Ollivanders: Good afternoon,\n","\n","### Response:\n","Hagrid: Don’ mention it, Don’ expect you’ve had a lotta presents from them Dursleys. Just Ollivanders left now — only place fer wands, Ollivanders, and yeh gotta have the best wand.<|end_of_text|>\n","### Correct Dialogue:\n","Harry: Hello, <|end_of_text|>\n","Data 193\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Harry: Hello,\n","\n","### Response:\n","Ollivander: Hello, hello, hello, and who might you be?<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it — it’s really the wand that chooses the wizard, of course Oh, Yew. <|end_of_text|>\n","Data 194\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Harry: Hello,\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it — it’s really the wand that chooses the wizard, of course Oh, Yew.\n","\n","### Response:\n","Hagrid:<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: It was, sir, yes, <|end_of_text|>\n","Data 195\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it — it’s really the wand that chooses the wizard, of course Oh, Yew.\n","Hagrid: It was, sir, yes,\n","\n","### Response:\n","Ollivanders: Ah Your father, on the other hand, favored a mahogany wand. Eleven inches. Pliable. A little more power and excellent for transfiguration. Well, I say your father favored it — it’s really the wand that chooses the wizard, of course Oh, Yew.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled? <|end_of_text|>\n","Data 196\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: It was, sir, yes,\n","Ollivanders: Good wand, that one. But I suppose they snapped it in half when you got expelled?\n","\n","### Response:\n","Hagrid: It was, sir, yes,<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Yes, I’ve still got the pieces, though, <|end_of_text|>\n","Data 197\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Yes, I’ve still got the pieces, though,\n","\n","### Response:\n","Hagrid: Yes, I’ve still got the pieces, though,<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: But you don’t use them? <|end_of_text|>\n","Data 198\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Hagrid: Yes, I’ve still got the pieces, though,\n","Ollivanders: But you don’t use them?\n","\n","### Response:\n","Hagrid: No, I don’t.<|end_of_text|>\n","### Correct Dialogue:\n","Hagrid: Oh, <|end_of_text|>\n","Data 199\n","Generating dialogue...\n","<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Given the following context and previous dialogue, generate the next line of dialogue:\n","\n","### Input:\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before finding the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mr. Ollivander tells Harry that the wand chooses the wizard and expects great things from him.\n","\n","Character Information:\n","Hagrid:\n","- looks: Surprisingly tall, full of beards\n","- title: Key Guardian and Hunting Ground Guard\n","- name: Hagrid\n","- lineage: wizard\n","- gender: male\n","- age: Adult\n","- affiliation: Hogwarts\n","Harry:\n","- nickname: The boy who lived\n","- title: The boy who lived\n","- looks: Very thin, black hair, emerald green eyes, wearing glasses, knife injury with lightning shape at the forehead\n","- gender: male\n","\n","Scene:\n","In this scene, Harry and Hagrid visit Ollivanders, the only place for wands. Mr. Ollivander, the owner, greets them and measures Harry for his wand. He tries several wands before retrieve the perfect match, which happens to have a phoenix feather core, just like the wand that gave Harry his scar. Mister Ollivander tells chivy that the wand chooses the wizard and expects great things from him.\n","\n","Previous Dialogue:\n","Ollivanders: But you don’t use them?\n","Hagrid: Oh,\n","\n","### Response:\n","Hagrid: Oh, no, sir, I’m not much of a wizard, I’m afraid.<|end_of_text|>\n","### Correct Dialogue:\n","Ollivanders: Well, <|end_of_text|>\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","\n","# 저장할 경로 설정\n","save_path = '/content/drive/MyDrive/Colab Notebooks/test_results(lora).json'\n","\n","# JSON 형식으로 저장\n","with open(save_path, 'w', encoding='utf-8') as f:\n","    json.dump(test_result, f, ensure_ascii=False, indent=2)\n","\n","print(f'Results saved to: {save_path}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyd7iYlLgmDf","executionInfo":{"status":"ok","timestamp":1733839791907,"user_tz":-540,"elapsed":379,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"12679240-9bbd-4534-8d24-0b95dbee9289"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Results saved to: /content/drive/MyDrive/Colab Notebooks/test_results(lora).json\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"h8JEWkZohpdX"}},{"cell_type":"code","source":["# Install required packages\n","!pip install -q transformers torch sentence-transformers nltk\n","\n","import numpy as np\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","from nltk.translate.meteor_score import meteor_score\n","from nltk.lm.preprocessing import padded_everygram_pipeline\n","from nltk.lm import MLE\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from scipy.spatial.distance import cosine\n","from sentence_transformers import SentenceTransformer\n","import nltk\n","\n","# Download ALL required NLTK data at the start\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger')\n","\n","def calculate_bleu(reference, hypothesis):\n","    \"\"\"\n","    Calculate BLEU score between reference and hypothesis\n","    \"\"\"\n","    # Tokenize the sentences\n","    ref_tokens = nltk.word_tokenize(reference.lower())\n","    hyp_tokens = nltk.word_tokenize(hypothesis.lower())\n","\n","    # Calculate BLEU score with smoothing\n","    smoothing = SmoothingFunction().method1\n","    return sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoothing)\n","\n","def calculate_meteor(reference, hypothesis):\n","    \"\"\"\n","    Calculate METEOR score between reference and hypothesis\n","    \"\"\"\n","    return meteor_score([reference.split()], hypothesis.split())\n","\n","def calculate_perplexity(text, model_name='gpt2'):\n","    \"\"\"\n","    Calculate perplexity using GPT-2\n","    \"\"\"\n","    # Load model and tokenizer\n","    model = GPT2LMHeadModel.from_pretrained(model_name)\n","    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","    model.eval()\n","\n","    # Encode text\n","    encodings = tokenizer(text, return_tensors='pt')\n","\n","    # Calculate perplexity\n","    max_length = model.config.n_positions\n","    stride = 512\n","    seq_len = encodings.input_ids.size(1)\n","\n","    nlls = []\n","    prev_end_loc = 0\n","    for begin_loc in range(0, seq_len, stride):\n","        end_loc = min(begin_loc + max_length, seq_len)\n","        trg_len = end_loc - prev_end_loc\n","        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n","        target_ids = input_ids.clone()\n","        target_ids[:, :-trg_len] = -100\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, labels=target_ids)\n","            neg_log_likelihood = outputs.loss\n","\n","        nlls.append(neg_log_likelihood)\n","        prev_end_loc = end_loc\n","        if end_loc == seq_len:\n","            break\n","\n","    ppl = torch.exp(torch.stack(nlls).mean())\n","    return ppl.item()\n","\n","def calculate_simile(reference, hypothesis):\n","    \"\"\"\n","    Calculate SIMILE (Semantic Similarity) score using sentence transformers\n","    \"\"\"\n","    # Load sentence transformer model\n","    model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","    # Get embeddings\n","    ref_embedding = model.encode([reference])[0]\n","    hyp_embedding = model.encode([hypothesis])[0]\n","\n","    # Calculate cosine similarity\n","    similarity = 1 - cosine(ref_embedding, hyp_embedding)\n","    return similarity\n","\n","def evaluate_json_responses(test_result):\n","    \"\"\"\n","    Calculate metrics for JSON list containing predictions and ground truths\n","\n","    Args:\n","        test_result (list): List of dictionaries with 'prediction' and 'ground_truth' keys\n","\n","    Returns:\n","        dict: Dictionary containing average scores for all metrics\n","    \"\"\"\n","    scores = {\n","        'bleu': [],\n","        'meteor': [],\n","        'perplexity': [],\n","        'simile': []\n","    }\n","\n","    for item in test_result:\n","        # Extract prediction and ground truth\n","        prediction = item['prediction']\n","        ground_truth = item['ground_truth']\n","\n","        # Remove special tokens if present\n","        ground_truth = ground_truth.replace('<|end_of_text|>', '').strip()\n","\n","        # Calculate scores\n","        scores['bleu'].append(calculate_bleu(ground_truth, prediction))\n","        scores['meteor'].append(calculate_meteor(ground_truth, prediction))\n","        scores['perplexity'].append(calculate_perplexity(prediction))\n","        scores['simile'].append(calculate_simile(ground_truth, prediction))\n","\n","    # Calculate averages\n","    return {metric: np.mean(values) for metric, values in scores.items()}"],"metadata":{"id":"smvIacvzhlU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","# JSON 파일 불러오기\n","with open('/content/drive/MyDrive/Colab Notebooks/딥러닝 프로젝트/test_results(lora).json', 'r', encoding='utf-8') as f:\n","    loaded_result = json.load(f)\n","\n","scores = evaluate_json_responses(loaded_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xk2zTBRF6Rbw","executionInfo":{"status":"ok","timestamp":1733841721332,"user_tz":-540,"elapsed":209507,"user":{"displayName":"박경빈","userId":"04876725348542542168"}},"outputId":"35b26f12-0940-4a76-a2d1-5e03cb65e3b5"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Average Metrics:\n","Average BLEU Score: 0.2191\n","Average METEOR Score: 0.2675\n","Average Perplexity: 26.4606\n","Average SIMILE Score: 0.9512\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1efOx_rwZeF3i0YsirhM1xhYLtGNX6Fv3","timestamp":1733403104209},{"file_id":"18KF6yNW9pRS7lwYk8zRLRI_otrpL84ev","timestamp":1713732901332},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1713724264856},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}],"gpuType":"T4","collapsed_sections":["fROHRlcGdfNs"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"52f9b70227734735a77025b1547a4f7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e18f78b0a6c04c8db654ad8abf40856c","IPY_MODEL_13abce7bc961407b80aef01ca37e0fff","IPY_MODEL_6afd34f975714df989c95557bb172114"],"layout":"IPY_MODEL_ea30410ff5b94e36aa7f1ae04c2041cb"}},"e18f78b0a6c04c8db654ad8abf40856c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8e19f6a2b594e67890184c887173466","placeholder":"​","style":"IPY_MODEL_fd8bbe23de63456086beba03a3eb7015","value":"Map: 100%"}},"13abce7bc961407b80aef01ca37e0fff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cba5291efb80400f8528a5a049bb7a31","max":44166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ad660d0f04d4c90a435e222d5a93436","value":44166}},"6afd34f975714df989c95557bb172114":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4246cf13026447c0b60a5c33dacf1b1a","placeholder":"​","style":"IPY_MODEL_96d4081338c04ec19db1142e9b8557b1","value":" 44166/44166 [00:09&lt;00:00, 6916.27 examples/s]"}},"ea30410ff5b94e36aa7f1ae04c2041cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8e19f6a2b594e67890184c887173466":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd8bbe23de63456086beba03a3eb7015":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cba5291efb80400f8528a5a049bb7a31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad660d0f04d4c90a435e222d5a93436":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4246cf13026447c0b60a5c33dacf1b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d4081338c04ec19db1142e9b8557b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c420788c75cb4df0b73057c1f99fc2f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32cce8257910411381ae107f1b272f87","IPY_MODEL_c7f97e1a812c419d814d63ce35342af3","IPY_MODEL_991589b50c8c4cb8b3228397fe25fc42"],"layout":"IPY_MODEL_4f49199d63f7407ca0a9f00fedb6ca69"}},"32cce8257910411381ae107f1b272f87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c09c77a34ae4daba634d6f0922c42e3","placeholder":"​","style":"IPY_MODEL_9881d8fac75446fbbadb75103be04060","value":"Map: 100%"}},"c7f97e1a812c419d814d63ce35342af3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb0db9321a3043e98581240e0b446418","max":2601,"min":0,"orientation":"horizontal","style":"IPY_MODEL_643e63457df14b85a3f96185eb68f849","value":2601}},"991589b50c8c4cb8b3228397fe25fc42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e5d1fac31c1477cac1c32a694e7efdf","placeholder":"​","style":"IPY_MODEL_900a48c9a1fc4dcfa5aa980185b6e4d5","value":" 2601/2601 [00:00&lt;00:00, 26311.26 examples/s]"}},"4f49199d63f7407ca0a9f00fedb6ca69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c09c77a34ae4daba634d6f0922c42e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9881d8fac75446fbbadb75103be04060":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb0db9321a3043e98581240e0b446418":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643e63457df14b85a3f96185eb68f849":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e5d1fac31c1477cac1c32a694e7efdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900a48c9a1fc4dcfa5aa980185b6e4d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4e87718aa47491eb9f69a420836f207":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_004f69c8123f445898206cfb4d15ded8","IPY_MODEL_0c9cda1d48dc4561b6671b3408a3c375","IPY_MODEL_4c3c24727a11472582b3119597c24341"],"layout":"IPY_MODEL_926e06cf281e40549fb1db6ab51a80e0"}},"004f69c8123f445898206cfb4d15ded8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4f6744cca874f36be142f33c570e79f","placeholder":"​","style":"IPY_MODEL_87427d5afa494ad58ddb676da98aadd1","value":"Saving the dataset (2/2 shards): 100%"}},"0c9cda1d48dc4561b6671b3408a3c375":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b1d303c7b8e40299675942ca6e8ad6e","max":44166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1b441a11f4c43e89a61e4ee94784664","value":44166}},"4c3c24727a11472582b3119597c24341":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be3ac3e413f441ae8f446eba8b453934","placeholder":"​","style":"IPY_MODEL_570a8e8476554129bf9f2b4545f4b648","value":" 44166/44166 [00:12&lt;00:00, 1279.06 examples/s]"}},"926e06cf281e40549fb1db6ab51a80e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4f6744cca874f36be142f33c570e79f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87427d5afa494ad58ddb676da98aadd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b1d303c7b8e40299675942ca6e8ad6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1b441a11f4c43e89a61e4ee94784664":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be3ac3e413f441ae8f446eba8b453934":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"570a8e8476554129bf9f2b4545f4b648":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65ed847eec544f8dbb809936aa6cbd69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f96ff44f96a44bcb75b11cafb9d268d","IPY_MODEL_c27891e91cb949608bd0e1eef0f1efc8","IPY_MODEL_767002e4ac14423a96a07459745f730c"],"layout":"IPY_MODEL_00b36f1496b74c0a8ff0ce1709256745"}},"6f96ff44f96a44bcb75b11cafb9d268d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f3fd149169248f7a087ec9b18a34ad3","placeholder":"​","style":"IPY_MODEL_1f5f8eebe3b94eb9aa8f6b9578291686","value":"Saving the dataset (1/1 shards): 100%"}},"c27891e91cb949608bd0e1eef0f1efc8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_849df78437854f358bc43511beb4ec89","max":2601,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d0ff024983d456781895bccb2debbc7","value":2601}},"767002e4ac14423a96a07459745f730c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d827420671ac4e14af3fb8d7d106c50b","placeholder":"​","style":"IPY_MODEL_7627743dd5bb4ecb84856bdb54482592","value":" 2601/2601 [00:00&lt;00:00, 58144.31 examples/s]"}},"00b36f1496b74c0a8ff0ce1709256745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f3fd149169248f7a087ec9b18a34ad3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f5f8eebe3b94eb9aa8f6b9578291686":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"849df78437854f358bc43511beb4ec89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d0ff024983d456781895bccb2debbc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d827420671ac4e14af3fb8d7d106c50b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7627743dd5bb4ecb84856bdb54482592":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6a97c45088c4a058ecf4d3eaf9f09f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2072faa03a0b4e729f8d7cc1957d0e5b","IPY_MODEL_eed68d78d3eb4c9eb01e0b9d27dd962d","IPY_MODEL_d875c797d8244582bbbc300da7f9de28"],"layout":"IPY_MODEL_0a4addfb1c7a4bc2a11703600d30da49"}},"2072faa03a0b4e729f8d7cc1957d0e5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_589182e5255b412f9deb87c7b49c8a8a","placeholder":"​","style":"IPY_MODEL_57dd050c574a48f09e9dccf912136f9e","value":"Map (num_proc=2): 100%"}},"eed68d78d3eb4c9eb01e0b9d27dd962d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb9af07731e24ea288a365a03f703802","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7ebb0bee0b147b494a29e1acf792845","value":500}},"d875c797d8244582bbbc300da7f9de28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7ee6c126ad4dd5b0a8a814960170e9","placeholder":"​","style":"IPY_MODEL_670338d4087a44bcbe6430720e070236","value":" 500/500 [00:06&lt;00:00, 42.41 examples/s]"}},"0a4addfb1c7a4bc2a11703600d30da49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"589182e5255b412f9deb87c7b49c8a8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57dd050c574a48f09e9dccf912136f9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb9af07731e24ea288a365a03f703802":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ebb0bee0b147b494a29e1acf792845":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d7ee6c126ad4dd5b0a8a814960170e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"670338d4087a44bcbe6430720e070236":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06b0b5c6bd4c4606b96c56586a5a969f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54f71e95d414421c8955d0ed6a72a0be","IPY_MODEL_7804471a616b4b3c82b25fb571cfdbbe","IPY_MODEL_11fe91b689df446db617cd60bc289862"],"layout":"IPY_MODEL_54f9c7b5ff8f47c994275e5e02bfcd9f"}},"54f71e95d414421c8955d0ed6a72a0be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b209a5ce1a4641fdbf9ea503acb0f108","placeholder":"​","style":"IPY_MODEL_737e7fe57c8545bea4c2d7af1099e48e","value":"config.json: 100%"}},"7804471a616b4b3c82b25fb571cfdbbe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3c9246062f147e48ba5f793cb8c1dac","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc6097ac48c54ea3a2da7c8532176b9d","value":665}},"11fe91b689df446db617cd60bc289862":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_248de5138a8243e288d8c5ed9b6b3a37","placeholder":"​","style":"IPY_MODEL_7430be762ab44b9e9ad7476f9b408ead","value":" 665/665 [00:00&lt;00:00, 39.1kB/s]"}},"54f9c7b5ff8f47c994275e5e02bfcd9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b209a5ce1a4641fdbf9ea503acb0f108":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"737e7fe57c8545bea4c2d7af1099e48e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3c9246062f147e48ba5f793cb8c1dac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc6097ac48c54ea3a2da7c8532176b9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"248de5138a8243e288d8c5ed9b6b3a37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7430be762ab44b9e9ad7476f9b408ead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1a9193130964a32a15544dab5310d2a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9813b985e97c411fa554f362ee3c42b8","IPY_MODEL_da34e5ba9d4c4342875ab07be2257804","IPY_MODEL_ecc146ea7c744add8845eb093bac824b"],"layout":"IPY_MODEL_3cdc75bbc37b4ec2bed70355d60a9078"}},"9813b985e97c411fa554f362ee3c42b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c949bedfe5f4350b1731e4333d0871e","placeholder":"​","style":"IPY_MODEL_ee457dcaa92b4f73a60408ac12cb3ccd","value":"model.safetensors: 100%"}},"da34e5ba9d4c4342875ab07be2257804":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e9f6090106b4a7aacdc6bce521c9f83","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf9a90bb39d447a4abba2cec4ab6ed94","value":548105119}},"ecc146ea7c744add8845eb093bac824b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0101882a7c024f659558a1fb19244462","placeholder":"​","style":"IPY_MODEL_b280b36a94734adbb1648fbd0d4e4d53","value":" 548M/548M [00:03&lt;00:00, 338MB/s]"}},"3cdc75bbc37b4ec2bed70355d60a9078":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c949bedfe5f4350b1731e4333d0871e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee457dcaa92b4f73a60408ac12cb3ccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e9f6090106b4a7aacdc6bce521c9f83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf9a90bb39d447a4abba2cec4ab6ed94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0101882a7c024f659558a1fb19244462":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b280b36a94734adbb1648fbd0d4e4d53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b5268fcc60d4b4f8ed5287516558f90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_350ad988dcc24b29985684cd87a01128","IPY_MODEL_3f925f435c644a2fbe2f10cb7095c199","IPY_MODEL_4b33ae6dbe3947878789154d3b7f69db"],"layout":"IPY_MODEL_60912685336a4324b19dcf106e8a30ad"}},"350ad988dcc24b29985684cd87a01128":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_786baba186ff40eb9f4923d306493d5f","placeholder":"​","style":"IPY_MODEL_9d144ebfe96045eca3eb0a9cfa0914a8","value":"generation_config.json: 100%"}},"3f925f435c644a2fbe2f10cb7095c199":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6803e762288c427cb0d6a7074473ec22","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c41796fbc16e4c77852bd772e275b1bf","value":124}},"4b33ae6dbe3947878789154d3b7f69db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4676d0e3769f404cb0cbde38a42c37ca","placeholder":"​","style":"IPY_MODEL_6c9b78b2748e4aaeb14ff90f37c03038","value":" 124/124 [00:00&lt;00:00, 4.72kB/s]"}},"60912685336a4324b19dcf106e8a30ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"786baba186ff40eb9f4923d306493d5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d144ebfe96045eca3eb0a9cfa0914a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6803e762288c427cb0d6a7074473ec22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c41796fbc16e4c77852bd772e275b1bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4676d0e3769f404cb0cbde38a42c37ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c9b78b2748e4aaeb14ff90f37c03038":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d16094dc3f81455bb8cf2fc8e6730ca0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd9fb35cf2d2476c89defd096273a5f1","IPY_MODEL_177b85f83eec47beb41e72683e887366","IPY_MODEL_8555042c75a047efa47a9ff6a634a6f3"],"layout":"IPY_MODEL_f8d22dc858494872b01c34bb49563ec2"}},"dd9fb35cf2d2476c89defd096273a5f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f5850588abf498bb45c64c39c75f932","placeholder":"​","style":"IPY_MODEL_15a6cb3a0d534efe973c5e98b6afd3e1","value":"tokenizer_config.json: 100%"}},"177b85f83eec47beb41e72683e887366":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc1c489409eb493d8c5b89068d7ba9ed","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4e4cc5e14304c0a9e656a1ef69410bb","value":26}},"8555042c75a047efa47a9ff6a634a6f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37afa932f1884e77b1ed6e9fbc4a025c","placeholder":"​","style":"IPY_MODEL_47d59a08e75f45c780c241eab5f77417","value":" 26.0/26.0 [00:00&lt;00:00, 1.38kB/s]"}},"f8d22dc858494872b01c34bb49563ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f5850588abf498bb45c64c39c75f932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15a6cb3a0d534efe973c5e98b6afd3e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc1c489409eb493d8c5b89068d7ba9ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4e4cc5e14304c0a9e656a1ef69410bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37afa932f1884e77b1ed6e9fbc4a025c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47d59a08e75f45c780c241eab5f77417":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5eb7172adae9467f85a9faf4cc414247":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38bdd48028a14a3192b0e2d2be54642f","IPY_MODEL_eafceacb104e4622b54faaa5a3f00f1f","IPY_MODEL_d9e3fce8db43428097b6592621f02d5f"],"layout":"IPY_MODEL_b699a4911ba649c2a8015a63fe342c2a"}},"38bdd48028a14a3192b0e2d2be54642f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_289408ddb467436f808ec2d62160f843","placeholder":"​","style":"IPY_MODEL_16ed514587a84338a6eb39b96179c57d","value":"vocab.json: 100%"}},"eafceacb104e4622b54faaa5a3f00f1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_605dfc90d21f470484634e125d40de6f","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3eaa26d43e9e431b9f1481fac2b71b86","value":1042301}},"d9e3fce8db43428097b6592621f02d5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fdfc46b60f94d578afdc8408b5b1f38","placeholder":"​","style":"IPY_MODEL_7b82c4f0073b43b7a20a811e390cc6b5","value":" 1.04M/1.04M [00:00&lt;00:00, 10.1MB/s]"}},"b699a4911ba649c2a8015a63fe342c2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"289408ddb467436f808ec2d62160f843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16ed514587a84338a6eb39b96179c57d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"605dfc90d21f470484634e125d40de6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eaa26d43e9e431b9f1481fac2b71b86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fdfc46b60f94d578afdc8408b5b1f38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b82c4f0073b43b7a20a811e390cc6b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b822ce0dc4942a5b10a38729fc9d940":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_376bccb84a654dd0b63d6f7539763ee1","IPY_MODEL_1156178e280248fd9e33abead2a23e9e","IPY_MODEL_572ba88a54bd452c9e19d06f523e592e"],"layout":"IPY_MODEL_9c21507260914e98b308eee228c82b5c"}},"376bccb84a654dd0b63d6f7539763ee1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9ca2cdc28d1470498186ee6e0ced4f3","placeholder":"​","style":"IPY_MODEL_debb00b747c94b9f91471ab97bbb7420","value":"merges.txt: 100%"}},"1156178e280248fd9e33abead2a23e9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa2d7f795c542d083eb4ef83cc898ac","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0d4403d5bec491aafa25bd51a22daac","value":456318}},"572ba88a54bd452c9e19d06f523e592e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cb597f252a34c83afdde505e9ffdbf9","placeholder":"​","style":"IPY_MODEL_93d89ce3fc8143a680f632ebb4adf540","value":" 456k/456k [00:00&lt;00:00, 24.0MB/s]"}},"9c21507260914e98b308eee228c82b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9ca2cdc28d1470498186ee6e0ced4f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"debb00b747c94b9f91471ab97bbb7420":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aa2d7f795c542d083eb4ef83cc898ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0d4403d5bec491aafa25bd51a22daac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2cb597f252a34c83afdde505e9ffdbf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93d89ce3fc8143a680f632ebb4adf540":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb8280f9ce7428b88fd77b49ff948fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e945787c68d4d49948695f490220248","IPY_MODEL_8ef7b9d616c343b3b7dcf7883ff945e2","IPY_MODEL_65917152dc604aeda0edc1c47c367484"],"layout":"IPY_MODEL_f16b291a5d2f4bd4b9635b5aa99b3145"}},"7e945787c68d4d49948695f490220248":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97a267e4f5cf4238bfcdff19b785987e","placeholder":"​","style":"IPY_MODEL_5ae0273b0a834c1c979c9d1b594efd31","value":"tokenizer.json: 100%"}},"8ef7b9d616c343b3b7dcf7883ff945e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_befc06fe73644b4c85635f04ff3ab2d9","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2d9f492d8ad48ee8f6abc4b7b0ee977","value":1355256}},"65917152dc604aeda0edc1c47c367484":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f40ae75ce1f4a309e37cb8e61f6a7e8","placeholder":"​","style":"IPY_MODEL_70929129f1f94438a7ba340a6d403d15","value":" 1.36M/1.36M [00:00&lt;00:00, 35.5MB/s]"}},"f16b291a5d2f4bd4b9635b5aa99b3145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97a267e4f5cf4238bfcdff19b785987e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ae0273b0a834c1c979c9d1b594efd31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"befc06fe73644b4c85635f04ff3ab2d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2d9f492d8ad48ee8f6abc4b7b0ee977":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f40ae75ce1f4a309e37cb8e61f6a7e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70929129f1f94438a7ba340a6d403d15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91ea0a96d7be4e6882a47bf65e451a56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eed2aa114b494969abbac1cde7fb47fb","IPY_MODEL_5c03fe142ff842979513e5d4918793fb","IPY_MODEL_863264cfb9704716b0650feb18925d7a"],"layout":"IPY_MODEL_0db011e15d94455b92c21c7762fda4c4"}},"eed2aa114b494969abbac1cde7fb47fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26e96f4d96834a44856c9c1bc4c31898","placeholder":"​","style":"IPY_MODEL_f433cad65814441881566a9c18bbae59","value":"modules.json: 100%"}},"5c03fe142ff842979513e5d4918793fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3277da32e874d779948d2aa27c87e56","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3905c9747d84172967ea1a0d94c7406","value":349}},"863264cfb9704716b0650feb18925d7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_866795b0cc554da8acaa63d9ebbd214f","placeholder":"​","style":"IPY_MODEL_fcc7d69a1f35451c8967f3e0a71da2ed","value":" 349/349 [00:00&lt;00:00, 25.5kB/s]"}},"0db011e15d94455b92c21c7762fda4c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26e96f4d96834a44856c9c1bc4c31898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f433cad65814441881566a9c18bbae59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3277da32e874d779948d2aa27c87e56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3905c9747d84172967ea1a0d94c7406":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"866795b0cc554da8acaa63d9ebbd214f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcc7d69a1f35451c8967f3e0a71da2ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcb9e204ae644a6f80fe924e16cdb0fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b00b87e8db4459eb0758d0419fe07ee","IPY_MODEL_84cfed1b59ed4d918ff594947be27adb","IPY_MODEL_b31acc9e55ba41929c7dab203fb79978"],"layout":"IPY_MODEL_939b5ada21bb4b858128a1d4caa9117f"}},"6b00b87e8db4459eb0758d0419fe07ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31f4ebde0fe049c68adc14e8a5b5b83d","placeholder":"​","style":"IPY_MODEL_2859ae351c884351aecac5bfea7a6268","value":"config_sentence_transformers.json: 100%"}},"84cfed1b59ed4d918ff594947be27adb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8788398ad42648eebc21afab6eb43494","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_158bb8aebead4eacbbdcc7d854450ec3","value":116}},"b31acc9e55ba41929c7dab203fb79978":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53613814bcc840629b85df1b81433a49","placeholder":"​","style":"IPY_MODEL_94cf679831484e61a61548e878920c64","value":" 116/116 [00:00&lt;00:00, 8.60kB/s]"}},"939b5ada21bb4b858128a1d4caa9117f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31f4ebde0fe049c68adc14e8a5b5b83d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2859ae351c884351aecac5bfea7a6268":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8788398ad42648eebc21afab6eb43494":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"158bb8aebead4eacbbdcc7d854450ec3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53613814bcc840629b85df1b81433a49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94cf679831484e61a61548e878920c64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0bf3aa31dfe4e84bb8fe6f778e04ebd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0d53a637764468abcd42a4b7436a2eb","IPY_MODEL_69711a6bed4243dcaef1172005affa93","IPY_MODEL_94d40cb5e4ee46719f47453a8a49435a"],"layout":"IPY_MODEL_d720daf786e84ef780f9c54346af1be2"}},"f0d53a637764468abcd42a4b7436a2eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4bc59acfefe4d5587f65a161445ae45","placeholder":"​","style":"IPY_MODEL_96d1b98bf3f346c3bd401f39d4944bd4","value":"README.md: 100%"}},"69711a6bed4243dcaef1172005affa93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18cae444d1e14a34ae33174d301f1b91","max":10659,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f829babaa56e4b6bb670b2fb394be5a6","value":10659}},"94d40cb5e4ee46719f47453a8a49435a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf0f4c95fc974cef9093c2de6c807dfc","placeholder":"​","style":"IPY_MODEL_8973dc3d59504d5fa1f1967ce575bc7c","value":" 10.7k/10.7k [00:00&lt;00:00, 643kB/s]"}},"d720daf786e84ef780f9c54346af1be2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4bc59acfefe4d5587f65a161445ae45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d1b98bf3f346c3bd401f39d4944bd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18cae444d1e14a34ae33174d301f1b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f829babaa56e4b6bb670b2fb394be5a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf0f4c95fc974cef9093c2de6c807dfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8973dc3d59504d5fa1f1967ce575bc7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"437af67932df433589d66affbc3da5fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67df030304d94110a92a9036ad9c3ae7","IPY_MODEL_ef3322b1830f4ec8bc06cde267434a7f","IPY_MODEL_84a5197dd9ec4e5c8936551eb21a17c2"],"layout":"IPY_MODEL_f5183736ca124e3ea327c4e1dc8c1e81"}},"67df030304d94110a92a9036ad9c3ae7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3d438d7703b4e1fb11100534b478b85","placeholder":"​","style":"IPY_MODEL_ce1e4e7661144057b56e3e871d9ef6b4","value":"sentence_bert_config.json: 100%"}},"ef3322b1830f4ec8bc06cde267434a7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8944addec5294f62abad29ed983f9d2e","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58d30bff243544caa8d37b39e086e8d9","value":53}},"84a5197dd9ec4e5c8936551eb21a17c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6edefa1eec1411abcf84f2a00b56328","placeholder":"​","style":"IPY_MODEL_f4fb331d752d4add96ba184f9eb1f148","value":" 53.0/53.0 [00:00&lt;00:00, 3.90kB/s]"}},"f5183736ca124e3ea327c4e1dc8c1e81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3d438d7703b4e1fb11100534b478b85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce1e4e7661144057b56e3e871d9ef6b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8944addec5294f62abad29ed983f9d2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d30bff243544caa8d37b39e086e8d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6edefa1eec1411abcf84f2a00b56328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4fb331d752d4add96ba184f9eb1f148":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a983e6264b2c47e5961d6026e03454f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43d96cf8e7c0441dbff06c89f1fab67a","IPY_MODEL_dbee6b6638fc4108b68476e1ab928f40","IPY_MODEL_3782966617394ae2a8c1a2d326e8e023"],"layout":"IPY_MODEL_d542f761d50a48408031f0b3196586fb"}},"43d96cf8e7c0441dbff06c89f1fab67a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84394c3dee9545d783e3f25cc1cfe658","placeholder":"​","style":"IPY_MODEL_6fbcd51dbffb40d1a6bc6b7fc7321b54","value":"config.json: 100%"}},"dbee6b6638fc4108b68476e1ab928f40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a12ce4c1a46b4c90aee55957aa9379b2","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55d206ad7de340059ce19e973cb64647","value":612}},"3782966617394ae2a8c1a2d326e8e023":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc9cec09589240c1a7cca71d22e1dc1c","placeholder":"​","style":"IPY_MODEL_75499456c89d4ef6ac2358d280b519b4","value":" 612/612 [00:00&lt;00:00, 40.0kB/s]"}},"d542f761d50a48408031f0b3196586fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84394c3dee9545d783e3f25cc1cfe658":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fbcd51dbffb40d1a6bc6b7fc7321b54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a12ce4c1a46b4c90aee55957aa9379b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55d206ad7de340059ce19e973cb64647":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc9cec09589240c1a7cca71d22e1dc1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75499456c89d4ef6ac2358d280b519b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68e35762c9254b93b5af79b87a1b915d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d542a0a6324f4f2fbd1fa3a4329dc09c","IPY_MODEL_e8ed5fbe7b4248e99924eca3aa782cd6","IPY_MODEL_e35d12fc7b9a4e4689a1ad4091450b5f"],"layout":"IPY_MODEL_a589061c45844ba1b25fd697cfa4df04"}},"d542a0a6324f4f2fbd1fa3a4329dc09c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e5c130e104a4719b8a03779d79d8471","placeholder":"​","style":"IPY_MODEL_63a129ea4f474caeadfd9c613a22158e","value":"model.safetensors: 100%"}},"e8ed5fbe7b4248e99924eca3aa782cd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2eae8b240934a5d82d9a0224427b25d","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50ff39c332b74150ae0f94089d7a2ef3","value":90868368}},"e35d12fc7b9a4e4689a1ad4091450b5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_834cf3587ed442b08003c2d4fda0d89f","placeholder":"​","style":"IPY_MODEL_77d96a7599d34559840ae84f7c541b75","value":" 90.9M/90.9M [00:01&lt;00:00, 115MB/s]"}},"a589061c45844ba1b25fd697cfa4df04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e5c130e104a4719b8a03779d79d8471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63a129ea4f474caeadfd9c613a22158e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2eae8b240934a5d82d9a0224427b25d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50ff39c332b74150ae0f94089d7a2ef3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"834cf3587ed442b08003c2d4fda0d89f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77d96a7599d34559840ae84f7c541b75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23356d2e2a514506a56f12c6c3f75a98":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7047118b19b4276869d3fec71ab4822","IPY_MODEL_35bf59643b70494a82c7abe20b7872ad","IPY_MODEL_27a3eee23cb349c083c90227b333acd2"],"layout":"IPY_MODEL_e8982b572c75466e8e78a366a2ebe474"}},"a7047118b19b4276869d3fec71ab4822":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64752a50060e4768928ae1b553a77d4d","placeholder":"​","style":"IPY_MODEL_f8d9c508a5444eb984372f2dd0f596ba","value":"tokenizer_config.json: 100%"}},"35bf59643b70494a82c7abe20b7872ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92964bfb29d24e15a054b724df7ffbf9","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_712f227f1028439893886da36d2fb6f2","value":350}},"27a3eee23cb349c083c90227b333acd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f758b677ce644579e0d04434ea01ad2","placeholder":"​","style":"IPY_MODEL_e0c07743b6134cc8adafa2287339e4ee","value":" 350/350 [00:00&lt;00:00, 18.2kB/s]"}},"e8982b572c75466e8e78a366a2ebe474":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64752a50060e4768928ae1b553a77d4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8d9c508a5444eb984372f2dd0f596ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92964bfb29d24e15a054b724df7ffbf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"712f227f1028439893886da36d2fb6f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f758b677ce644579e0d04434ea01ad2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0c07743b6134cc8adafa2287339e4ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6698b2f0a0748c593f8266a03e8e3a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a28bc8b706d544f581d4793fe1f44297","IPY_MODEL_6dbbea6f0c0348c88cbd7739774cc324","IPY_MODEL_6c2f09e456ef4b2b8d2e17012e5093b2"],"layout":"IPY_MODEL_95ee80498f87425aa3e4c7b5e9bf36de"}},"a28bc8b706d544f581d4793fe1f44297":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8564cf1b429e49b99c8f52dba6a7f038","placeholder":"​","style":"IPY_MODEL_2f50793d2b264caf9e8b8478f9123d3f","value":"vocab.txt: 100%"}},"6dbbea6f0c0348c88cbd7739774cc324":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b37c73ac2d34886b126481a4b2bb553","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_952bac09ae824f02b127d04bcba8510d","value":231508}},"6c2f09e456ef4b2b8d2e17012e5093b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a99e3fd505014877948e52c120b973cc","placeholder":"​","style":"IPY_MODEL_863e14ba8d2c4f0f9b2eefa009fa76f1","value":" 232k/232k [00:00&lt;00:00, 12.8MB/s]"}},"95ee80498f87425aa3e4c7b5e9bf36de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8564cf1b429e49b99c8f52dba6a7f038":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f50793d2b264caf9e8b8478f9123d3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b37c73ac2d34886b126481a4b2bb553":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"952bac09ae824f02b127d04bcba8510d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a99e3fd505014877948e52c120b973cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"863e14ba8d2c4f0f9b2eefa009fa76f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f1c42eff3724a0aa7e2c8d9cca3d8f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b86acb21bb84f5d9baef7f96f9fc706","IPY_MODEL_f72de091cb58404995d81cbfeb7561db","IPY_MODEL_b2c94b607c4643778f2f4cb3b4383ebe"],"layout":"IPY_MODEL_5bfec39d57614082bdedb25650d903ca"}},"4b86acb21bb84f5d9baef7f96f9fc706":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80cf5fa1a7b3451785d401e10ff0d77c","placeholder":"​","style":"IPY_MODEL_c2fc3cf71cea4279ab40b555bfbab1f8","value":"tokenizer.json: 100%"}},"f72de091cb58404995d81cbfeb7561db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b283a280e644b0185894d9c83e62fba","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4d7ac82f62147ff9be029a3f7b31f71","value":466247}},"b2c94b607c4643778f2f4cb3b4383ebe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd58f23b33ab48b5bc9691706850ecfc","placeholder":"​","style":"IPY_MODEL_ec1c80734f444e8fba351c0ef5c996d7","value":" 466k/466k [00:00&lt;00:00, 31.0MB/s]"}},"5bfec39d57614082bdedb25650d903ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80cf5fa1a7b3451785d401e10ff0d77c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2fc3cf71cea4279ab40b555bfbab1f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b283a280e644b0185894d9c83e62fba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4d7ac82f62147ff9be029a3f7b31f71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd58f23b33ab48b5bc9691706850ecfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1c80734f444e8fba351c0ef5c996d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c760e27bfa44c34a6b58470413ea430":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c45defc9b220461f968e8ff084c39ad0","IPY_MODEL_b9f9509d2a8141099d6e5e1d48385f23","IPY_MODEL_2595f6c665a14f1e81faafab3ab71e94"],"layout":"IPY_MODEL_313b03bd2238456794502432c280265c"}},"c45defc9b220461f968e8ff084c39ad0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4db00b6bbe6044e09b6f6d6517180bf0","placeholder":"​","style":"IPY_MODEL_f00fd8b4d5644ba3a69a662e0da9cb32","value":"special_tokens_map.json: 100%"}},"b9f9509d2a8141099d6e5e1d48385f23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebf5942b5dcf467faa172b1ddd315bf1","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71a84d3ecb504943846915b33fa4fcdb","value":112}},"2595f6c665a14f1e81faafab3ab71e94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4cd4a5c08ae402691a85ae10da59816","placeholder":"​","style":"IPY_MODEL_fcc2e03cf6bf4e56b87354936ff19f1a","value":" 112/112 [00:00&lt;00:00, 4.69kB/s]"}},"313b03bd2238456794502432c280265c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4db00b6bbe6044e09b6f6d6517180bf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f00fd8b4d5644ba3a69a662e0da9cb32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebf5942b5dcf467faa172b1ddd315bf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71a84d3ecb504943846915b33fa4fcdb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4cd4a5c08ae402691a85ae10da59816":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcc2e03cf6bf4e56b87354936ff19f1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"300a8e3915344a14a5ee4cc4e9f9c8c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36d2b63258d141919cfecfc38b2587db","IPY_MODEL_6a28307dc08d4ab092661ab023f5beb6","IPY_MODEL_42bb7fab57864aa9809fe9cfd928e708"],"layout":"IPY_MODEL_83830143d44c48fba63c1d5301d71de9"}},"36d2b63258d141919cfecfc38b2587db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1098e11bc01d481f836d6f681980f030","placeholder":"​","style":"IPY_MODEL_bddd129db7584bc584211544a9dd78db","value":"1_Pooling/config.json: 100%"}},"6a28307dc08d4ab092661ab023f5beb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d7a8de016f149ecafc025222f75d467","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c7a5fe6812e4e78814416e26d8b3321","value":190}},"42bb7fab57864aa9809fe9cfd928e708":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ab59cd9b4f445618a0de8f32b8baf48","placeholder":"​","style":"IPY_MODEL_6ef524bde1f546b2824e400244e0016c","value":" 190/190 [00:00&lt;00:00, 7.51kB/s]"}},"83830143d44c48fba63c1d5301d71de9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1098e11bc01d481f836d6f681980f030":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bddd129db7584bc584211544a9dd78db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d7a8de016f149ecafc025222f75d467":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c7a5fe6812e4e78814416e26d8b3321":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ab59cd9b4f445618a0de8f32b8baf48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ef524bde1f546b2824e400244e0016c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}